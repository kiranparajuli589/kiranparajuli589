import {
  __privateAdd,
  __privateGet,
  __privateMethod,
  __privateSet,
  __privateWrapper,
  __publicField
} from "./chunk-QWN5BXRD.js";

// node_modules/.pnpm/htmlmark@0.1.3/node_modules/htmlmark/dist/htmlmark.esm.js
var REGEX = {
  HR_LINE: /^\s*[-+*](?:(?:\s[-+*]){2,}|[-+*]{2,})$/g,
  QUOTE: {
    ITEM: /^\s*(?:>\s*)+(?<value>.+)/g,
    EMPTY: /^\s*[>\s]+$/g,
    COUNT: />/g,
    NON_QUOTE: /[^>\s\t]/
  },
  COMMENT: /^\s*<!-{2}\s(?<value>.+)\s-{2}>/g,
  IMAGE: /^\s*!\[(?<alt>.+)]\((?<url>.+)\)/g,
  HEADING: {
    ITEM: /^\s*(?<level>#{1,6})\s+((?<fenceVal>.+)(?=\s+#+\s*$)|(?<val>.+))/g,
    UNDERLINE_1: /^\s*=+$/g,
    UNDERLINE_2: /^\s*-+$/g
  },
  CODE_BLOCK: /^\s*`{3}\s*(?<lang>[a-z]*)$/g,
  LIST: {
    CHECKBOX: /^\s*(?:[-~*]|\d+\.)\s\[(?<check>\s|x)]\s(?<value>.+)/g,
    UNORDERED: /^\s*(?<mark>[-*+])\s(?<value>.+)/g,
    ORDERED: /^\s*(?<count>\d)\.\s(?<value>.+)/g,
    ITEM: /^\s*(?:(?<mark>[-*+])|(?<count>\d+)\.)\s+(\[(?<check>\s|x)]\s+)?(?<value>.+)/g,
    EMPTY: /^\s*(?<mark>[-*+]|(?<count>\d+)\.)(\s\[(?<check>(\s|x))]\s*|\s*)$/g
  },
  PARAGRAPH: {
    LINK: /^\[(?<text>.+?)]\((?<href>\S+)(?:\s['"](?<title>.+)['"])?\)/,
    REF_LINK: new RegExp("^((?<!!)\\[.+?](?!\\(.+\\))){1,2}"),
    HTML: /^\s*<\/(?<endTag>\w+)>|^\s*<(?<tag>\w+)(?<attrs>\s\w+(=\\?['"].+?['"])?)?>/,
    // eslint-disable-next-line no-useless-escape
    COMPUTED_HTML: `<(?<tag>%s)(?<attrs>sw+=\\?['"].+?['"])?>(?<content>.+)</%s>`,
    IMAGE: /^!\[(?<alt>.+)]\((?<href>\S+)(?:\s'(?<title>[^']+)'(\s(?<width>\d+)(\s(?<height>\d+))?)?)?\)/
  },
  HTML: /^\s*<(?<tag>\w+)(?<attrs>\s\w+=\\?['"].+?['"])?>(?<content>.?)/g,
  LINK_REF: {
    DECLARATION: /\s*\[(?<text>.+)]:\s+(?<href>\S+(?:\s'(?<title>.+?)')?)/g,
    WITH_TEXT: new RegExp("^(?<!!)\\[(?<text>.+?)](?!\\(.+\\))(?<!!)\\[(?<ref>.+?)](?!\\(.+\\))"),
    WITHOUT_TEXT: new RegExp("^(?<!!)\\[(?<ref>.+?)](?!\\(.+\\))")
  },
  TABLE: {
    ROW: new RegExp("^\\s*(?<!\\\\)\\|(?=(?:.+(?<!\\\\)\\|)+$)|(?!^)(?<cell>.+?)(?<!\\\\)\\|", "gy"),
    /**
     * @example |----|-----|------|
     */
    DASH_LINE: /^\s*\|(?=(?:-{2,}\|)+$)|(?!^)(?<cell>-{2,})\|/gy,
    /**
     * @example | --- | --- | --- |
     */
    S_DASH_LINE: /^\s*\|(?=(?:\s-{2,}\s\|)+$)|(?!^)(?<cell>\s-{2,})\s\|/gy,
    /**
     * @example |:----:|:----:|:----:|
     */
    COLON_LINE: /^\s*\|(?=(?::-{2,}:\|)+$)|(?!^):(?<cell>-{2,}):\|/gy,
    /**
     * @example | :---: | :---: | :---: |
     */
    S_COLON_LINE: /^\s*\|(?=(?:\s:-{2,}:\s\|)+$)|\s(?!^):(?<cell>-{2,}):\s\|/gy,
    CELL: new RegExp("(?<!\\\\)(\\|)", "g")
  },
  ESC: {
    GT: new RegExp("(?<!<\\/?\\w[^<>]*)>", "g"),
    LT: /<(?!([a-z/1-6]+>))/g
  },
  ESCAPED: /\\([*_[\]()!~+\\|`#><])/g,
  FRONT_MATTER: {
    BOUNDARY: /^-{3}\s*$/,
    ENTRY: /^\s*(?<key>\w+):\s*(?<value>.*)$/
  },
  NUMBER: /^\d+$/,
  NUMBER_WITH_DECIMAL: /^\d+\.\d+$/,
  BIG_BRACKETED: /^\[.*]$/,
  CURLY_BRACKETED: /^\{.*}$/
};
var Utils = class _Utils {
  /**
   * Checks if the given text matches the given regex
   *
   * @param {string} text
   * @param {RegExp} regex
   *
   * @returns {boolean}
   */
  static testRegex(text, regex) {
    regex.lastIndex = 0;
    return !!regex.test(text);
  }
  /**
   * Returns the regex matches for the given text
   *
   * @param {string} text
   * @param {RegExp} regex
   * @returns {RegExpExecArray}
   */
  static execRegex(text, regex) {
    regex.lastIndex = 0;
    return regex.exec(text);
  }
  /**
   * Match the given text against the given regex
   *
   * @param {string} text
   * @param {RegExp} regex
   *
   * @returns {*[]}
   */
  static matchRegex(text, regex) {
    let m;
    const matches = [];
    while ((m = regex.exec(text)) !== null) {
      if (m.index === regex.lastIndex) {
        regex.lastIndex++;
      }
      const rGroups = Object.keys(m.groups);
      m.forEach((match, groupIndex) => {
        if (match && groupIndex !== 0) {
          matches.push({
            type: rGroups[groupIndex - 1],
            value: match
          });
        }
      });
    }
    return matches;
  }
  /**
   * Groups the given array of objects by the given key
   *
   * @param {Object[]} array - Array of objects to group
   * @param {string} key - Key to group by
   *
   * @returns {Object[]} - Grouped array of objects
   */
  static groupBy(array, key) {
    const grouped = [];
    array.forEach((item, index) => {
      if (index === 0) {
        grouped.push(item);
      } else {
        const last = grouped[grouped.length - 1];
        if (last[key] === item[key]) {
          last.value += item.value;
        } else {
          grouped.push(item);
        }
      }
    });
    return grouped;
  }
  /**
   *
   * @param {string} text
   * @param {RegExp} regex
   * @returns {{type: string, value: string}[]}
   */
  static matchRG(text, regex) {
    const matches = _Utils.matchRegex(text, regex);
    return _Utils.groupBy(matches, "type");
  }
  /**
   * Returns the index of the nth occurrence of the given character in the given text
   * If the nth occurrence is not found, -1 is returned
   *
   * @param {string} text - Text to search in
   * @param {number} position - Position of the nth occurrence
   * @param {string} delimiter - Character to search for
   *
   * @returns {number}
   */
  static getNthIndex(text, position, delimiter = ">") {
    let count = 0;
    for (let i = 0; i < text.length; i++) {
      if (text[i] === delimiter) {
        count++;
        if (count === position) {
          return i;
        }
      }
    }
    return -1;
  }
  /**
   * Finds number of consecutive characters in a string from a given index
   *
   * @param {String} str - String to search
   * @param {Number} cursor - Index to start from
   * @param {string} char - Character to search for
   *
   * @returns {String}
   */
  static findConsecutive(str, cursor, char) {
    let consecutive = 0;
    for (let i = cursor; i < str.length; i++) {
      if (str[i] === char) {
        consecutive++;
      } else {
        break;
      }
    }
    return char.repeat(consecutive);
  }
  /**
   * Checks if the provided string contains an exact match for the provided identifier
   *
   * Generates regex like: /(?<![\\*])\*{2}(?!\*)/ for "**" as identifier
   *
   * Returns the index of the found identifier, or -1 if not found
   *
   * @param {String} str
   * @param {String} identifier
   *
   * @returns {Number}
   */
  static isExactMatch(str, identifier) {
    const count = identifier.length;
    const iChar = identifier[0];
    const exactRegex = new RegExp(`(?<![\\\\${iChar}])\\${iChar}{${count}}(?!\\${iChar})`);
    return str.search(exactRegex);
  }
  /**
   * Checks if the provided string contains an loose match for the provided identifier
   *
   * Generates regex like: /(?<!\\)\*{2}/ where * is the identifier
   *
   * Returns the index of the found identifier, or -1 if not found
   *
   * @param {String} str
   * @param {String} identifier
   *
   * @returns {Number}
   */
  static isLooseMatch(str, identifier) {
    const iChar = identifier[0];
    const count = identifier.length;
    const regex = new RegExp(
      `(?<![\\\\${iChar}])\\${iChar}{${count}}`
    );
    return str.search(regex);
  }
};
var Esc = class {
  static nonTags(str) {
    if (!str) return str;
    return str.replaceAll("&", "&amp;").replaceAll(REGEX.ESC.LT, "&lt;").replaceAll(REGEX.ESC.GT, "&gt;").replaceAll('"', "&quot;").replaceAll("'", "&#39;");
  }
  static everything(str) {
    if (!str) return str;
    return str.replaceAll("&", "&amp;").replaceAll(">", "&gt;").replaceAll("<", "&lt;").replaceAll('"', "&quot;").replaceAll("'", "&#39;");
  }
  static decode(str) {
    if (!str) return str;
    return str.replaceAll("&amp;", "&").replaceAll("&gt;", ">").replaceAll("&lt;", "<").replaceAll("&quot;", '"').replaceAll("&#39;", "'");
  }
  static unEscape(str) {
    if (!str) return str;
    if (Utils.testRegex(str, REGEX.ESCAPED)) {
      str = str.replaceAll(REGEX.ESCAPED, "$1");
    }
    return str;
  }
};
var TOKENS = {
  NEW_LINE: "new-line",
  PARAGRAPH: "paragraph",
  CODE_BLOCK: "code-block",
  COMMENT: "comment",
  IMAGE: "image",
  QUOTE: "quote",
  BOLD: "bold",
  ITALIC: "italic",
  UNDERLINE: "underline",
  STRIKE_THROUGH: "strike-through",
  CODE: "code",
  LINK: "link",
  LIST: "list",
  LIST_ITEM: "list-item",
  COUNT_ITEM: "count-item",
  CHECK_ITEM: "check-item",
  HEADING: "heading",
  TEXT: "text",
  HR_LINE: "hr-line",
  TABLE: "table",
  UNORDERED_ITEM: "unordered",
  ORDERED_ITEM: "ordered",
  QUOTE_SEPARATOR: "q-sep",
  LINES: "lines",
  HTML: "html",
  FRONT_MATTER: "front-matter"
};
Number.prototype.inRange = function(a, b) {
  return this >= a && this <= b;
};
var INDENT_SIZE = 2;
var Indent = class {
  /**
   * returns the indentation count of the given text
   *
   * @param {string} text
   *
   * @returns {number}
   */
  static raw(text) {
    if (["", "\n", void 0].includes(text)) return 0;
    let count = 0;
    while (text[count] === " " || text[count] === "	") {
      count++;
    }
    return count;
  }
  /**
   * calculates the indentation of the given value
   *
   * @param {number} rawIndent
   *
   * @returns {number}
   */
  static calc(rawIndent) {
    return Math.floor(rawIndent / INDENT_SIZE) * INDENT_SIZE;
  }
  /**
   * returns the calculated indentation of the given text
   *
   * @param {string} text
   *
   * @returns {number}
   */
  static get(text) {
    return this.calc(this.raw(text));
  }
  /**
   * returns if in the range of the given indentation
   *
   * @param {number} test the indentation to test
   * @param {number} indent the indentation to test against
   *
   * @returns {boolean}
   */
  static inRange(test, indent) {
    return test.inRange(
      indent - INDENT_SIZE < 0 ? 0 : indent - INDENT_SIZE,
      indent + INDENT_SIZE
    );
  }
};
var _lines, _start, _cursor, _indent, _cellCount, _rows, _lex, _linkRefs, _withHeading, _Table_static, testRow_fn, getCellCount_fn, isHBSep_fn, isRow_fn, tokenizeCell_fn, _Table_instances, findEnd_fn, setRows_fn, performDeepLex_fn;
var _Table = class _Table {
  /**
   * Table Tokenizer Constructor
   *
   * @param {String[]} lines
   * @param {Number} cursor
   * @param {Number} indent
   * @param {Array} linkRefs
   *
   * @returns {Table}
   */
  constructor(lines, cursor, indent, linkRefs) {
    __privateAdd(this, _Table_instances);
    __privateAdd(this, _lines);
    __privateAdd(this, _start);
    __privateAdd(this, _cursor);
    __privateAdd(this, _indent);
    __privateAdd(this, _cellCount);
    __privateAdd(this, _rows, []);
    __privateAdd(this, _lex);
    __privateAdd(this, _linkRefs);
    __privateAdd(this, _withHeading);
    var _a;
    __privateSet(this, _lines, lines);
    __privateSet(this, _cursor, cursor);
    __privateSet(this, _start, cursor);
    __privateSet(this, _indent, indent);
    __privateSet(this, _linkRefs, linkRefs);
    __privateSet(this, _cellCount, __privateMethod(_a = _Table, _Table_static, getCellCount_fn).call(_a, __privateGet(this, _lines)[__privateGet(this, _cursor)]));
    __privateSet(this, _lex, { type: TOKENS.TABLE, indent: __privateGet(this, _indent), rows: [] });
    __privateSet(this, _withHeading, false);
  }
  /**
   * Checks if the lines from the given cursor contains a table
   *
   * @returns {boolean}
   */
  static test({ lines, cursor, indent }) {
    var _a, _b, _c, _d;
    const lineToParse = lines[cursor];
    if (!__privateMethod(_a = _Table, _Table_static, testRow_fn).call(_a, lineToParse)) return false;
    const cellCount = __privateMethod(this, _Table_static, getCellCount_fn).call(this, lineToParse);
    let nextLine = lines[cursor + 1];
    let nextNextLine = lines[cursor + 2];
    if (nextLine !== void 0) {
      nextLine = nextLine.trimEnd();
      nextNextLine = nextNextLine == null ? void 0 : nextNextLine.trimEnd();
      if (nextNextLine && __privateMethod(_b = _Table, _Table_static, isHBSep_fn).call(_b, nextLine, cellCount, indent) && __privateMethod(_c = _Table, _Table_static, isRow_fn).call(_c, nextNextLine, cellCount, indent) || __privateMethod(_d = _Table, _Table_static, isRow_fn).call(_d, nextLine, cellCount, indent)) {
        return true;
      }
    }
    return false;
  }
  /**
   * Tokenizes the lines for the Table token
   *
   * @returns {{cursor: number, lexer: {indent, type: string, rows: *[]}}}
   */
  tokenize() {
    __privateMethod(this, _Table_instances, findEnd_fn).call(this);
    __privateMethod(this, _Table_instances, setRows_fn).call(this);
    __privateMethod(this, _Table_instances, performDeepLex_fn).call(this);
    return { lexer: __privateGet(this, _lex), cursor: __privateGet(this, _cursor) - 1 };
  }
  /**
   * Runs the HTML parsing for the Table token
   *
   * @param {Object} lexer - the Table lexer
   *
   * @returns {string} - the Table HTML
   */
  static parse(lexer) {
    let tHeadingHtml, tBody;
    if (lexer.withHeading) {
      const tHeading = lexer.rows[0];
      tHeadingHtml = `<th>${tHeading.map((t) => Paragraph.parse(t)).join("</th><th>")}</th>`;
      tBody = lexer.rows.slice(1);
    } else {
      tBody = lexer.rows;
    }
    const tBodyHtml = tBody.map((row) => `<tr><td>${row.map((cell) => Paragraph.parse(cell)).join("</td><td>")}</td></tr>`).join("");
    return `<table>${tHeadingHtml ? `<thead><tr>
    ${tHeadingHtml}
  </tr></thead>` : ""}
  <tbody>
    ${tBodyHtml}
  </tbody>
</table>`;
  }
};
_lines = new WeakMap();
_start = new WeakMap();
_cursor = new WeakMap();
_indent = new WeakMap();
_cellCount = new WeakMap();
_rows = new WeakMap();
_lex = new WeakMap();
_linkRefs = new WeakMap();
_withHeading = new WeakMap();
_Table_static = new WeakSet();
testRow_fn = function(text) {
  return Utils.testRegex(text, REGEX.TABLE.ROW) && !(Utils.testRegex(text, REGEX.TABLE.DASH_LINE) || Utils.testRegex(text, REGEX.TABLE.COLON_LINE) || Utils.testRegex(text, REGEX.TABLE.S_DASH_LINE) || Utils.testRegex(text, REGEX.TABLE.S_COLON_LINE));
};
getCellCount_fn = function(text) {
  return (text.match(REGEX.TABLE.CELL) || []).length;
};
isHBSep_fn = function(text, count, indent) {
  var _a;
  return Indent.get(text) === indent && (Utils.testRegex(text, REGEX.TABLE.DASH_LINE) || Utils.testRegex(text, REGEX.TABLE.COLON_LINE) || Utils.testRegex(text, REGEX.TABLE.S_DASH_LINE) || Utils.testRegex(text, REGEX.TABLE.S_COLON_LINE)) && __privateMethod(_a = _Table, _Table_static, getCellCount_fn).call(_a, text) === count;
};
isRow_fn = function(text, count, indent) {
  var _a, _b, _c;
  return Indent.get(text) === indent && __privateMethod(_a = _Table, _Table_static, testRow_fn).call(_a, text) && __privateMethod(_b = _Table, _Table_static, getCellCount_fn).call(_b, text) === count && !__privateMethod(_c = _Table, _Table_static, isHBSep_fn).call(_c, text, count, indent);
};
tokenizeCell_fn = function(row, linkRefs) {
  const strippedRow = row.trim().slice(1, -1);
  const rawCells = strippedRow.split(REGEX.TABLE.CELL);
  const cells = [];
  rawCells.forEach((cell) => {
    if (cell === "|") return;
    cells.push({
      raw: cell,
      tokens: Paragraph.tokenize(cell.trim(), linkRefs)
    });
  });
  return cells;
};
_Table_instances = new WeakSet();
/**
 * Runs checks to find the actual end of the table
 */
findEnd_fn = function() {
  var _a, _b;
  __privateSet(this, _cursor, __privateGet(this, _cursor) + 1);
  if (__privateMethod(_a = _Table, _Table_static, isHBSep_fn).call(_a, __privateGet(this, _lines)[__privateGet(this, _cursor)], __privateGet(this, _cellCount), __privateGet(this, _indent))) {
    __privateSet(this, _cursor, __privateGet(this, _cursor) + 2);
    __privateSet(this, _withHeading, true);
  }
  while (__privateGet(this, _lines)[__privateGet(this, _cursor)] !== void 0 && __privateMethod(_b = _Table, _Table_static, isRow_fn).call(_b, __privateGet(this, _lines)[__privateGet(this, _cursor)], __privateGet(this, _cellCount), __privateGet(this, _indent))) {
    __privateWrapper(this, _cursor)._++;
  }
  __privateGet(this, _lex)["withHeading"] = __privateGet(this, _withHeading);
};
/**
 * Set the rows of the table to the #rows array
 */
setRows_fn = function() {
  const headingLine = __privateGet(this, _lines)[__privateGet(this, _start)];
  if (__privateGet(this, _withHeading)) {
    __privateSet(this, _rows, __privateGet(this, _cursor) === __privateGet(this, _start) + 3 ? [headingLine, __privateGet(this, _lines)[__privateGet(this, _start) + 2]] : [...[headingLine], ...__privateGet(this, _lines).slice(__privateGet(this, _start) + 2, __privateGet(this, _cursor))]);
  } else {
    __privateSet(this, _rows, __privateGet(this, _lines).slice(__privateGet(this, _start), __privateGet(this, _cursor)));
  }
};
/**
 * Tokenizes cells for each table rows
 */
performDeepLex_fn = function() {
  __privateGet(this, _rows).forEach((row) => {
    var _a;
    __privateGet(this, _lex).rows.push(__privateMethod(_a = _Table, _Table_static, tokenizeCell_fn).call(_a, row, __privateGet(this, _linkRefs)));
  });
};
__privateAdd(_Table, _Table_static);
__publicField(_Table, "tokenName", TOKENS.TABLE);
var Table = _Table;
var _Image = class _Image {
  /**
   * @returns {boolean}
   */
  static test({ line }) {
    return Utils.testRegex(line, REGEX.IMAGE);
  }
  /**
   * @param {string} text
   *
   * @returns {RegExpExecArray}
   */
  static match(text) {
    return Utils.execRegex(text.trim(), REGEX.IMAGE);
  }
  /**
   * @param {string} text
   *
   * @returns {{[p: string]: string}}
   */
  static tokenize(text) {
    return _Image.match(text).groups;
  }
  /**
   * returns HTML for image
   * @param {{url: string, alt: string}} lexer
   * @returns {string}
   */
  static parse(lexer) {
    return `<img src='${lexer.url}' alt='${Esc.nonTags(lexer.alt)}'>`;
  }
};
__publicField(_Image, "tokenName", TOKENS.IMAGE);
var Image = _Image;
var _Comment = class _Comment {
  /**
   * @returns {boolean}
   */
  static test({ line }) {
    return Utils.testRegex(line, REGEX.COMMENT);
  }
  /**
   * @param {string} text
   *
   * @returns {RegExpExecArray}
   */
  static match(text) {
    return Utils.execRegex(text.trim(), REGEX.COMMENT);
  }
  /**
   * @param {string} text
   *
   * @returns {{[p: string]: string}}
   */
  static tokenize(text) {
    return _Comment.match(text).groups;
  }
  /**
   * returns HTML for comment
   *
   * @param {{value: string}} lexer
   *
   * @returns {string}
   */
  static parse(lexer) {
    return `<!-- ${lexer.value}-->`;
  }
};
__publicField(_Comment, "tokenName", TOKENS.COMMENT);
var Comment = _Comment;
var HrLine = class {
  /**
   * @returns {boolean}
   */
  static test({ line }) {
    return Utils.testRegex(line, REGEX.HR_LINE);
  }
  /**
   * returns HTML for horizontal line
   *
   * @returns {string}
   */
  static parse() {
    return "<hr>";
  }
};
__publicField(HrLine, "tokenName", TOKENS.HR_LINE);
var _lines2, _start2, _cursor2, _indent2, _rawIndent, _withBraces, _lang, _body, _raw, _isBroken, _CodeBlock_instances, findEnd_fn2, setBody_fn, setRaw_fn;
var _CodeBlock = class _CodeBlock {
  /**
   * The CodeBlock Tokenizer Constructor
   *
   * @param {String[]} lines - Lines of the text
   * @param {Number} cursor - Cursor position to start from
   * @param {Number} indent - Calculated Indent of the text
   * @param {Number} rawIndent - Raw indent of the text
   *
   * @returns {CodeBlock}
   */
  constructor(lines, cursor, indent, rawIndent) {
    __privateAdd(this, _CodeBlock_instances);
    __privateAdd(this, _lines2);
    __privateAdd(this, _start2);
    __privateAdd(this, _cursor2);
    __privateAdd(this, _indent2);
    __privateAdd(this, _rawIndent);
    __privateAdd(this, _withBraces);
    __privateAdd(this, _lang);
    __privateAdd(this, _body);
    __privateAdd(this, _raw);
    __privateAdd(this, _isBroken, false);
    var _a, _b;
    __privateSet(this, _lines2, lines);
    __privateSet(this, _cursor2, cursor);
    __privateSet(this, _start2, cursor);
    __privateSet(this, _indent2, indent);
    __privateSet(this, _rawIndent, rawIndent);
    __privateSet(this, _withBraces, _CodeBlock.testRegex(lines[cursor]));
    __privateSet(this, _lang, ((_b = (_a = _CodeBlock.matchRegex(lines[cursor])) == null ? void 0 : _a.groups) == null ? void 0 : _b.lang) || null);
  }
  /**
   * Checks if the given text is of the CodeBlock type
   *
   * @returns {boolean}
   */
  static test({ line, indent, fromToken, lastLexer }) {
    if (!fromToken && indent >= 4 && (!lastLexer || lastLexer.type === TOKENS.NEW_LINE)) {
      return true;
    }
    if (fromToken === TOKENS.LIST_ITEM && indent >= 8 && (!lastLexer || (lastLexer == null ? void 0 : lastLexer.type) === TOKENS.NEW_LINE)) {
      return true;
    }
    if (fromToken === TOKENS.QUOTE && indent >= 4 && (!lastLexer || (lastLexer == null ? void 0 : lastLexer.type) === TOKENS.NEW_LINE)) {
      return true;
    }
    return _CodeBlock.testRegex(line);
  }
  /**
   * Checks if the given string matches the CodeBlock regex
   *
   * @param {String} text - Text to be checked
   *
   * @returns {boolean}
   */
  static testRegex(text) {
    return Utils.testRegex(text.trimEnd(), REGEX.CODE_BLOCK);
  }
  /**
   * Returns the CodeBlock regex match for the given text
   *
   * @param {String} text - Text to be checked
   *
   * @returns {RegExpExecArray}
   */
  static matchRegex(text) {
    return Utils.execRegex(text.trimEnd(), REGEX.CODE_BLOCK);
  }
  /**
   * Tokenizes the lines for the CodeBlock token
   *
   * @returns {{
   * cursor: number,
   * lexer: {
   * 		type: string,
   * 		indent: number,
   * 		language: string|null,
   * 		value: string,
   * 		raw: string
   * }}}
   */
  tokenize() {
    __privateMethod(this, _CodeBlock_instances, findEnd_fn2).call(this);
    __privateMethod(this, _CodeBlock_instances, setBody_fn).call(this);
    __privateMethod(this, _CodeBlock_instances, setRaw_fn).call(this);
    return {
      cursor: __privateGet(this, _cursor2) - 1,
      lexer: {
        type: TOKENS.CODE_BLOCK,
        indent: __privateGet(this, _indent2),
        language: __privateGet(this, _lang) || null,
        value: __privateGet(this, _body),
        raw: __privateGet(this, _raw)
      }
    };
  }
  /**
   * returns HTML for code block
   *
   * Format: <pre><code>{body}</code></pre>
   *
   * @param {Object} lexer - the CodeBlock lexer
   * @param {Function|null} highlightFn - A function to highlight code blocks
   *
   * @returns {string} - the CodeBlock HTML
   */
  static parse(lexer, highlightFn = null) {
    let skeleton = "<pre><code%class>%s</code></pre>";
    if (lexer.language) {
      skeleton = skeleton.replace("%class", ` class='language-${lexer.language}'`);
    } else {
      skeleton = skeleton.replace("%class", "");
    }
    if (highlightFn) {
      const highlightedCode = highlightFn(lexer.value, lexer.language);
      if (typeof highlightedCode === "string") {
        lexer.value = highlightedCode;
      } else {
        console.error("highlightFn must return a string");
        console.info("highlightFn was not used");
      }
      skeleton = skeleton.replace("%s", lexer.value);
    } else {
      skeleton = skeleton.replace("%s", Esc.everything(lexer.value));
    }
    return skeleton;
  }
};
_lines2 = new WeakMap();
_start2 = new WeakMap();
_cursor2 = new WeakMap();
_indent2 = new WeakMap();
_rawIndent = new WeakMap();
_withBraces = new WeakMap();
_lang = new WeakMap();
_body = new WeakMap();
_raw = new WeakMap();
_isBroken = new WeakMap();
_CodeBlock_instances = new WeakSet();
/**
 * Finds the end of the CodeBlock
 *
 * Checks if the CodeBlock is broken or not
 */
findEnd_fn2 = function() {
  let nextLine, nextLineIndent, nextLineMatch, isNextLineClosingOne;
  do {
    nextLine = __privateGet(this, _lines2)[++__privateWrapper(this, _cursor2)._];
    if (nextLine === "") {
      continue;
    }
    nextLineIndent = nextLine ? Indent.get(nextLine) : null;
    if (nextLine !== void 0) {
      if (__privateGet(this, _withBraces)) {
        nextLineMatch = nextLine.trim() === "```";
        if (nextLineMatch && nextLineIndent === __privateGet(this, _indent2)) {
          isNextLineClosingOne = true;
        }
      }
    }
    if (!isNextLineClosingOne) {
      if (nextLineIndent < __privateGet(this, _indent2)) {
        isNextLineClosingOne = true;
        if (__privateGet(this, _withBraces)) __privateSet(this, _isBroken, true);
      }
    }
  } while (nextLine !== void 0 && !isNextLineClosingOne);
};
/**
 * Sets the CodeBlock body
 */
setBody_fn = function() {
  const start = __privateGet(this, _withBraces) ? __privateGet(this, _start2) + 1 : __privateGet(this, _start2);
  __privateSet(this, _body, __privateGet(this, _lines2).slice(start, __privateGet(this, _cursor2)).map((line) => line.slice(Math.min(__privateGet(this, _rawIndent), Indent.raw(line)))).join("\n"));
};
/**
 * Sets the CodeBlock raw body
 */
setRaw_fn = function() {
  let endRaw;
  if (__privateGet(this, _withBraces)) {
    endRaw = __privateGet(this, _cursor2) + 1;
    if (__privateGet(this, _isBroken)) endRaw = __privateGet(this, _cursor2);
  } else endRaw = __privateGet(this, _cursor2);
  __privateSet(this, _raw, __privateGet(this, _lines2).slice(__privateGet(this, _start2), endRaw).join("\n"));
  __privateSet(this, _cursor2, endRaw);
};
__publicField(_CodeBlock, "tokenName", TOKENS.CODE_BLOCK);
var CodeBlock = _CodeBlock;
var _lexers, _cursor3, _config, _fromToken, _currentLexer, _parsedContent, _modifiedParsers, _Parser_instances, parseParagraph_fn, parseCurrentLexer_fn;
var Parser = class {
  constructor(lexers, { from = null, config = {} } = {}) {
    __privateAdd(this, _Parser_instances);
    __privateAdd(this, _lexers);
    __privateAdd(this, _cursor3);
    __privateAdd(this, _config);
    __privateAdd(this, _fromToken);
    __privateAdd(this, _currentLexer);
    __privateAdd(this, _parsedContent);
    __privateAdd(this, _modifiedParsers, {});
    __privateSet(this, _lexers, lexers);
    __privateSet(this, _parsedContent, []);
    __privateSet(this, _fromToken, from);
    __privateSet(this, _config, config);
    __privateSet(this, _modifiedParsers, {});
    __privateGet(this, _modifiedParsers)[TOKENS.PARAGRAPH] = __privateMethod(this, _Parser_instances, parseParagraph_fn).bind(this);
  }
  run() {
    for (__privateSet(this, _cursor3, 0); __privateGet(this, _cursor3) < __privateGet(this, _lexers).length; __privateWrapper(this, _cursor3)._++) {
      __privateSet(this, _currentLexer, __privateGet(this, _lexers)[__privateGet(this, _cursor3)]);
      __privateMethod(this, _Parser_instances, parseCurrentLexer_fn).call(this);
    }
    return __privateGet(this, _parsedContent).map((item) => item.replaceAll("%s", "")).join("");
  }
};
_lexers = new WeakMap();
_cursor3 = new WeakMap();
_config = new WeakMap();
_fromToken = new WeakMap();
_currentLexer = new WeakMap();
_parsedContent = new WeakMap();
_modifiedParsers = new WeakMap();
_Parser_instances = new WeakSet();
parseParagraph_fn = function() {
  let parsed = Parsers.Paragraph.parse(__privateGet(this, _currentLexer));
  if (__privateGet(this, _fromToken) === TOKENS.LIST) {
    __privateGet(this, _parsedContent).push(`${parsed}`);
  } else __privateGet(this, _parsedContent).push(`<p>${parsed}</p>`);
};
parseCurrentLexer_fn = function() {
  for (const module in Parsers) {
    if (Parsers[module].tokenName === __privateGet(this, _currentLexer).type) {
      if (__privateGet(this, _modifiedParsers)[__privateGet(this, _currentLexer).type]) {
        __privateGet(this, _modifiedParsers)[__privateGet(this, _currentLexer).type]();
        return;
      }
      if (__privateGet(this, _currentLexer).type === TOKENS.CODE_BLOCK && __privateGet(this, _config).highlightFn && typeof __privateGet(this, _config).highlightFn === "function") {
        __privateGet(this, _parsedContent).push(Parsers[module].parse(__privateGet(this, _currentLexer), __privateGet(this, _config).highlightFn));
        return;
      }
      __privateGet(this, _parsedContent).push(Parsers[module].parse(__privateGet(this, _currentLexer)));
      return;
    }
  }
};
var _lines3, _start3, _cursor4, _body2, _tBody, _cDepth, _breakTokens, _Quote_instances, findLazyEnd_fn, findEnd_fn3, calcCommonDepth_fn, setBody_fn2, trimBody_fn, _Quote_static, wrapInside_fn;
var _Quote = class _Quote {
  constructor(lines, cursor) {
    __privateAdd(this, _Quote_instances);
    __privateAdd(this, _lines3);
    __privateAdd(this, _start3);
    __privateAdd(this, _cursor4);
    __privateAdd(this, _body2, []);
    __privateAdd(this, _tBody, []);
    __privateAdd(this, _cDepth);
    // these items should break the quote
    __privateAdd(this, _breakTokens, [
      // TODO: for heading, we may have to
      //  check for underlined headings too
      REGEX.HEADING.ITEM,
      REGEX.LIST.ITEM,
      REGEX.CODE_BLOCK
    ]);
    __privateSet(this, _lines3, lines);
    __privateSet(this, _cursor4, cursor);
    __privateSet(this, _start3, cursor);
  }
  /**
   * Checks if the given text matches the Quote regex
   *
   * @returns {boolean}
   */
  static test({ line }) {
    return Utils.testRegex(line, REGEX.QUOTE.ITEM);
  }
  /**
   * Checks if the given text matches the Empty Quote regex
   *
   * @param {string} text
   *
   * @returns {boolean}
   */
  static testEmpty(text) {
    return Utils.testRegex(text, REGEX.QUOTE.EMPTY);
  }
  /**
   * Returns the depth of the quote
   *
   * If the text does not start with > i.e. the lazy items, then 0 is returned
   * Otherwise, the count of > before the first non > character is returned
   *
   * @param {string} text
   *
   * @returns {number}
   */
  static getDepth(text) {
    text = text.trimStart();
    if (text[0] !== ">") return 0;
    if (_Quote.testEmpty(text.trim())) return text.match(REGEX.QUOTE.COUNT).length;
    const quotePart = text.substring(0, text.search(REGEX.QUOTE.NON_QUOTE));
    return quotePart.match(REGEX.QUOTE.COUNT).length;
  }
  /**
   * Returns the value of the quote from the provided depth
   *
   * @param {string} text - the text to be parsed
   * @param depth - the depth of the quote
   *
   * @returns {string}
   */
  static getValue(text, depth) {
    text = text.trimStart();
    const cursor = Utils.getNthIndex(text, depth);
    return text.substring(cursor + 1);
  }
  /**
   * Tokenizes the lines for the Quote token
   *
   * @returns {{ cursor: number, lexer: { tokens: Lexer[], depth: number, raw: string } }}
   */
  tokenize() {
    __privateMethod(this, _Quote_instances, findEnd_fn3).call(this);
    __privateMethod(this, _Quote_instances, setBody_fn2).call(this);
    __privateMethod(this, _Quote_instances, calcCommonDepth_fn).call(this);
    __privateMethod(this, _Quote_instances, trimBody_fn).call(this);
    const lex = new Lexer(__privateGet(this, _tBody), { from: TOKENS.QUOTE });
    return {
      cursor: __privateGet(this, _cursor4),
      lexer: {
        type: TOKENS.QUOTE,
        tokens: lex.run(),
        depth: __privateGet(this, _cDepth),
        raw: __privateGet(this, _body2).join("\n")
      }
    };
  }
  /**
   * Runs the HTML parsing for the Quote token
   *
   * @param {Object} lexer - the Quote lex
   *
   * @returns {string} - the HTML quote
   */
  static parse(lexer) {
    var _a;
    const qParts = [];
    lexer.tokens.forEach((qTokens) => {
      let babyParser;
      babyParser = new Parser([qTokens]);
      qParts.push(babyParser.run());
    });
    return __privateMethod(_a = _Quote, _Quote_static, wrapInside_fn).call(_a, lexer.depth, qParts.join(""));
  }
};
_lines3 = new WeakMap();
_start3 = new WeakMap();
_cursor4 = new WeakMap();
_body2 = new WeakMap();
_tBody = new WeakMap();
_cDepth = new WeakMap();
_breakTokens = new WeakMap();
_Quote_instances = new WeakSet();
findLazyEnd_fn = function() {
  __privateWrapper(this, _cursor4)._--;
  let nextLine;
  let endLazy = false;
  do {
    nextLine = __privateGet(this, _lines3)[++__privateWrapper(this, _cursor4)._];
    if (nextLine !== void 0) {
      if (Newline.test({ line: nextLine })) {
        endLazy = true;
      }
      for (let r = 0; r < __privateGet(this, _breakTokens).length; r++) {
        if (Utils.testRegex(nextLine, __privateGet(this, _breakTokens)[r])) {
          endLazy = true;
          break;
        }
      }
    }
  } while (nextLine !== void 0 && !endLazy);
  __privateWrapper(this, _cursor4)._--;
};
/**
 * Finds the end of the quote
 *
 * Runs check for laziness and breaks
 */
findEnd_fn3 = function() {
  let nextLine = __privateGet(this, _lines3)[__privateGet(this, _cursor4)];
  let nextLineMatch;
  do {
    nextLine = __privateGet(this, _lines3)[++__privateWrapper(this, _cursor4)._];
    if (nextLine !== void 0) {
      nextLineMatch = nextLine.trim().startsWith(">");
    } else nextLineMatch = false;
  } while (nextLineMatch);
  const lastLineOfQuote = __privateGet(this, _lines3)[__privateGet(this, _cursor4) - 1];
  if (_Quote.testEmpty(lastLineOfQuote)) {
    __privateWrapper(this, _cursor4)._--;
    return;
  }
  __privateMethod(this, _Quote_instances, findLazyEnd_fn).call(this);
};
/**
 * Calculates the common depth for the Quote
 */
calcCommonDepth_fn = function() {
  __privateGet(this, _body2).forEach((item) => {
    const currDepth = _Quote.getDepth(item);
    if (__privateGet(this, _cDepth) === void 0) {
      __privateSet(this, _cDepth, currDepth);
    } else if (currDepth !== 0) {
      __privateSet(this, _cDepth, Math.min(__privateGet(this, _cDepth), currDepth));
    }
  });
};
/**
 * Sets the body of the quote
 */
setBody_fn2 = function() {
  __privateSet(this, _body2, __privateGet(this, _lines3).slice(__privateGet(this, _start3), __privateGet(this, _cursor4) + 1));
};
/**
 * Trims the quote from the body
 * Every common depth quote part is stripped
 */
trimBody_fn = function() {
  __privateGet(this, _body2).forEach((item) => {
    if (_Quote.test({ line: item }) || _Quote.testEmpty(item)) {
      __privateGet(this, _tBody).push(_Quote.getValue(item, __privateGet(this, _cDepth)).trimEnd());
    } else {
      __privateGet(this, _tBody).push(item.trimEnd());
    }
  });
};
_Quote_static = new WeakSet();
wrapInside_fn = function(depth, content) {
  let qHtml = "%s";
  for (let j = 0; j < depth; j++) {
    qHtml = qHtml.replace("%s", `<blockquote>
%s</blockquote>`);
  }
  return qHtml.replace("%s", `${content}`);
};
__privateAdd(_Quote, _Quote_static);
__publicField(_Quote, "tokenName", TOKENS.QUOTE);
var Quote = _Quote;
var _line, _nextLine, _level, _match, _setext, _Heading_instances, findType_fn;
var _Heading = class _Heading {
  /**
   * Heading Tokenizer Constructor
   *
   * @param {string} line current line to tokenize
   * @param {string| undefined} nextLine next line for tokenization
   *
   * @returns {Heading}
   */
  constructor(line, nextLine) {
    __privateAdd(this, _Heading_instances);
    __privateAdd(this, _line);
    __privateAdd(this, _nextLine);
    __privateAdd(this, _level);
    __privateAdd(this, _match);
    __privateAdd(this, _setext, false);
    __privateSet(this, _line, line);
    __privateSet(this, _nextLine, nextLine);
    __privateMethod(this, _Heading_instances, findType_fn).call(this);
  }
  /**
   * Checks if the given text matches the Heading regex
   *
   * @param {string} text
   * @returns {boolean}
   */
  static testRegex(text) {
    return Utils.testRegex(text, REGEX.HEADING.ITEM);
  }
  /**
   * Checks if the given text is of Heading 1 underline type
   *
   * @param {string} text
   * @returns {boolean}
   */
  static testH1UnderlineRegex(text) {
    return Utils.testRegex(text, REGEX.HEADING.UNDERLINE_1);
  }
  /**
   * Checks if the given text is of Heading 2 underline type
   *
   * @param {string} text
   *
   * @returns {boolean}
   */
  static testH2UnderlineRegex(text) {
    return Utils.testRegex(text, REGEX.HEADING.UNDERLINE_2);
  }
  /**
   * Returns the regex groups match for the Heading token
   *
   * Following groups are returned:
   * 1. level - number of #s in the Heading
   * 2. fenceVal - If fenced Heading, the value of the fenced Heading
   * 3. val - the value of the normal Heading (without fence)
   *
   * @param {string} text
   *
   * @returns {RegExpExecArray}
   */
  static match(text) {
    return Utils.execRegex(text, REGEX.HEADING.ITEM);
  }
  /**
   * Checks if the given text is of Heading type
   *
   * @returns {boolean}
   */
  static test({ line, nextLine }) {
    if (_Heading.testRegex(line)) return true;
    if (nextLine !== void 0 && !HrLine.test({ line })) {
      if (_Heading.testH1UnderlineRegex(nextLine) || _Heading.testH2UnderlineRegex(nextLine)) {
        return true;
      }
    }
  }
  /**
   * tokenizes the line for Heading token
   *
   * @returns {{level: number, value: string, raw: string, setext: boolean}}
   */
  tokenize() {
    if (!__privateGet(this, _setext)) {
      return {
        level: __privateGet(this, _match).level.length,
        value: __privateGet(this, _match).value.trimEnd(),
        raw: __privateGet(this, _line),
        setext: false
      };
    } else {
      return {
        level: __privateGet(this, _level),
        value: __privateGet(this, _line).trimEnd(),
        raw: `${__privateGet(this, _line)}
${__privateGet(this, _nextLine)}`,
        setext: true
      };
    }
  }
  /**
   * Runs the HTML parsing for the Heading token
   *
   * @param {Object} lexer the Heading lex
   *
   * @returns {string} the Heading HTML
   */
  static parse(lexer) {
    return `<h${lexer.level}>${Paragraph.parse(lexer)}</h${lexer.level}>`;
  }
};
_line = new WeakMap();
_nextLine = new WeakMap();
_level = new WeakMap();
_match = new WeakMap();
_setext = new WeakMap();
_Heading_instances = new WeakSet();
/**
 * Checks if the Heading is of Setext or ATX type
 *
 * Sets the #setext property to true if it is of Underline type
 * Sets the #level property to the level of the Heading
 *
 * @returns void
 */
findType_fn = function() {
  var _a;
  if (__privateGet(this, _nextLine) !== void 0) {
    if (!_Heading.testRegex(__privateGet(this, _line))) {
      if (_Heading.testH1UnderlineRegex(__privateGet(this, _nextLine))) {
        __privateSet(this, _setext, true);
        __privateSet(this, _level, 1);
      } else if (_Heading.testH2UnderlineRegex(__privateGet(this, _nextLine))) {
        __privateSet(this, _setext, true);
        __privateSet(this, _level, 2);
      }
    }
  }
  if (!__privateGet(this, _setext)) {
    __privateSet(this, _match, (_a = _Heading.match(__privateGet(this, _line))) == null ? void 0 : _a.groups);
    __privateGet(this, _match).value = __privateGet(this, _match).fenceVal || __privateGet(this, _match).val;
    delete __privateGet(this, _match).fenceVal;
    delete __privateGet(this, _match).val;
  }
};
__publicField(_Heading, "tokenName", TOKENS.HEADING);
var Heading = _Heading;
var _lines4, _cursor5, _indent3, _body3, _end, _shrunkBody, _lex2, _match2, _isEmpty, _meta, _List_instances, findEnd_fn4, processMeta_fn, setBody_fn3, shrinkBody_fn;
var _List = class _List {
  constructor(lines, cursor, indent) {
    __privateAdd(this, _List_instances);
    __privateAdd(this, _lines4);
    __privateAdd(this, _cursor5);
    __privateAdd(this, _indent3);
    __privateAdd(this, _body3, []);
    __privateAdd(this, _end);
    __privateAdd(this, _shrunkBody, []);
    __privateAdd(this, _lex2);
    __privateAdd(this, _match2);
    __privateAdd(this, _isEmpty);
    __privateAdd(this, _meta, {
      checklist: false,
      ordered: false,
      identifier: null
    });
    __privateSet(this, _lines4, lines);
    __privateSet(this, _cursor5, cursor);
    __privateSet(this, _indent3, indent);
    __privateSet(this, _isEmpty, _List.testEmpty(lines[cursor]));
    __privateMethod(this, _List_instances, processMeta_fn).call(this);
  }
  static testEmpty(text) {
    return Utils.testRegex(text, REGEX.LIST.EMPTY);
  }
  static testItem(text) {
    return Utils.testRegex(text, REGEX.LIST.ITEM);
  }
  static test({ line }) {
    if (_List.testEmpty(line)) {
      return true;
    }
    return _List.testItem(line);
  }
  static matchEmpty(text) {
    return Utils.execRegex(text, REGEX.LIST.EMPTY);
  }
  static matchItem(text) {
    return Utils.execRegex(text, REGEX.LIST.ITEM);
  }
  static match(text, isEmpty = false) {
    if (isEmpty) {
      return _List.matchEmpty(text);
    }
    return _List.matchItem(text);
  }
  /**
   * Tokenizes the provided lines for the List Item token
   *
   * @returns {{cursor: number,  meta: {ordered: boolean, identifier: null, checklist: boolean}, lexer: {count: null, checked: (boolean|null), raw: string, tokens: *, type: string}}}
   */
  tokenize() {
    __privateMethod(this, _List_instances, findEnd_fn4).call(this);
    __privateMethod(this, _List_instances, setBody_fn3).call(this);
    __privateMethod(this, _List_instances, shrinkBody_fn).call(this);
    __privateSet(this, _lex2, new Lexer(__privateGet(this, _shrunkBody), { from: TOKENS.LIST_ITEM }));
    return {
      cursor: __privateGet(this, _end) - 1,
      meta: __privateGet(this, _meta),
      lexer: {
        type: TOKENS.LIST_ITEM,
        tokens: __privateGet(this, _lex2).run(),
        count: __privateGet(this, _match2).count || null,
        checked: __privateGet(this, _meta).checklist ? __privateGet(this, _match2).check === "x" : null,
        raw: __privateGet(this, _body3).join("\n")
      }
    };
  }
  /**
   * Runs HTML parsing for the List token
   *
   * @param {Object} lexer - the List lexer
   *
   * @returns {string} - the List HTML
   */
  static parse(lexer) {
    const listTag = lexer.meta.ordered ? "ol" : "ul";
    let listBodyHtml = [];
    lexer.items.forEach((listItem) => {
      let listItemHtml = "<li>%s</li>";
      const lParser = new Parser(listItem.tokens, { from: TOKENS.LIST });
      if (lexer.meta.checklist) {
        const isChecked = listItem.checked ? " checked" : "";
        listItemHtml = listItemHtml.replace(
          "%s",
          "<input type='checkbox'" + isChecked + ">" + lParser.run()
        );
      } else {
        listItemHtml = listItemHtml.replace(
          "%s",
          new Parser(listItem.tokens, { from: TOKENS.LIST }).run()
        );
      }
      listBodyHtml.push(listItemHtml);
    });
    return `<${listTag}>${listBodyHtml.join("")}</${listTag}>`;
  }
  /**
   * Runs check if the last and current lexer is of same list type
   *
   * Things under check are:
   * 1. type of the lexers
   * 2. indentation
   * 3. is of type checklist
   * 4. ordered or unordered
   * 5. identifier of the list item
   *
   * @param {Object} baseLexer
   * @param {Object} lexerToCompare
   * @param {number} indent
   *
   * @returns {boolean}
   */
  static compareIfTwoListLexerAreOfSameType(baseLexer, lexerToCompare, indent) {
    return baseLexer && baseLexer.type === TOKENS.LIST && baseLexer.indent === indent && baseLexer.meta.checklist === lexerToCompare.meta.checklist && baseLexer.meta.ordered === lexerToCompare.meta.ordered && baseLexer.meta.identifier === lexerToCompare.meta.identifier;
  }
};
_lines4 = new WeakMap();
_cursor5 = new WeakMap();
_indent3 = new WeakMap();
_body3 = new WeakMap();
_end = new WeakMap();
_shrunkBody = new WeakMap();
_lex2 = new WeakMap();
_match2 = new WeakMap();
_isEmpty = new WeakMap();
_meta = new WeakMap();
_List_instances = new WeakSet();
/**
 * Finds the end of the list item
 * Updates the cursor value
 */
findEnd_fn4 = function() {
  if (__privateGet(this, _isEmpty)) {
    __privateSet(this, _end, __privateGet(this, _cursor5) + 1);
    return;
  }
  let cursor = __privateGet(this, _cursor5);
  let nextLine, nextLineIndent, nextNextLine;
  let breakMatch = false;
  do {
    nextLine = __privateGet(this, _lines4)[++cursor];
    nextLineIndent = Indent.get(nextLine);
    nextNextLine = __privateGet(this, _lines4)[cursor + 1];
    if (Newline.test({ line: nextLine })) {
      if (nextNextLine && Newline.test({ line: nextNextLine })) {
        breakMatch = true;
      } else if (Indent.get(nextNextLine) <= __privateGet(this, _indent3)) {
        breakMatch = true;
      }
    }
  } while (nextLine !== void 0 && !breakMatch && !((_List.test({ line: nextLine }) || Heading.test({ line: nextLine, nextLine: nextNextLine }) || Quote.test({ line: nextLine })) && nextLineIndent <= __privateGet(this, _indent3)));
  __privateSet(this, _end, cursor);
};
/**
 * Processes the list item meta
 *
 * The following meta are calculated:
 * 1. ordered: boolean - if the list item is ordered
 * 2. identifier: string - the identifier for the list item
 * 3. check: boolean - if the list item is a checklist item
 */
processMeta_fn = function() {
  __privateSet(this, _match2, _List.match(__privateGet(this, _lines4)[__privateGet(this, _cursor5)], __privateGet(this, _isEmpty)).groups);
  __privateGet(this, _meta).checklist = __privateGet(this, _match2).check !== void 0;
  __privateGet(this, _meta).ordered = !!__privateGet(this, _match2).count;
  if (__privateGet(this, _match2).mark) __privateGet(this, _meta).identifier = __privateGet(this, _match2).mark;
};
/**
 * Sets the raw body of the list item
 */
setBody_fn3 = function() {
  __privateSet(this, _body3, __privateGet(this, _lines4).slice(__privateGet(this, _cursor5), __privateGet(this, _end)));
};
/**
 * Shrinks raw body for the list item
 */
shrinkBody_fn = function() {
  for (let index = 0; index < __privateGet(this, _body3).length; index++) {
    const line = __privateGet(this, _body3)[index];
    if (index === 0) {
      if (__privateGet(this, _isEmpty)) {
        __privateGet(this, _shrunkBody).push("");
      } else {
        __privateGet(this, _shrunkBody).push(__privateGet(this, _match2).value);
      }
    } else {
      __privateGet(this, _shrunkBody).push(line);
    }
  }
};
__publicField(_List, "tokenName", TOKENS.LIST);
var List = _List;
var _linkRefs2, _lines5, _cursor6, _indent4, _lex3;
var HTML = class {
  constructor(lines, cursor, indent, linkRefs) {
    __privateAdd(this, _linkRefs2);
    __privateAdd(this, _lines5);
    __privateAdd(this, _cursor6);
    __privateAdd(this, _indent4);
    __privateAdd(this, _lex3);
    __privateSet(this, _lines5, lines);
    __privateSet(this, _cursor6, cursor);
    __privateSet(this, _indent4, indent);
    __privateSet(this, _linkRefs2, linkRefs);
    __privateSet(this, _lex3, []);
  }
  /**
   * @param {string} text
   *
   * @returns {boolean}
   */
  static test(text) {
    return Utils.testRegex(text, REGEX.PARAGRAPH.HTML);
  }
  static testBlock({ lines, cursor }) {
    const lineToParse = lines[cursor];
    return Utils.testRegex(lineToParse, REGEX.HTML);
  }
  tokenize() {
    const regexMatch = Utils.execRegex(__privateGet(this, _lines5)[__privateGet(this, _cursor6)], REGEX.HTML);
    __privateSet(this, _lex3, {
      type: TOKENS.HTML,
      indent: __privateGet(this, _indent4),
      ...regexMatch.groups,
      raw: __privateGet(this, _lines5)[__privateGet(this, _cursor6)]
    });
    return { lexer: __privateGet(this, _lex3), cursor: __privateGet(this, _cursor6) };
  }
  /**
   * returns HTML
   *
   * @returns {string}
   */
  static parse(lexer) {
    return lexer.raw;
  }
};
_linkRefs2 = new WeakMap();
_lines5 = new WeakMap();
_cursor6 = new WeakMap();
_indent4 = new WeakMap();
_lex3 = new WeakMap();
__publicField(HTML, "tokenName", TOKENS.HTML);
var _Paragraph_static, fenceSanity_fn, isFenced_fn, findLink_fn, findHtml_fn, findLinkRef_fn, findImage_fn, findEmphasis_fn;
var _Paragraph = class _Paragraph {
  /**
   * Returns a fence object
   *
   * @param {Boolean} fence - true if fence, false otherwise
   * @param {String} ident - identifier, defaults to ""
   * @param {Number} start - start index, defaults to -1
   * @param {Number} end - end index, defaults to -1
   *
   * @returns {{ident: string, start: number, end: number, fence: boolean}}
   */
  static fenceObj(fence = false, ident = "", start = -1, end = -1) {
    return {
      fence,
      ident,
      start,
      end
    };
  }
  /**
   * Paragraph Tokenization
   * Tokenizes a line of text into emphasis tokens
   *
   * @param {String} lineToParse
   * @param {Array} linkRefs
   *
   * @returns {*[]}
   */
  static tokenize(lineToParse, linkRefs) {
    var _a;
    return __privateMethod(_a = _Paragraph, _Paragraph_static, findEmphasis_fn).call(_a, lineToParse, linkRefs);
  }
  static parse(lexer) {
    let parsed = "";
    lexer.tokens.forEach((token) => {
      if (token.type === TOKENS.BOLD) {
        parsed += `<strong>${_Paragraph.parse(token)}</strong>`;
      } else if (token.type === TOKENS.ITALIC) {
        parsed += `<em>${_Paragraph.parse(token)}</em>`;
      } else if (token.type === TOKENS.CODE) {
        token.value = Esc.unEscape(token.value);
        parsed += `<code>${Esc.everything(token.value)}</code>`;
      } else if (token.type === TOKENS.STRIKE_THROUGH) {
        parsed += `<s>${_Paragraph.parse(token)}</s>`;
      } else if (token.type === TOKENS.LINK) {
        const linkTokens = token.tokens;
        let linkTag = `<a href="${linkTokens.href}"` + (linkTokens.tooltip ? ` title="${linkTokens.tooltip}"` : "") + ">" + _Paragraph.parse(linkTokens.title) + "</a>";
        parsed += linkTag;
      } else if (token.type === TOKENS.UNDERLINE) {
        parsed += `<u>${_Paragraph.parse(token)}</u>`;
      } else if (token.type === TOKENS.IMAGE) {
        const imgTokens = token.tokens;
        let imgTag = `<img src="${imgTokens.href}"` + (imgTokens.alt !== void 0 ? ` alt="${imgTokens.alt}"` : "") + (imgTokens.title !== void 0 ? ` title="${imgTokens.title}"` : "") + (imgTokens.width !== void 0 ? ` width="${imgTokens.width}"` : "") + (imgTokens.height !== void 0 ? ` height="${imgTokens.height}"` : "") + ">";
        parsed += imgTag;
      } else if (token.type === TOKENS.HTML) {
        parsed += token.raw;
      } else {
        const escaped = Esc.nonTags(token.value);
        const unescaped = Esc.unEscape(escaped);
        parsed += unescaped;
      }
    });
    return parsed;
  }
};
_Paragraph_static = new WeakSet();
fenceSanity_fn = function(str, start, identifierChar) {
  if (start > str.length) return false;
  const afterIdentifier = str.substring(start);
  return afterIdentifier.includes(identifierChar);
};
isFenced_fn = function(lineToParse, cursor, identifier, onlyExact = false, evenFence = false) {
  var _a;
  const start = cursor + identifier.length;
  const sanity = __privateMethod(_a = _Paragraph, _Paragraph_static, fenceSanity_fn).call(_a, lineToParse, start, identifier[0]);
  if (!sanity) return _Paragraph.fenceObj();
  const afterStartStr = lineToParse.slice(start);
  if (evenFence && identifier.length % 2 === 0 || !evenFence) {
    const exactEnd = Utils.isExactMatch(afterStartStr, identifier);
    if (exactEnd !== -1) {
      return this.fenceObj(true, identifier, start, start + exactEnd);
    }
  }
  if (!onlyExact) {
    for (let i = start; i >= cursor; i--) {
      const tempIdentifier = lineToParse.substring(cursor, i);
      if (evenFence) {
        if (tempIdentifier.length % 2 !== 0) {
          continue;
        }
      }
      const end = Utils.isLooseMatch(afterStartStr, tempIdentifier);
      if (end !== -1) {
        return _Paragraph.fenceObj(true, tempIdentifier, start, start + end);
      }
    }
  }
  return _Paragraph.fenceObj();
};
findLink_fn = function(lineToParse, cursor) {
  const check = lineToParse.substring(cursor);
  if (Utils.testRegex(check, REGEX.PARAGRAPH.LINK)) {
    const match = Utils.execRegex(check, REGEX.PARAGRAPH.LINK);
    return {
      found: true,
      groups: match.groups,
      end: cursor + match[0].length - 1
    };
  }
  return { found: false, groups: null, end: -1 };
};
findHtml_fn = function(lineToParse, cursor) {
  const check = lineToParse.substring(cursor);
  if (Utils.testRegex(check, REGEX.PARAGRAPH.HTML)) {
    const match = Utils.execRegex(check, REGEX.PARAGRAPH.HTML);
    return {
      found: true,
      groups: match.groups,
      end: cursor + match[0].length - 1
    };
  }
  return { found: false, groups: null, end: -1 };
};
findLinkRef_fn = function(lineToParse, cursor) {
  const check = lineToParse.substring(cursor);
  let withText = false;
  let match;
  if (Utils.testRegex(check, REGEX.PARAGRAPH.REF_LINK)) {
    if (Utils.testRegex(check, REGEX.LINK_REF.WITH_TEXT)) {
      withText = true;
      match = Utils.execRegex(check, REGEX.LINK_REF.WITH_TEXT);
    } else {
      match = Utils.execRegex(check, REGEX.LINK_REF.WITHOUT_TEXT);
    }
    return {
      found: true,
      withText,
      groups: match.groups,
      end: cursor + match[0].length - 1
    };
  }
  return { found: false, groups: null, end: -1 };
};
findImage_fn = function(lineToParse, cursor) {
  const check = lineToParse.substring(cursor);
  if (Utils.testRegex(check, REGEX.PARAGRAPH.IMAGE)) {
    const match = Utils.execRegex(check, REGEX.PARAGRAPH.IMAGE);
    return {
      found: true,
      groups: match.groups,
      end: cursor + match[0].length - 1
    };
  }
  return { found: false, groups: null, end: -1 };
};
findEmphasis_fn = function(lineToParse, linkRefs) {
  var _a, _b, _c, _d, _e, _f, _g, _h, _i, _j, _k, _l, _m, _n, _o;
  let identifier;
  const tokens = [];
  function runCheckForTextBeforeStart(start, cursor, ident) {
    const lastToken = tokens[tokens.length - 1];
    if (start > cursor + ident.length) {
      const text = lineToParse.substring(cursor, start - ident.length);
      if (lastToken && lastToken.type === TOKENS.TEXT) {
        lastToken.raw += text;
        lastToken.value += text;
      } else {
        tokens.push({
          type: TOKENS.TEXT,
          raw: text,
          value: text
        });
      }
    }
  }
  for (let cursor = 0; cursor < lineToParse.length; cursor++) {
    const currChar = lineToParse[cursor];
    const prevChar = lineToParse[cursor - 1] || null;
    const nextChar = lineToParse[cursor + 1] || null;
    const lastToken = tokens[tokens.length - 1];
    let escape = false;
    if (prevChar && prevChar === "\\") escape = true;
    if (!escape && (currChar === "*" || currChar === "_")) {
      identifier = Utils.findConsecutive(lineToParse, cursor, currChar);
      const { fence, ident, start, end } = __privateMethod(_a = _Paragraph, _Paragraph_static, isFenced_fn).call(_a, lineToParse, cursor, identifier);
      if (fence) {
        runCheckForTextBeforeStart(start, cursor, ident);
        const v = lineToParse.slice(start, end);
        tokens.push({
          type: ident.length % 2 === 0 ? TOKENS.BOLD : TOKENS.ITALIC,
          raw: `${ident}${v}${ident}`,
          tokens: __privateMethod(_b = _Paragraph, _Paragraph_static, findEmphasis_fn).call(_b, v, linkRefs)
        });
        cursor = end + ident.length - 1;
        continue;
      }
    } else if (!escape && currChar === "`") {
      identifier = Utils.findConsecutive(lineToParse, cursor, "`");
      const { fence, ident, start, end } = __privateMethod(_c = _Paragraph, _Paragraph_static, isFenced_fn).call(_c, lineToParse, cursor, identifier, true);
      if (fence) {
        const value = lineToParse.slice(start, end);
        if (value.length > 0) {
          tokens.push({
            type: TOKENS.CODE,
            raw: `${ident}${value}${ident}`,
            // TIP: no need to waste time escaping it again
            // because, the code token value is already escaped here
            value: value.trim()
          });
          cursor = end + ident.length - 1;
          continue;
        }
      }
    } else if (!escape && ["~", "+"].includes(currChar)) {
      if (nextChar && nextChar === currChar) {
        identifier = Utils.findConsecutive(lineToParse, cursor, currChar);
        const { fence, ident, start, end } = __privateMethod(_d = _Paragraph, _Paragraph_static, isFenced_fn).call(_d, lineToParse, cursor, identifier, false, true);
        if (fence) {
          runCheckForTextBeforeStart(start, cursor, ident);
          const v = lineToParse.slice(start, end);
          tokens.push({
            type: currChar === "+" ? TOKENS.UNDERLINE : TOKENS.STRIKE_THROUGH,
            raw: `${ident}${v}${ident}`,
            tokens: __privateMethod(_e = _Paragraph, _Paragraph_static, findEmphasis_fn).call(_e, v, linkRefs)
          });
          cursor = end + ident.length - 1;
          continue;
        }
      }
    } else if (!escape && currChar === "[") {
      const linkMatch = __privateMethod(_f = _Paragraph, _Paragraph_static, findLink_fn).call(_f, lineToParse, cursor);
      if (linkMatch.found) {
        tokens.push({
          type: TOKENS.LINK,
          raw: lineToParse.slice(cursor, linkMatch.end + 1),
          tokens: {
            title: {
              raw: linkMatch.groups.text,
              tokens: __privateMethod(_g = _Paragraph, _Paragraph_static, findEmphasis_fn).call(_g, linkMatch.groups.text, linkRefs)
            },
            href: linkMatch.groups.href,
            tooltip: linkMatch.groups.title
          }
        });
        cursor = linkMatch.end;
        continue;
      }
      if (linkRefs.length > 0) {
        const linkRefMatch = __privateMethod(_h = _Paragraph, _Paragraph_static, findLinkRef_fn).call(_h, lineToParse, cursor);
        if (linkRefMatch.found) {
          const ref = linkRefs.find((r) => r.text === linkRefMatch.groups.ref);
          if (ref) {
            const rawTitle = linkRefMatch.withText ? linkRefMatch.groups.text : ref.text;
            tokens.push({
              type: TOKENS.LINK,
              raw: lineToParse.slice(cursor, linkRefMatch.end + 1),
              tokens: {
                title: {
                  raw: rawTitle,
                  tokens: __privateMethod(_i = _Paragraph, _Paragraph_static, findEmphasis_fn).call(_i, rawTitle, linkRefs)
                },
                href: ref.href,
                tooltip: ref.title
              }
            });
            cursor = linkRefMatch.end;
            continue;
          }
        }
      }
    } else if (!escape && currChar === "!") {
      const imageMatch = __privateMethod(_j = _Paragraph, _Paragraph_static, findImage_fn).call(_j, lineToParse, cursor);
      if (imageMatch.found) {
        tokens.push({
          type: TOKENS.IMAGE,
          raw: lineToParse.slice(cursor, imageMatch.end + 1),
          tokens: imageMatch.groups
        });
        cursor = imageMatch.end;
        continue;
      }
    } else if (!escape && currChar === "<") {
      const htmlMatch = __privateMethod(_k = _Paragraph, _Paragraph_static, findHtml_fn).call(_k, lineToParse, cursor);
      if (htmlMatch.found) {
        tokens.push({
          type: TOKENS.HTML,
          raw: lineToParse.slice(cursor, htmlMatch.end + 1),
          tokens: {
            tag: ((_l = htmlMatch.groups) == null ? void 0 : _l.tag) || ((_m = htmlMatch.groups) == null ? void 0 : _m.endTag),
            attributes: (_n = htmlMatch.groups.attrs) == null ? void 0 : _n.trim(),
            isEndTag: !!((_o = htmlMatch.groups) == null ? void 0 : _o.endTag)
          }
        });
        cursor = htmlMatch.end;
        continue;
      }
    }
    if (lastToken && lastToken.type === TOKENS.TEXT) {
      lastToken.raw += currChar;
      lastToken.value += currChar;
    } else {
      tokens.push({
        type: TOKENS.TEXT,
        raw: currChar,
        value: currChar
      });
    }
  }
  return tokens;
};
__privateAdd(_Paragraph, _Paragraph_static);
__publicField(_Paragraph, "tokenName", TOKENS.PARAGRAPH);
var Paragraph = _Paragraph;
var _lines6, _endLine, _body4, _value;
var FrontMatter = class {
  constructor(lines) {
    __privateAdd(this, _lines6);
    __privateAdd(this, _endLine);
    __privateAdd(this, _body4);
    __privateAdd(this, _value, {});
    __privateSet(this, _lines6, lines);
    this.findEnd();
  }
  static test(lines) {
    if (Utils.testRegex(lines[0], REGEX.FRONT_MATTER.BOUNDARY)) {
      for (let i = 1; i < lines.length; i++) {
        const line = lines[i];
        if (Utils.testRegex(line, REGEX.FRONT_MATTER.BOUNDARY)) {
          return true;
        }
        if (!Utils.testRegex(line, REGEX.FRONT_MATTER.ENTRY)) {
          return false;
        }
      }
    }
    return false;
  }
  findEnd() {
    for (let i = 1; i < __privateGet(this, _lines6).length; i++) {
      if (Utils.testRegex(__privateGet(this, _lines6)[i], REGEX.FRONT_MATTER.BOUNDARY)) {
        __privateSet(this, _endLine, i + 1);
      }
    }
    __privateSet(this, _body4, __privateGet(this, _lines6).slice(1, __privateGet(this, _endLine) - 1));
  }
  removeFrontMatterFromGivenLines() {
    return __privateGet(this, _lines6).slice(__privateGet(this, _endLine) + 1);
  }
  getValue() {
    for (let i = 0; i < __privateGet(this, _body4).length; i++) {
      const line = __privateGet(this, _body4)[i];
      if (Utils.testRegex(line, REGEX.FRONT_MATTER.ENTRY)) {
        const match = Utils.execRegex(line, REGEX.FRONT_MATTER.ENTRY);
        if (match) {
          let keyValue = match.groups.value;
          if (["true", "false"].includes(keyValue.toLowerCase())) {
            keyValue = keyValue.toLowerCase() === "true";
          } else if (REGEX.NUMBER.test(keyValue)) {
            keyValue = parseInt(keyValue);
          } else if (REGEX.NUMBER_WITH_DECIMAL.test(keyValue)) {
            keyValue = parseFloat(keyValue);
          } else if (REGEX.BIG_BRACKETED.test(keyValue) || REGEX.CURLY_BRACKETED.test(keyValue)) {
            try {
              keyValue = JSON.parse(keyValue);
            } catch (e) {
            }
          }
          __privateGet(this, _value)[match.groups.key] = keyValue;
        }
      }
    }
    return __privateGet(this, _value);
  }
};
_lines6 = new WeakMap();
_endLine = new WeakMap();
_body4 = new WeakMap();
_value = new WeakMap();
__publicField(FrontMatter, "tokenName", TOKENS.FRONT_MATTER);
var Newline = class {
  static test({ line }) {
    if (typeof line !== "string") return false;
    return ["", "\n"].includes(line.trim());
  }
  /**
   * returns HTML for a newline
   *
   * @returns {string}
   */
  static parse() {
    return "<br>";
  }
};
__publicField(Newline, "tokenName", TOKENS.NEW_LINE);
var Parsers = {
  Table,
  Image,
  Comment,
  HrLine,
  CodeBlock,
  Quote,
  Heading,
  List,
  HTML,
  Paragraph
};
var _cursor7, _lines7, _lexerData, _currLine, _nextLine2, _currLineIndent, _currLineRawIndent, _lastLexerItem, _lexerLengthBefore, _fromToken2, _linkRefs3, _frontMatter, _config2, _Lexer_instances, runCurrLineLexer_fn, runNewLineLexer_fn, runHrLineLexer_fn, runCodeBlockLexer_fn, runTableLexer_fn, runHTMLLexer_fn, runListLexer_fn, runQuoteLexer_fn, runHeadingLexer_fn, runCommentLexer_fn, runImageLexer_fn, runParagraphLexer_fn, checkForLinkRefs_fn, runPrep_fn, skipFrontMatter_fn;
var Lexer = class {
  constructor(lines, { from = null, config = {} } = {}) {
    __privateAdd(this, _Lexer_instances);
    __privateAdd(this, _cursor7);
    __privateAdd(this, _lines7);
    __privateAdd(this, _lexerData);
    __privateAdd(this, _currLine);
    __privateAdd(this, _nextLine2);
    __privateAdd(this, _currLineIndent);
    __privateAdd(this, _currLineRawIndent);
    __privateAdd(this, _lastLexerItem);
    __privateAdd(this, _lexerLengthBefore);
    __privateAdd(this, _fromToken2);
    __privateAdd(this, _linkRefs3, []);
    __privateAdd(this, _frontMatter);
    __privateAdd(this, _config2);
    __privateSet(this, _lines7, lines);
    __privateSet(this, _lexerData, []);
    __privateSet(this, _fromToken2, from);
    __privateSet(this, _cursor7, 0);
    __privateSet(this, _config2, config);
  }
  getFrontMatter() {
    if (FrontMatter.test(__privateGet(this, _lines7))) {
      __privateSet(this, _frontMatter, new FrontMatter(__privateGet(this, _lines7)));
      return __privateGet(this, _frontMatter).getValue();
    } else {
      return {};
    }
  }
  run() {
    __privateMethod(this, _Lexer_instances, skipFrontMatter_fn).call(this);
    __privateMethod(this, _Lexer_instances, checkForLinkRefs_fn).call(this);
    for (__privateSet(this, _cursor7, 0); __privateGet(this, _cursor7) < __privateGet(this, _lines7).length; __privateWrapper(this, _cursor7)._++) {
      __privateMethod(this, _Lexer_instances, runPrep_fn).call(this);
      __privateMethod(this, _Lexer_instances, runCurrLineLexer_fn).call(this);
    }
    return __privateGet(this, _lexerData);
  }
};
_cursor7 = new WeakMap();
_lines7 = new WeakMap();
_lexerData = new WeakMap();
_currLine = new WeakMap();
_nextLine2 = new WeakMap();
_currLineIndent = new WeakMap();
_currLineRawIndent = new WeakMap();
_lastLexerItem = new WeakMap();
_lexerLengthBefore = new WeakMap();
_fromToken2 = new WeakMap();
_linkRefs3 = new WeakMap();
_frontMatter = new WeakMap();
_config2 = new WeakMap();
_Lexer_instances = new WeakSet();
runCurrLineLexer_fn = function() {
  const context = {
    line: __privateGet(this, _currLine),
    nextLine: __privateGet(this, _nextLine2),
    lines: __privateGet(this, _lines7),
    cursor: __privateGet(this, _cursor7),
    indent: __privateGet(this, _currLineIndent),
    lastLexer: __privateGet(this, _lastLexerItem),
    fromToken: __privateGet(this, _fromToken2)
  };
  if (Newline.test(context)) return __privateMethod(this, _Lexer_instances, runNewLineLexer_fn).call(this);
  if (Heading.test(context)) return __privateMethod(this, _Lexer_instances, runHeadingLexer_fn).call(this);
  if (HrLine.test(context)) return __privateMethod(this, _Lexer_instances, runHrLineLexer_fn).call(this);
  if (Comment.test(context)) return __privateMethod(this, _Lexer_instances, runCommentLexer_fn).call(this);
  if (Image.test(context)) return __privateMethod(this, _Lexer_instances, runImageLexer_fn).call(this);
  if (Quote.test(context)) return __privateMethod(this, _Lexer_instances, runQuoteLexer_fn).call(this);
  if (List.test(context)) return __privateMethod(this, _Lexer_instances, runListLexer_fn).call(this);
  if (Table.test(context)) return __privateMethod(this, _Lexer_instances, runTableLexer_fn).call(this);
  if (HTML.testBlock(context)) return __privateMethod(this, _Lexer_instances, runHTMLLexer_fn).call(this);
  if (CodeBlock.test(context)) return __privateMethod(this, _Lexer_instances, runCodeBlockLexer_fn).call(this);
  return __privateMethod(this, _Lexer_instances, runParagraphLexer_fn).call(this);
};
runNewLineLexer_fn = function() {
  if (__privateGet(this, _lexerLengthBefore) === 0) return true;
  if (__privateGet(this, _lastLexerItem).type !== TOKENS.NEW_LINE) {
    __privateGet(this, _lexerData).push({
      type: TOKENS.NEW_LINE
    });
  }
};
runHrLineLexer_fn = function() {
  __privateGet(this, _lexerData).push({
    type: TOKENS.HR_LINE
  });
};
runCodeBlockLexer_fn = function() {
  const cbTokenizer = new CodeBlock(
    __privateGet(this, _lines7),
    __privateGet(this, _cursor7),
    __privateGet(this, _currLineIndent),
    __privateGet(this, _currLineRawIndent)
  );
  const cbTokens = cbTokenizer.tokenize();
  __privateGet(this, _lexerData).push(cbTokens.lexer);
  __privateSet(this, _cursor7, cbTokens.cursor);
};
runTableLexer_fn = function() {
  const tableTokenizer = new Table(
    __privateGet(this, _lines7),
    __privateGet(this, _cursor7),
    __privateGet(this, _currLineIndent),
    __privateGet(this, _linkRefs3)
  );
  const tableTokens = tableTokenizer.tokenize();
  __privateGet(this, _lexerData).push(tableTokens.lexer);
  __privateSet(this, _cursor7, tableTokens.cursor);
};
runHTMLLexer_fn = function() {
  const htmlTokenizer = new HTML(
    __privateGet(this, _lines7),
    __privateGet(this, _cursor7),
    __privateGet(this, _currLineIndent),
    __privateGet(this, _linkRefs3)
  );
  const htmlTokens = htmlTokenizer.tokenize();
  __privateGet(this, _lexerData).push(htmlTokens.lexer);
  __privateSet(this, _cursor7, htmlTokens.cursor);
};
runListLexer_fn = function() {
  const list = new List(
    __privateGet(this, _lines7),
    __privateGet(this, _cursor7),
    __privateGet(this, _currLineIndent),
    __privateGet(this, _fromToken2)
  );
  const listTokens = list.tokenize();
  __privateSet(this, _cursor7, listTokens.cursor);
  if (List.compareIfTwoListLexerAreOfSameType(__privateGet(this, _lastLexerItem), listTokens, __privateGet(this, _currLineIndent))) {
    __privateGet(this, _lastLexerItem).items.push(listTokens.lexer);
    __privateGet(this, _lastLexerItem).raw += `
${listTokens.lexer.raw}`;
    return;
  }
  const lastLastLexerItem = __privateGet(this, _lexerData)[__privateGet(this, _lexerData).length - 2] || false;
  if (__privateGet(this, _lastLexerItem) && __privateGet(this, _lastLexerItem).type === TOKENS.NEW_LINE && List.compareIfTwoListLexerAreOfSameType(lastLastLexerItem, listTokens, __privateGet(this, _currLineIndent))) {
    __privateGet(this, _lexerData).pop();
    const lastLexerItem = __privateGet(this, _lexerData).at(-1);
    lastLexerItem.items.push(listTokens.lexer);
    lastLexerItem.raw += `
${listTokens.lexer.raw}`;
    return;
  }
  __privateGet(this, _lexerData).push({
    type: TOKENS.LIST,
    indent: __privateGet(this, _currLineIndent),
    meta: listTokens.meta,
    items: [listTokens.lexer],
    raw: listTokens.lexer.raw
  });
};
runQuoteLexer_fn = function() {
  const quoteTokenizer = new Quote(__privateGet(this, _lines7), __privateGet(this, _cursor7));
  const quoteTokens = quoteTokenizer.tokenize();
  __privateSet(this, _cursor7, quoteTokens.cursor);
  __privateGet(this, _lexerData).push({
    indent: __privateGet(this, _currLineIndent),
    ...quoteTokens.lexer
  });
};
runHeadingLexer_fn = function() {
  const hTokenizer = new Heading(__privateGet(this, _currLine), __privateGet(this, _nextLine2));
  const hTokens = hTokenizer.tokenize();
  if (hTokens.setext) {
    __privateWrapper(this, _cursor7)._++;
  }
  __privateGet(this, _lexerData).push({
    type: TOKENS.HEADING,
    indent: __privateGet(this, _currLineIndent),
    ...hTokens,
    tokens: Paragraph.tokenize(hTokens.value, __privateGet(this, _linkRefs3))
  });
};
runCommentLexer_fn = function() {
  __privateGet(this, _lexerData).push({
    type: TOKENS.COMMENT,
    indent: __privateGet(this, _currLineIndent),
    ...Comment.tokenize(__privateGet(this, _currLine)),
    raw: __privateGet(this, _currLine)
  });
};
runImageLexer_fn = function() {
  __privateGet(this, _lexerData).push({
    type: TOKENS.IMAGE,
    indent: __privateGet(this, _currLineIndent),
    ...Image.tokenize(__privateGet(this, _currLine)),
    raw: __privateGet(this, _currLine)
  });
};
runParagraphLexer_fn = function() {
  if (__privateGet(this, _lastLexerItem) && __privateGet(this, _lastLexerItem).type === TOKENS.PARAGRAPH && __privateGet(this, _currLineIndent) >= __privateGet(this, _lastLexerItem).indent) {
    if (__privateGet(this, _lastLexerItem).raw.endsWith("  ")) {
      __privateGet(this, _lastLexerItem).value = __privateGet(this, _lastLexerItem).value.trimEnd() + "<br>";
    }
    __privateGet(this, _lastLexerItem).raw += `
${__privateGet(this, _currLine)}`;
    __privateGet(this, _lastLexerItem).value += ` ${__privateGet(this, _currLine)}`;
    __privateGet(this, _lastLexerItem).tokens = Paragraph.tokenize(__privateGet(this, _lastLexerItem).value, __privateGet(this, _linkRefs3));
  } else {
    __privateGet(this, _lexerData).push({
      type: TOKENS.PARAGRAPH,
      indent: __privateGet(this, _currLineIndent),
      tokens: Paragraph.tokenize(__privateGet(this, _currLine), __privateGet(this, _linkRefs3)),
      raw: __privateGet(this, _currLine),
      value: __privateGet(this, _currLine)
    });
  }
};
checkForLinkRefs_fn = function() {
  for (__privateSet(this, _cursor7, 0); __privateGet(this, _cursor7) < __privateGet(this, _lines7).length; __privateWrapper(this, _cursor7)._++) {
    const line = __privateGet(this, _lines7)[__privateGet(this, _cursor7)];
    if (Utils.testRegex(line, REGEX.LINK_REF.DECLARATION)) {
      __privateGet(this, _linkRefs3).push(Utils.execRegex(line, REGEX.LINK_REF.DECLARATION).groups);
      __privateGet(this, _lines7).splice(__privateGet(this, _cursor7), 1);
      __privateWrapper(this, _cursor7)._--;
    }
  }
};
runPrep_fn = function() {
  __privateSet(this, _currLine, __privateGet(this, _lines7)[__privateGet(this, _cursor7)]);
  __privateSet(this, _nextLine2, __privateGet(this, _lines7)[__privateGet(this, _cursor7) + 1]);
  __privateSet(this, _lexerLengthBefore, __privateGet(this, _lexerData).length);
  __privateSet(this, _lastLexerItem, __privateGet(this, _lexerData)[__privateGet(this, _lexerLengthBefore) - 1] || null);
  __privateSet(this, _currLineRawIndent, Indent.raw(__privateGet(this, _currLine)));
  __privateSet(this, _currLineIndent, Indent.calc(__privateGet(this, _currLineRawIndent)));
};
skipFrontMatter_fn = function() {
  if (FrontMatter.test(__privateGet(this, _lines7))) {
    __privateSet(this, _frontMatter, new FrontMatter(__privateGet(this, _lines7)));
    __privateSet(this, _lines7, __privateGet(this, _frontMatter).removeFrontMatterFromGivenLines());
    __privateSet(this, _cursor7, 0);
  }
};
var HtmlMark = class {
  constructor(config = {}) {
    __publicField(this, "config", {});
    this.config.indent = config.indent || 4;
    this.config.highlightFn = config.highlightFn || null;
    this.config.useLinkRefs = config.useLinkRefs || false;
  }
  tokenize(str) {
    if (typeof str !== "string") throw new Error("Input must be a string");
    const lexer = new Lexer(str.split("\n"), { config: this.config });
    return lexer.run();
  }
  parse(str) {
    if (typeof str !== "string") throw new Error("Input must be a string");
    const lex = this.tokenize(str);
    const parser = new Parser(lex, { config: this.config });
    return parser.run();
  }
  getFrontMatter(str) {
    if (typeof str !== "string") throw new Error("Input must be a string");
    const lexer = new Lexer(str.split("\n"));
    return lexer.getFrontMatter();
  }
};
export {
  HtmlMark
};
//# sourceMappingURL=htmlmark.js.map
