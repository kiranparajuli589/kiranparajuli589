{
  "version": 3,
  "sources": ["../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/regex/index.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/util/utils.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/util/esc.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/util/tokens.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/util/indent.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/table.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/image.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/comment.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/hrLine.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/codeblock.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/parser/index.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/quote.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/heading.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/list.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/html.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/paragraph.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/frontMatter.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/newline.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/tokenizer/index.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/lexer/index.js", "../../.pnpm/htmlmark@0.1.3/node_modules/htmlmark/lib/index.js"],
  "sourcesContent": ["export const REGEX = {\n\tHR_LINE: /^\\s*[-+*](?:(?:\\s[-+*]){2,}|[-+*]{2,})$/g,\n\tQUOTE: {\n\t\tITEM: /^\\s*(?:>\\s*)+(?<value>.+)/g,\n\t\tEMPTY: /^\\s*[>\\s]+$/g,\n\t\tCOUNT: />/g,\n\t\tNON_QUOTE: /[^>\\s\\t]/\n\t},\n\tCOMMENT: /^\\s*<!-{2}\\s(?<value>.+)\\s-{2}>/g,\n\tIMAGE: /^\\s*!\\[(?<alt>.+)]\\((?<url>.+)\\)/g,\n\tHEADING: {\n\t\tITEM: /^\\s*(?<level>#{1,6})\\s+((?<fenceVal>.+)(?=\\s+#+\\s*$)|(?<val>.+))/g,\n\t\tUNDERLINE_1: /^\\s*=+$/g,\n\t\tUNDERLINE_2: /^\\s*-+$/g\n\t},\n\tCODE_BLOCK: /^\\s*`{3}\\s*(?<lang>[a-z]*)$/g,\n\tLIST: {\n\t\tCHECKBOX: /^\\s*(?:[-~*]|\\d+\\.)\\s\\[(?<check>\\s|x)]\\s(?<value>.+)/g,\n\t\tUNORDERED: /^\\s*(?<mark>[-*+])\\s(?<value>.+)/g,\n\t\tORDERED: /^\\s*(?<count>\\d)\\.\\s(?<value>.+)/g,\n\t\tITEM: /^\\s*(?:(?<mark>[-*+])|(?<count>\\d+)\\.)\\s+(\\[(?<check>\\s|x)]\\s+)?(?<value>.+)/g,\n\t\tEMPTY: /^\\s*(?<mark>[-*+]|(?<count>\\d+)\\.)(\\s\\[(?<check>(\\s|x))]\\s*|\\s*)$/g\n\t},\n\tPARAGRAPH: {\n\t\tLINK: /^\\[(?<text>.+?)]\\((?<href>\\S+)(?:\\s['\"](?<title>.+)['\"])?\\)/,\n\t\tREF_LINK: /^((?<!!)\\[.+?](?!\\(.+\\))){1,2}/,\n\t\tHTML: /^\\s*<\\/(?<endTag>\\w+)>|^\\s*<(?<tag>\\w+)(?<attrs>\\s\\w+(=\\\\?['\"].+?['\"])?)?>/,\n\t\t// eslint-disable-next-line no-useless-escape\n\t\tCOMPUTED_HTML: \"<(?<tag>%s)(?<attrs>\\s\\w+=\\\\?['\\\"].+?['\\\"])?>(?<content>.+)<\\/%s>\",\n\t\tIMAGE: /^!\\[(?<alt>.+)]\\((?<href>\\S+)(?:\\s'(?<title>[^']+)'(\\s(?<width>\\d+)(\\s(?<height>\\d+))?)?)?\\)/\n\t},\n\tHTML: /^\\s*<(?<tag>\\w+)(?<attrs>\\s\\w+=\\\\?['\"].+?['\"])?>(?<content>.?)/g,\n\tLINK_REF: {\n\t\tDECLARATION: /\\s*\\[(?<text>.+)]:\\s+(?<href>\\S+(?:\\s'(?<title>.+?)')?)/g,\n\t\tWITH_TEXT: /^(?<!!)\\[(?<text>.+?)](?!\\(.+\\))(?<!!)\\[(?<ref>.+?)](?!\\(.+\\))/,\n\t\tWITHOUT_TEXT: /^(?<!!)\\[(?<ref>.+?)](?!\\(.+\\))/\n\t},\n\tTABLE: {\n\t\tROW: /^\\s*(?<!\\\\)\\|(?=(?:.+(?<!\\\\)\\|)+$)|(?!^)(?<cell>.+?)(?<!\\\\)\\|/gy,\n\t\t/**\n\t\t * @example |----|-----|------|\n\t\t */\n\t\tDASH_LINE: /^\\s*\\|(?=(?:-{2,}\\|)+$)|(?!^)(?<cell>-{2,})\\|/gy,\n\t\t/**\n\t\t * @example | --- | --- | --- |\n\t\t */\n\t\tS_DASH_LINE: /^\\s*\\|(?=(?:\\s-{2,}\\s\\|)+$)|(?!^)(?<cell>\\s-{2,})\\s\\|/gy,\n\t\t/**\n\t\t * @example |:----:|:----:|:----:|\n\t\t */\n\t\tCOLON_LINE: /^\\s*\\|(?=(?::-{2,}:\\|)+$)|(?!^):(?<cell>-{2,}):\\|/gy,\n\t\t/**\n\t\t * @example | :---: | :---: | :---: |\n\t\t */\n\t\tS_COLON_LINE: /^\\s*\\|(?=(?:\\s:-{2,}:\\s\\|)+$)|\\s(?!^):(?<cell>-{2,}):\\s\\|/gy,\n\t\tCELL: /(?<!\\\\)(\\|)/g\n\t},\n\tESC: {\n\t\tGT: /(?<!<\\/?\\w[^<>]*)>/g,\n\t\tLT: /<(?!([a-z/1-6]+>))/g\n\t},\n\tESCAPED: /\\\\([*_[\\]()!~+\\\\|`#><])/g,\n\tFRONT_MATTER: {\n\t\tBOUNDARY: /^-{3}\\s*$/,\n\t\tENTRY: /^\\s*(?<key>\\w+):\\s*(?<value>.*)$/\n\t},\n\tNUMBER: /^\\d+$/,\n\tNUMBER_WITH_DECIMAL: /^\\d+\\.\\d+$/,\n\tBIG_BRACKETED: /^\\[.*]$/,\n\tCURLY_BRACKETED: /^\\{.*}$/\n}\n", "/**\n * Utilities Store for the Parser\n */\nexport class Utils {\n\t/**\n\t * Checks if the given text matches the given regex\n\t *\n\t * @param {string} text\n\t * @param {RegExp} regex\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic testRegex(text, regex) {\n\t\tregex.lastIndex = 0\n\t\treturn !!regex.test(text)\n\t}\n\n\t/**\n\t * Returns the regex matches for the given text\n\t *\n\t * @param {string} text\n\t * @param {RegExp} regex\n\t * @returns {RegExpExecArray}\n\t */\n\tstatic execRegex(text, regex) {\n\t\tregex.lastIndex = 0\n\t\treturn regex.exec(text)\n\t}\n\n\t/**\n\t * Match the given text against the given regex\n\t *\n\t * @param {string} text\n\t * @param {RegExp} regex\n\t *\n\t * @returns {*[]}\n\t */\n\tstatic matchRegex(text, regex) {\n\t\tlet m\n\t\tconst matches = []\n\n\t\twhile ((m = regex.exec(text)) !== null) {\n\t\t\tif (m.index === regex.lastIndex) {\n\t\t\t\tregex.lastIndex++\n\t\t\t}\n\n\t\t\tconst rGroups = Object.keys(m.groups)\n\n\t\t\tm.forEach((match, groupIndex) => {\n\t\t\t\tif (match && groupIndex !== 0) {\n\t\t\t\t\tmatches.push({\n\t\t\t\t\t\ttype: rGroups[groupIndex - 1],\n\t\t\t\t\t\tvalue: match\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t})\n\t\t}\n\t\treturn matches\n\t}\n\n\t/**\n\t * Groups the given array of objects by the given key\n\t *\n\t * @param {Object[]} array - Array of objects to group\n\t * @param {string} key - Key to group by\n\t *\n\t * @returns {Object[]} - Grouped array of objects\n\t */\n\tstatic groupBy(array, key) {\n\t\tconst grouped = []\n\t\tarray.forEach((item, index) => {\n\t\t\tif (index === 0) {\n\t\t\t\tgrouped.push(item)\n\t\t\t} else {\n\t\t\t\tconst last = grouped[grouped.length - 1]\n\t\t\t\tif (last[key] === item[key]) {\n\t\t\t\t\tlast.value += item.value\n\t\t\t\t} else {\n\t\t\t\t\tgrouped.push(item)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t\treturn grouped\n\t}\n\n\t/**\n\t *\n\t * @param {string} text\n\t * @param {RegExp} regex\n\t * @returns {{type: string, value: string}[]}\n\t */\n\tstatic matchRG(text, regex) {\n\t\tconst matches = Utils.matchRegex(text, regex)\n\n\t\treturn Utils.groupBy(matches, \"type\")\n\t}\n\n\t/**\n\t * Returns the index of the nth occurrence of the given character in the given text\n\t * If the nth occurrence is not found, -1 is returned\n\t *\n\t * @param {string} text - Text to search in\n\t * @param {number} position - Position of the nth occurrence\n\t * @param {string} delimiter - Character to search for\n\t *\n\t * @returns {number}\n\t */\n\tstatic getNthIndex(text, position, delimiter = \">\") {\n\t\tlet count = 0\n\t\tfor (let i = 0; i < text.length; i++) {\n\t\t\tif (text[i] === delimiter) {\n\t\t\t\tcount++\n\t\t\t\tif (count === position) {\n\t\t\t\t\treturn i\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn -1\n\t}\n\t/**\n\t * Finds number of consecutive characters in a string from a given index\n\t *\n\t * @param {String} str - String to search\n\t * @param {Number} cursor - Index to start from\n\t * @param {string} char - Character to search for\n\t *\n\t * @returns {String}\n\t */\n\tstatic findConsecutive(str, cursor, char) {\n\t\tlet consecutive = 0\n\t\tfor (let i=cursor; i<str.length; i++) {\n\t\t\tif (str[i] === char) {\n\t\t\t\tconsecutive++\n\t\t\t} else {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\treturn char.repeat(consecutive)\n\t}\n\t/**\n\t * Checks if the provided string contains an exact match for the provided identifier\n\t *\n\t * Generates regex like: /(?<![\\\\*])\\*{2}(?!\\*)/ for \"**\" as identifier\n\t *\n\t * Returns the index of the found identifier, or -1 if not found\n\t *\n\t * @param {String} str\n\t * @param {String} identifier\n\t *\n\t * @returns {Number}\n\t */\n\tstatic isExactMatch(str, identifier) {\n\t\tconst count = identifier.length\n\t\tconst iChar = identifier[0]\n\n\t\tconst exactRegex = new RegExp(\"(?<![\\\\\\\\\" +\n\t\t\t`${iChar}` +\n\t\t\t\"])\\\\\" +\n\t\t\t`${iChar}` +\n\t\t\t`{${count}}` +\n\t\t\t\"(?!\\\\\" +\n\t\t\t`${iChar}` +\n\t\t\t\")\")\n\n\t\treturn str.search(exactRegex)\n\t}\n\n\t/**\n\t * Checks if the provided string contains an loose match for the provided identifier\n\t *\n\t * Generates regex like: /(?<!\\\\)\\*{2}/ where * is the identifier\n\t *\n\t * Returns the index of the found identifier, or -1 if not found\n\t *\n\t * @param {String} str\n\t * @param {String} identifier\n\t *\n\t * @returns {Number}\n\t */\n\tstatic isLooseMatch(str, identifier) {\n\t\tconst iChar = identifier[0]\n\t\tconst count = identifier.length\n\n\t\tconst regex = new RegExp(\n\t\t\t`(?<![\\\\\\\\${iChar}])` +\n\t\t\t`\\\\${iChar}` +\n\t\t\t`{${count}}`\n\t\t)\n\t\treturn str.search(regex)\n\t}\n}\n", "import { REGEX } from \"../regex/index.js\"\nimport { Utils } from \"./utils.js\"\n\n\nexport class Esc {\n\tstatic nonTags(str) {\n\t\tif (!str) return str\n\t\treturn str\n\t\t\t.replaceAll(\"&\", \"&amp;\")\n\t\t\t.replaceAll(REGEX.ESC.LT, \"&lt;\")\n\t\t\t.replaceAll(REGEX.ESC.GT, \"&gt;\")\n\t\t\t.replaceAll(\"\\\"\", \"&quot;\")\n\t\t\t.replaceAll(\"'\", \"&#39;\")\n\t}\n\n\tstatic everything(str) {\n\t\tif (!str) return str\n\t\treturn str\n\t\t\t.replaceAll(\"&\", \"&amp;\")\n\t\t\t.replaceAll(\">\", \"&gt;\")\n\t\t\t.replaceAll(\"<\", \"&lt;\")\n\t\t\t.replaceAll(\"\\\"\", \"&quot;\")\n\t\t\t.replaceAll(\"'\", \"&#39;\")\n\t}\n\n\tstatic decode(str) {\n\t\tif (!str) return str\n\t\treturn str\n\t\t\t.replaceAll(\"&amp;\", \"&\")\n\t\t\t.replaceAll(\"&gt;\", \">\")\n\t\t\t.replaceAll(\"&lt;\", \"<\")\n\t\t\t.replaceAll(\"&quot;\", \"\\\"\")\n\t\t\t.replaceAll(\"&#39;\", \"'\")\n\t}\n\n\tstatic unEscape(str) {\n\t\tif (!str) return str\n\t\tif (Utils.testRegex(str, REGEX.ESCAPED)) {\n\t\t\tstr = str.replaceAll(REGEX.ESCAPED, \"$1\")\n\t\t}\n\t\treturn str\n\t}\n}\n", "export const TOKENS = {\n\tNEW_LINE: \"new-line\",\n\tPARAGRAPH: \"paragraph\",\n\tCODE_BLOCK: \"code-block\",\n\tCOMMENT: \"comment\",\n\tIMAGE: \"image\",\n\tQUOTE: \"quote\",\n\tBOLD: \"bold\",\n\tITALIC: \"italic\",\n\tUNDERLINE: \"underline\",\n\tSTRIKE_THROUGH: \"strike-through\",\n\tCODE: \"code\",\n\tLINK: \"link\",\n\tLIST: \"list\",\n\tLIST_ITEM: \"list-item\",\n\tCOUNT_ITEM: \"count-item\",\n\tCHECK_ITEM: \"check-item\",\n\tHEADING: \"heading\",\n\tTEXT: \"text\",\n\tHR_LINE: \"hr-line\",\n\tTABLE: \"table\", UNORDERED_ITEM: \"unordered\",\n\tORDERED_ITEM: \"ordered\",\n\tQUOTE_SEPARATOR: \"q-sep\",\n\tLINES: \"lines\",\n\tHTML: \"html\",\n\tFRONT_MATTER: \"front-matter\"\n}\n", "/**\n * checks if number is in the given range\n * @param {number} a\n * @param {number} b\n * @returns {boolean}\n */\nNumber.prototype.inRange = function (a, b) {\n\treturn this >= a && this <= b\n}\n\nconst INDENT_SIZE = 2\n\n\n/**\n * Markdown Indentation\n */\nexport class Indent {\n\t/**\n\t * returns the indentation count of the given text\n\t *\n\t * @param {string} text\n\t *\n\t * @returns {number}\n\t */\n\tstatic raw(text) {\n\t\tif ([\"\", \"\\n\", undefined].includes(text)) return 0\n\t\tlet count = 0\n\t\twhile (text[count] === \" \" || text[count] === \"\\t\") {\n\t\t\tcount++\n\t\t}\n\t\treturn count\n\t}\n\n\t/**\n\t * calculates the indentation of the given value\n\t *\n\t * @param {number} rawIndent\n\t *\n\t * @returns {number}\n\t */\n\tstatic calc(rawIndent) {\n\t\treturn Math.floor(rawIndent / INDENT_SIZE) * INDENT_SIZE\n\t}\n\n\t/**\n\t * returns the calculated indentation of the given text\n\t *\n\t * @param {string} text\n\t *\n\t * @returns {number}\n\t */\n\tstatic get(text) {\n\t\treturn this.calc(this.raw(text))\n\t}\n\n\t/**\n\t * returns if in the range of the given indentation\n\t *\n\t * @param {number} test the indentation to test\n\t * @param {number} indent the indentation to test against\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic inRange(test, indent) {\n\t\treturn test.inRange(\n\t\t\t(indent-INDENT_SIZE < 0) ? 0 : indent-INDENT_SIZE,\n\t\t\tindent+INDENT_SIZE\n\t\t)\n\t}\n}\n", "import { REGEX } from \"../regex/index.js\"\nimport { TOKENS, Indent, Utils } from \"../util/index.js\"\nimport { Paragraph } from \"./index.js\"\n\n/**\n * Table Tokenizer\n */\nexport class Table {\n\t#lines\n\t#start\n\t#cursor\n\t#indent\n\t#cellCount\n\t#rows = []\n\t#lex\n\t#linkRefs\n\t#withHeading\n\n\tstatic tokenName = TOKENS.TABLE\n\n\t/**\n\t * Checks if the given text matches the Table Row regex\n\t *\n\t * @param {String} text - Text to check\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic #testRow(text) {\n\t\treturn Utils.testRegex(text, REGEX.TABLE.ROW)\n\t\t\t&& !(\n\t\t\t\tUtils.testRegex(text, REGEX.TABLE.DASH_LINE) ||\n\t\t\t\tUtils.testRegex(text, REGEX.TABLE.COLON_LINE) ||\n\t\t\t\tUtils.testRegex(text, REGEX.TABLE.S_DASH_LINE) ||\n\t\t\t\tUtils.testRegex(text, REGEX.TABLE.S_COLON_LINE)\n\t\t\t)\n\t}\n\n\t/**\n\t * Returns the number of cells in a row\n\t *\n\t * @param {string} text - Line to check\n\t *\n\t * @returns {number}\n\t */\n\tstatic #getCellCount(text) {\n\t\treturn (text.match(REGEX.TABLE.CELL) || []).length\n\t}\n\n\t/**\n\t * check if line is a table 'heading - body' separator\n\t *\n\t * @param {string} text\n\t * @param {number} count\n\t * @param {number} indent\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic #isHBSep(text, count, indent) {\n\t\treturn Indent.get(text) === indent &&\n\t\t\t(\n\t\t\t\tUtils.testRegex(text, REGEX.TABLE.DASH_LINE) ||\n\t\t\t\tUtils.testRegex(text, REGEX.TABLE.COLON_LINE) ||\n\t\t\t\tUtils.testRegex(text, REGEX.TABLE.S_DASH_LINE) ||\n\t\t\t\tUtils.testRegex(text, REGEX.TABLE.S_COLON_LINE)\n\t\t\t) &&\n\t\t\tTable.#getCellCount(text) === count\n\t}\n\n\t/**\n\t * Checks if the given line is a row of the table\n\t *\n\t * @param {string} text - Line to check\n\t * @param {Number} count - Number of cells in the row\n\t * @param {Number} indent - Indentation of the line\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic #isRow(text, count, indent) {\n\t\treturn Indent.get(text) === indent &&\n\t\t\tTable.#testRow(text) &&\n\t\t\tTable.#getCellCount(text) === count &&\n\t\t\t!Table.#isHBSep(text, count, indent)\n\t}\n\n\t/**\n\t * Tokenizes a cell of the table\n\t *\n\t * @param {String} row - Row to tokenize\n\t * @param {Array} linkRefs\n\t *\n\t * @returns {{raw: String, value: String}[]}\n\t */\n\tstatic #tokenizeCell(row, linkRefs) {\n\t\tconst strippedRow = row.trim().slice(1, -1)\n\t\tconst rawCells = strippedRow.split(REGEX.TABLE.CELL)\n\n\t\tconst cells = []\n\n\t\trawCells.forEach(cell => {\n\t\t\tif (cell === \"|\") return\n\t\t\tcells.push({\n\t\t\t\traw: cell,\n\t\t\t\ttokens: Paragraph.tokenize(cell.trim(), linkRefs)\n\t\t\t})\n\t\t})\n\n\t\treturn cells\n\t}\n\n\t/**\n\t * Checks if the lines from the given cursor contains a table\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic test({ lines, cursor, indent }) {\n\t\tconst lineToParse = lines[cursor]\n\n\t\tif (!Table.#testRow(lineToParse)) return false\n\n\t\tconst cellCount = this.#getCellCount(lineToParse)\n\t\tlet nextLine = lines[cursor + 1]\n\t\tlet nextNextLine = lines[cursor + 2]\n\n\t\tif (nextLine !== undefined) {\n\t\t\tnextLine = nextLine.trimEnd()\n\t\t\tnextNextLine = nextNextLine?.trimEnd()\n\n\t\t\tif (\n\t\t\t\t(\n\t\t\t\t\tnextNextLine\n\t\t\t\t\t&& Table.#isHBSep(nextLine, cellCount, indent)\n\t\t\t\t\t&& Table.#isRow(nextNextLine, cellCount, indent)\n\t\t\t\t)\n\t\t\t\t|| Table.#isRow(nextLine, cellCount, indent)\n\t\t\t) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t\treturn false\n\t}\n\n\t/**\n\t * Runs checks to find the actual end of the table\n\t */\n\t#findEnd() {\n\t\t// now the line at the cursor is the first line of the table\n\t\t// first we determine if the second line is a table heading/body separator or not\n\t\t// if it is, then we know that the table has a heading\n\t\t// if it is not, then we know that the table does not have a heading\n\n\t\tthis.#cursor += 1\n\t\tif (Table.#isHBSep(this.#lines[this.#cursor], this.#cellCount, this.#indent)) {\n\t\t\tthis.#cursor += 2\n\t\t\tthis.#withHeading = true\n\t\t}\n\n\t\twhile (\n\t\t\tthis.#lines[this.#cursor] !== undefined &&\n\t\t\tTable.#isRow(this.#lines[this.#cursor], this.#cellCount, this.#indent)\n\t\t) {\n\t\t\tthis.#cursor++\n\t\t}\n\t\tthis.#lex[\"withHeading\"] = this.#withHeading\n\t}\n\n\t/**\n\t * Table Tokenizer Constructor\n\t *\n\t * @param {String[]} lines\n\t * @param {Number} cursor\n\t * @param {Number} indent\n\t * @param {Array} linkRefs\n\t *\n\t * @returns {Table}\n\t */\n\tconstructor(lines, cursor, indent, linkRefs) {\n\t\tthis.#lines = lines\n\t\tthis.#cursor = cursor\n\t\tthis.#start = cursor\n\t\tthis.#indent = indent\n\t\tthis.#linkRefs = linkRefs\n\t\tthis.#cellCount = Table.#getCellCount(this.#lines[this.#cursor])\n\t\tthis.#lex = { type: TOKENS.TABLE, indent: this.#indent, rows: [] }\n\t\tthis.#withHeading = false\n\t}\n\n\t/**\n\t * Set the rows of the table to the #rows array\n\t */\n\t#setRows() {\n\t\tconst headingLine = this.#lines[this.#start]\n\n\t\tif (this.#withHeading) {\n\t\t\tthis.#rows = (this.#cursor === this.#start + 3)\n\t\t\t\t? [headingLine, this.#lines[this.#start + 2]]\n\t\t\t\t: [...[headingLine], ...this.#lines.slice(this.#start + 2, this.#cursor)]\n\t\t} else {\n\t\t\tthis.#rows = this.#lines.slice(this.#start, this.#cursor)\n\t\t}\n\t}\n\n\t/**\n\t * Tokenizes cells for each table rows\n\t */\n\t#performDeepLex() {\n\t\tthis.#rows.forEach(row => {\n\t\t\tthis.#lex.rows.push(Table.#tokenizeCell(row, this.#linkRefs))\n\t\t})\n\t}\n\n\t/**\n\t * Tokenizes the lines for the Table token\n\t *\n\t * @returns {{cursor: number, lexer: {indent, type: string, rows: *[]}}}\n\t */\n\ttokenize() {\n\t\tthis.#findEnd()\n\n\t\tthis.#setRows()\n\n\t\tthis.#performDeepLex()\n\n\t\treturn { lexer: this.#lex, cursor: this.#cursor - 1 }\n\t}\n\n\t/**\n\t * Runs the HTML parsing for the Table token\n\t *\n\t * @param {Object} lexer - the Table lexer\n\t *\n\t * @returns {string} - the Table HTML\n\t */\n\tstatic parse(lexer) {\n\t\tlet tHeadingHtml, tBody\n\t\tif (lexer.withHeading) {\n\t\t\tconst tHeading = lexer.rows[0]\n\t\t\ttHeadingHtml = `<th>${tHeading.map(t => Paragraph.parse(t)).join(\"</th><th>\")}</th>`\n\t\t\ttBody = lexer.rows.slice(1)\n\t\t} else {\n\t\t\ttBody = lexer.rows\n\t\t}\n\t\tconst tBodyHtml = tBody.map(row => `<tr><td>${row.map(cell => Paragraph.parse(cell)).join(\"</td><td>\")}</td></tr>`).join(\"\")\n\t\treturn `<table>${tHeadingHtml ? `<thead><tr>\n    ${tHeadingHtml}\n  </tr></thead>` : \"\"}\n  <tbody>\n    ${tBodyHtml}\n  </tbody>\n</table>`\n\t}\n}\n", "import { REGEX } from \"../regex/index.js\"\nimport { TOKENS, Esc, Utils } from \"../util/index.js\"\n\n\nexport class Image {\n\tstatic tokenName = TOKENS.IMAGE\n\n\t/**\n\t * @returns {boolean}\n\t */\n\tstatic test({ line }) {\n\t\treturn Utils.testRegex(line, REGEX.IMAGE)\n\t}\n\n\t/**\n\t * @param {string} text\n\t *\n\t * @returns {RegExpExecArray}\n\t */\n\tstatic match(text) {\n\t\treturn Utils.execRegex(text.trim(), REGEX.IMAGE)\n\t}\n\n\t/**\n\t * @param {string} text\n\t *\n\t * @returns {{[p: string]: string}}\n\t */\n\tstatic tokenize(text) {\n\t\treturn Image.match(text).groups\n\t}\n\n\t/**\n\t * returns HTML for image\n\t * @param {{url: string, alt: string}} lexer\n\t * @returns {string}\n\t */\n\tstatic parse(lexer) {\n\t\treturn `<img src='${lexer.url}' alt='${Esc.nonTags(lexer.alt)}'>`\n\t}\n}\n", "import { REGEX } from \"../regex/index.js\"\nimport { Utils, TOKENS } from \"../util/index.js\"\n\n\nexport class Comment {\n\tstatic tokenName = TOKENS.COMMENT\n\n\t/**\n\t * @returns {boolean}\n\t */\n\tstatic test({ line }) {\n\t\treturn Utils.testRegex(line, REGEX.COMMENT)\n\t}\n\t/**\n\t * @param {string} text\n\t *\n\t * @returns {RegExpExecArray}\n\t */\n\tstatic match(text) {\n\t\treturn Utils.execRegex(text.trim(), REGEX.COMMENT)\n\t}\n\n\t/**\n\t * @param {string} text\n\t *\n\t * @returns {{[p: string]: string}}\n\t */\n\tstatic tokenize(text) {\n\t\treturn Comment.match(text).groups\n\t}\n\n\t/**\n\t * returns HTML for comment\n\t *\n\t * @param {{value: string}} lexer\n\t *\n\t * @returns {string}\n\t */\n\tstatic parse(lexer) {\n\t\treturn `<!-- ${lexer.value}-->`\n\t}\n}\n", "import { REGEX } from \"../regex/index.js\"\nimport { Utils, TOKENS } from \"../util/index.js\"\n\n/**\n * Horizontal Line\n */\nexport class HrLine {\n\tstatic tokenName = TOKENS.HR_LINE\n\n\t/**\n\t * @returns {boolean}\n\t */\n\tstatic test({ line }) {\n\t\treturn Utils.testRegex(line, REGEX.HR_LINE)\n\t}\n\n\t/**\n\t * returns HTML for horizontal line\n\t *\n\t * @returns {string}\n\t */\n\tstatic parse() {\n\t\treturn \"<hr>\"\n\t}\n}\n", "import { REGEX } from \"../regex/index.js\"\nimport { Indent, TOKENS, Utils, Esc } from \"../util/index.js\"\n\n\nexport class CodeBlock {\n\t#lines\n\t#start\n\t#cursor\n\t#indent\n\t#rawIndent\n\t#withBraces\n\t#lang\n\t#body\n\t#raw\n\t#isBroken = false\n\n\tstatic tokenName = TOKENS.CODE_BLOCK\n\n\t/**\n\t * Checks if the given text is of the CodeBlock type\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic test({ line, indent, fromToken, lastLexer }) {\n\t\tif (\n\t\t\t!fromToken &&\n\t\t\tindent >= 4 &&\n\t\t\t(!lastLexer || lastLexer.type === TOKENS.NEW_LINE)\n\t\t) {\n\t\t\treturn true\n\t\t}\n\n\t\t// under deep condition inside list item\n\t\t// cb needs to be indented at least twice\n\t\tif (\n\t\t\tfromToken === TOKENS.LIST_ITEM && indent >= 8 &&\n\t\t\t(!lastLexer || lastLexer?.type === TOKENS.NEW_LINE)\n\t\t) {\n\t\t\treturn true\n\t\t}\n\n\n\t\t// under deep condition inside quote\n\t\t// cb needs regular indentation\n\n\t\tif (\n\t\t\tfromToken === TOKENS.QUOTE && indent >= 4 &&\n\t\t\t(!lastLexer || lastLexer?.type === TOKENS.NEW_LINE)\n\t\t) {\n\t\t\treturn true\n\t\t}\n\n\t\treturn CodeBlock.testRegex(line)\n\t}\n\n\t/**\n\t * Checks if the given string matches the CodeBlock regex\n\t *\n\t * @param {String} text - Text to be checked\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic testRegex(text) {\n\t\treturn Utils.testRegex(text.trimEnd(), REGEX.CODE_BLOCK)\n\t}\n\n\t/**\n\t * Returns the CodeBlock regex match for the given text\n\t *\n\t * @param {String} text - Text to be checked\n\t *\n\t * @returns {RegExpExecArray}\n\t */\n\tstatic matchRegex(text) {\n\t\treturn Utils.execRegex(text.trimEnd(), REGEX.CODE_BLOCK)\n\t}\n\n\t/**\n\t * The CodeBlock Tokenizer Constructor\n\t *\n\t * @param {String[]} lines - Lines of the text\n\t * @param {Number} cursor - Cursor position to start from\n\t * @param {Number} indent - Calculated Indent of the text\n\t * @param {Number} rawIndent - Raw indent of the text\n\t *\n\t * @returns {CodeBlock}\n\t */\n\tconstructor(lines, cursor, indent, rawIndent) {\n\t\tthis.#lines = lines\n\t\tthis.#cursor = cursor\n\t\tthis.#start = cursor\n\t\tthis.#indent = indent\n\t\tthis.#rawIndent = rawIndent\n\t\tthis.#withBraces = CodeBlock.testRegex(lines[cursor])\n\t\tthis.#lang = CodeBlock.matchRegex(lines[cursor])?.groups?.lang || null\n\t}\n\n\t/**\n\t * Finds the end of the CodeBlock\n\t *\n\t * Checks if the CodeBlock is broken or not\n\t */\n\t#findEnd() {\n\t\tlet nextLine, nextLineIndent, nextLineMatch, isNextLineClosingOne\n\n\t\tdo {\n\t\t\tnextLine = this.#lines[++this.#cursor]\n\t\t\tif (nextLine === \"\") {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tnextLineIndent = (nextLine) ? Indent.get(nextLine) : null\n\n\t\t\tif (nextLine !== undefined) {\n\t\t\t\tif (this.#withBraces) {\n\t\t\t\t\tnextLineMatch = nextLine.trim() === \"```\"\n\t\t\t\t\tif (\n\t\t\t\t\t\tnextLineMatch &&\n\t\t\t\t\t\tnextLineIndent === this.#indent\n\t\t\t\t\t) {\n\t\t\t\t\t\tisNextLineClosingOne = true\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif (!isNextLineClosingOne) {\n\t\t\t\tif (nextLineIndent < this.#indent) {\n\t\t\t\t\tisNextLineClosingOne = true\n\t\t\t\t\tif (this.#withBraces) this.#isBroken = true\n\t\t\t\t}\n\t\t\t}\n\n\t\t} while (\n\t\t\tnextLine !== undefined &&\n\t\t\t!isNextLineClosingOne\n\t\t)\n\t}\n\n\t/**\n\t * Sets the CodeBlock body\n\t */\n\t#setBody() {\n\t\tconst start = (this.#withBraces) ? this.#start + 1 : this.#start\n\n\t\tthis.#body = this.#lines.slice(start, this.#cursor)\n\t\t\t.map(line => line.slice(Math.min(this.#rawIndent, Indent.raw(line))))\n\t\t\t.join(\"\\n\")\n\t}\n\n\t/**\n\t * Sets the CodeBlock raw body\n\t */\n\t#setRaw() {\n\t\tlet endRaw\n\t\tif (this.#withBraces) {\n\t\t\tendRaw = this.#cursor + 1\n\t\t\tif (this.#isBroken) endRaw = this.#cursor\n\t\t} else endRaw = this.#cursor\n\t\tthis.#raw = this.#lines.slice(this.#start, endRaw).join(\"\\n\")\n\t\tthis.#cursor = endRaw\n\t}\n\n\t/**\n\t * Tokenizes the lines for the CodeBlock token\n\t *\n\t * @returns {{\n\t * cursor: number,\n\t * lexer: {\n\t * \t\ttype: string,\n\t * \t\tindent: number,\n\t * \t\tlanguage: string|null,\n\t * \t\tvalue: string,\n\t * \t\traw: string\n\t * }}}\n\t */\n\ttokenize() {\n\t\tthis.#findEnd()\n\n\t\tthis.#setBody()\n\n\t\tthis.#setRaw()\n\n\t\treturn {\n\t\t\tcursor: this.#cursor - 1,\n\t\t\tlexer: {\n\t\t\t\ttype: TOKENS.CODE_BLOCK,\n\t\t\t\tindent: this.#indent,\n\t\t\t\tlanguage: this.#lang || null,\n\t\t\t\tvalue: this.#body,\n\t\t\t\traw: this.#raw\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * returns HTML for code block\n\t *\n\t * Format: <pre><code>{body}</code></pre>\n\t *\n\t * @param {Object} lexer - the CodeBlock lexer\n\t * @param {Function|null} highlightFn - A function to highlight code blocks\n\t *\n\t * @returns {string} - the CodeBlock HTML\n\t */\n\tstatic parse(lexer, highlightFn = null) {\n\t\tlet skeleton = \"<pre><code%class>%s</code></pre>\"\n\t\tif (lexer.language) {\n\t\t\tskeleton = skeleton.replace(\"%class\", ` class='language-${lexer.language}'`)\n\t\t} else {\n\t\t\tskeleton = skeleton.replace(\"%class\", \"\")\n\t\t}\n\t\tif (highlightFn) {\n\t\t\tconst highlightedCode = highlightFn(lexer.value, lexer.language)\n\t\t\tif (typeof highlightedCode === \"string\") {\n\t\t\t\tlexer.value = highlightedCode\n\t\t\t} else {\n\t\t\t\tconsole.error(\"highlightFn must return a string\")\n\t\t\t\tconsole.info(\"highlightFn was not used\")\n\t\t\t}\n\t\t\tskeleton = skeleton.replace(\"%s\", lexer.value)\n\t\t} else {\n\t\t\tskeleton = skeleton.replace(\"%s\", Esc.everything(lexer.value))\n\t\t}\n\t\treturn skeleton\n\t}\n}\n", "import { Parsers } from \"../tokenizer/index.js\"\nimport { TOKENS } from \"../util/index.js\"\n\n\nexport class Parser {\n\t#lexers\n\t#cursor\n\t#config\n\t#fromToken\n\t#currentLexer\n\t#parsedContent\n\t#modifiedParsers = {}\n\n\tconstructor(lexers, { from = null, config = {} } = {}) {\n\t\tthis.#lexers = lexers\n\t\tthis.#parsedContent = []\n\t\tthis.#fromToken = from\n\t\tthis.#config = config\n\t\tthis.#modifiedParsers = {}\n\n\t\tthis.#modifiedParsers[TOKENS.PARAGRAPH] = this.#parseParagraph.bind(this)\n\t}\n\n\t#parseParagraph() {\n\t\tlet parsed = Parsers.Paragraph.parse(this.#currentLexer)\n\t\tif (this.#fromToken === TOKENS.LIST) {\n\t\t\tthis.#parsedContent.push(`${parsed}`)\n\t\t} else this.#parsedContent.push(`<p>${parsed}</p>`)\n\t}\n\n\n\t#parseCurrentLexer() {\n\t\tfor (const module in Parsers) {\n\t\t\tif (Parsers[module].tokenName === this.#currentLexer.type) {\n\t\t\t\tif (this.#modifiedParsers[this.#currentLexer.type]) {\n\t\t\t\t\tthis.#modifiedParsers[this.#currentLexer.type]()\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tif (\n\t\t\t\t\tthis.#currentLexer.type === TOKENS.CODE_BLOCK &&\n\t\t\t\t\tthis.#config.highlightFn &&\n\t\t\t\t\ttypeof this.#config.highlightFn === \"function\"\n\t\t\t\t) {\n\t\t\t\t\tthis.#parsedContent.push(Parsers[module].parse(this.#currentLexer, this.#config.highlightFn))\n\t\t\t\t\treturn\n\t\t\t\t}\n\n\t\t\t\tthis.#parsedContent.push(Parsers[module].parse(this.#currentLexer))\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\trun() {\n\t\tfor (this.#cursor=0; this.#cursor<this.#lexers.length; this.#cursor++) {\n\t\t\tthis.#currentLexer = this.#lexers[this.#cursor]\n\t\t\tthis.#parseCurrentLexer()\n\t\t}\n\n\t\t// remove any %s leftovers and return\n\t\treturn this.#parsedContent\n\t\t\t.map(item => item.replaceAll(\"%s\", \"\"))\n\t\t\t.join(\"\")\n\t}\n}\n", "import { Lexer } from \"../lexer/index.js\"\nimport { REGEX } from \"../regex/index.js\"\nimport { Parser } from \"../parser/index.js\"\nimport { Newline } from \"./index.js\"\nimport { TOKENS, Utils } from \"../util/index.js\"\n\n\nexport class Quote {\n\t#lines\n\t#start\n\t#cursor\n\t#body = []\n\t#tBody = []\n\t#cDepth\n\t// these items should break the quote\n\t#breakTokens = [\n\t\t// TODO: for heading, we may have to\n\t\t//  check for underlined headings too\n\t\tREGEX.HEADING.ITEM,\n\t\tREGEX.LIST.ITEM,\n\t\tREGEX.CODE_BLOCK\n\t]\n\n\tstatic tokenName = TOKENS.QUOTE\n\n\t/**\n\t * Checks if the given text matches the Quote regex\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic test({ line }) {\n\t\treturn Utils.testRegex(line, REGEX.QUOTE.ITEM)\n\t}\n\n\t/**\n\t * Checks if the given text matches the Empty Quote regex\n\t *\n\t * @param {string} text\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic testEmpty(text) {\n\t\treturn Utils.testRegex(text, REGEX.QUOTE.EMPTY)\n\t}\n\n\t/**\n\t * Returns the depth of the quote\n\t *\n\t * If the text does not start with > i.e. the lazy items, then 0 is returned\n\t * Otherwise, the count of > before the first non > character is returned\n\t *\n\t * @param {string} text\n\t *\n\t * @returns {number}\n\t */\n\tstatic getDepth(text) {\n\t\ttext = text.trimStart()\n\t\tif (text[0] !== \">\") return 0\n\t\tif (Quote.testEmpty(text.trim())) return text.match(REGEX.QUOTE.COUNT).length\n\t\tconst quotePart = text.substring(0, text.search(REGEX.QUOTE.NON_QUOTE))\n\t\treturn quotePart.match(REGEX.QUOTE.COUNT).length\n\t}\n\n\t/**\n\t * Returns the value of the quote from the provided depth\n\t *\n\t * @param {string} text - the text to be parsed\n\t * @param depth - the depth of the quote\n\t *\n\t * @returns {string}\n\t */\n\tstatic getValue(text, depth) {\n\t\ttext = text.trimStart()\n\t\tconst cursor = Utils.getNthIndex(text, depth)\n\t\t// +1 for the \">\" character\n\t\treturn text.substring(cursor + 1)\n\t}\n\n\tconstructor(lines, cursor) {\n\t\tthis.#lines = lines\n\t\tthis.#cursor = cursor\n\t\tthis.#start = cursor\n\t}\n\n\t#findLazyEnd() {\n\t\tthis.#cursor--\n\n\t\tlet nextLine\n\t\t// check for laziness\n\t\tlet endLazy = false\n\t\tdo {\n\t\t\tnextLine = this.#lines[++this.#cursor]\n\t\t\tif (nextLine !== undefined) {\n\t\t\t\tif (Newline.test({ line: nextLine })) {\n\t\t\t\t\tendLazy = true\n\t\t\t\t}\n\t\t\t\tfor (let r=0; r<this.#breakTokens.length; r++) {\n\t\t\t\t\tif (Utils.testRegex(nextLine, this.#breakTokens[r])) {\n\t\t\t\t\t\tendLazy = true\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} while (nextLine !== undefined && !endLazy)\n\n\n\t\tthis.#cursor--\n\t}\n\n\t/**\n\t * Finds the end of the quote\n\t *\n\t * Runs check for laziness and breaks\n\t */\n\t#findEnd() {\n\t\tlet nextLine = this.#lines[this.#cursor]\n\t\tlet nextLineMatch\n\n\t\tdo {\n\t\t\tnextLine = this.#lines[++this.#cursor]\n\t\t\tif (nextLine !== undefined) {\n\t\t\t\tnextLineMatch = nextLine.trim().startsWith(\">\")\n\t\t\t} else nextLineMatch = false\n\t\t} while (\n\t\t\tnextLineMatch\n\t\t\t// nextLineIndent === indent\n\t\t)\n\n\t\t// here we have formal end of the quote\n\t\t// keeping beside the laziness\n\t\t// if the last item of the quote is a quote separator\n\t\t// then no laziness is allowed\n\t\tconst lastLineOfQuote = this.#lines[this.#cursor - 1]\n\t\tif (Quote.testEmpty(lastLineOfQuote)) {\n\t\t\tthis.#cursor--\n\t\t\treturn\n\t\t}\n\n\t\tthis.#findLazyEnd()\n\t}\n\n\t/**\n\t * Calculates the common depth for the Quote\n\t */\n\t#calcCommonDepth() {\n\t\tthis.#body.forEach((item) => {\n\t\t\tconst currDepth = Quote.getDepth(item)\n\t\t\tif (this.#cDepth === undefined) {\n\t\t\t\tthis.#cDepth = currDepth\n\t\t\t} else if (currDepth !== 0) { // bypass lazy items\n\t\t\t\tthis.#cDepth = Math.min(this.#cDepth, currDepth)\n\t\t\t}\n\t\t})\n\t}\n\n\n\t/**\n\t * Sets the body of the quote\n\t */\n\t#setBody() {\n\t\tthis.#body = this.#lines.slice(this.#start, this.#cursor + 1)\n\t}\n\n\t/**\n\t * Trims the quote from the body\n\t * Every common depth quote part is stripped\n\t */\n\t#trimBody() {\n\t\tthis.#body.forEach((item) => {\n\t\t\tif (Quote.test({ line: item }) || Quote.testEmpty(item)) {\n\t\t\t\tthis.#tBody.push(Quote.getValue(item, this.#cDepth).trimEnd())\n\t\t\t} else {\n\t\t\t\t// the lazy items can be non-quote so no need to get quote value\n\t\t\t\tthis.#tBody.push(item.trimEnd())\n\t\t\t}\n\t\t})\n\t}\n\n\t/**\n\t * Tokenizes the lines for the Quote token\n\t *\n\t * @returns {{ cursor: number, lexer: { tokens: Lexer[], depth: number, raw: string } }}\n\t */\n\ttokenize() {\n\t\tthis.#findEnd()\n\n\t\tthis.#setBody()\n\n\t\tthis.#calcCommonDepth()\n\n\t\tthis.#trimBody()\n\n\t\tconst lex = new Lexer(this.#tBody, { from: TOKENS.QUOTE })\n\n\t\treturn {\n\t\t\tcursor: this.#cursor,\n\t\t\tlexer: {\n\t\t\t\ttype: TOKENS.QUOTE,\n\t\t\t\ttokens: lex.run(),\n\t\t\t\tdepth: this.#cDepth,\n\t\t\t\traw: this.#body.join(\"\\n\")\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Wraps the body of the quote inside the Quote HTML tag\n\t *\n\t * @param {number} depth - the depth of the quote\n\t * @param {string} content - the body of the quote\n\t *\n\t * @returns {string} - the HTML quote\n\t */\n\tstatic #wrapInside(depth, content) {\n\t\tlet qHtml = \"%s\"\n\t\tfor (let j=0; j<depth; j++) {\n\t\t\tqHtml = qHtml.replace(\"%s\", `<blockquote>\n%s</blockquote>`)\n\t\t}\n\t\treturn qHtml.replace(\"%s\", `${content}`)\n\t}\n\n\t/**\n\t * Runs the HTML parsing for the Quote token\n\t *\n\t * @param {Object} lexer - the Quote lex\n\t *\n\t * @returns {string} - the HTML quote\n\t */\n\tstatic parse(lexer) {\n\t\tconst qParts = []\n\t\tlexer.tokens.forEach(qTokens => {\n\t\t\tlet babyParser\n\t\t\tbabyParser = new Parser([qTokens])\n\t\t\tqParts.push(babyParser.run())\n\t\t})\n\t\treturn Quote.#wrapInside(\n\t\t\tlexer.depth,\n\t\t\tqParts.join(\"\")\n\t\t)\n\t}\n}\n", "import { REGEX } from \"../regex/index.js\"\nimport { HrLine, Paragraph } from \"./index.js\"\nimport { TOKENS, Utils } from \"../util/index.js\"\n\n/**\n * Heading Tokenizer\n */\nexport class Heading {\n\t#line\n\t#nextLine\n\t#level\n\t#match\n\t#setext = false\n\n\tstatic tokenName = TOKENS.HEADING\n\n\t/**\n\t * Checks if the given text matches the Heading regex\n\t *\n\t * @param {string} text\n\t * @returns {boolean}\n\t */\n\tstatic testRegex(text) {\n\t\treturn Utils.testRegex(text, REGEX.HEADING.ITEM)\n\t}\n\n\t/**\n\t * Checks if the given text is of Heading 1 underline type\n\t *\n\t * @param {string} text\n\t * @returns {boolean}\n\t */\n\tstatic testH1UnderlineRegex(text) {\n\t\treturn Utils.testRegex(text, REGEX.HEADING.UNDERLINE_1)\n\t}\n\n\t/**\n\t * Checks if the given text is of Heading 2 underline type\n\t *\n\t * @param {string} text\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic testH2UnderlineRegex(text) {\n\t\treturn Utils.testRegex(text, REGEX.HEADING.UNDERLINE_2)\n\t}\n\n\t/**\n\t * Returns the regex groups match for the Heading token\n\t *\n\t * Following groups are returned:\n\t * 1. level - number of #s in the Heading\n\t * 2. fenceVal - If fenced Heading, the value of the fenced Heading\n\t * 3. val - the value of the normal Heading (without fence)\n\t *\n\t * @param {string} text\n\t *\n\t * @returns {RegExpExecArray}\n\t */\n\tstatic match(text) {\n\t\treturn Utils.execRegex(text, REGEX.HEADING.ITEM)\n\t}\n\n\t/**\n\t * Checks if the given text is of Heading type\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic test({ line, nextLine }) {\n\t\tif (Heading.testRegex(line)) return true\n\t\tif (nextLine !== undefined && !HrLine.test({ line })) {\n\t\t\tif (\n\t\t\t\tHeading.testH1UnderlineRegex(nextLine) ||\n\t\t\t\tHeading.testH2UnderlineRegex(nextLine)\n\t\t\t) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Heading Tokenizer Constructor\n\t *\n\t * @param {string} line current line to tokenize\n\t * @param {string| undefined} nextLine next line for tokenization\n\t *\n\t * @returns {Heading}\n\t */\n\tconstructor(line, nextLine) {\n\t\tthis.#line = line\n\t\tthis.#nextLine = nextLine\n\t\tthis.#findType()\n\t}\n\n\t/**\n\t * Checks if the Heading is of Setext or ATX type\n\t *\n\t * Sets the #setext property to true if it is of Underline type\n\t * Sets the #level property to the level of the Heading\n\t *\n\t * @returns void\n\t */\n\t#findType() {\n\t\tif (this.#nextLine !== undefined) {\n\t\t\tif (!Heading.testRegex(this.#line)) {\n\t\t\t\tif (Heading.testH1UnderlineRegex(this.#nextLine)) {\n\t\t\t\t\tthis.#setext = true\n\t\t\t\t\tthis.#level = 1\n\t\t\t\t}\n\t\t\t\telse if (Heading.testH2UnderlineRegex(this.#nextLine)) {\n\t\t\t\t\tthis.#setext = true\n\t\t\t\t\tthis.#level = 2\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (!this.#setext) {\n\t\t\tthis.#match = Heading.match(this.#line)?.groups\n\t\t\tthis.#match.value = this.#match.fenceVal || this.#match.val\n\t\t\tdelete this.#match.fenceVal\n\t\t\tdelete this.#match.val\n\t\t}\n\t}\n\n\t/**\n\t * tokenizes the line for Heading token\n\t *\n\t * @returns {{level: number, value: string, raw: string, setext: boolean}}\n\t */\n\ttokenize() {\n\t\tif (!this.#setext) {\n\t\t\treturn {\n\t\t\t\tlevel: this.#match.level.length,\n\t\t\t\tvalue: this.#match.value.trimEnd(),\n\t\t\t\traw: this.#line,\n\t\t\t\tsetext: false\n\t\t\t}\n\t\t} else {\n\t\t\treturn {\n\t\t\t\tlevel: this.#level,\n\t\t\t\tvalue: this.#line.trimEnd(),\n\t\t\t\traw: `${this.#line}\\n${this.#nextLine}`,\n\t\t\t\tsetext: true\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Runs the HTML parsing for the Heading token\n\t *\n\t * @param {Object} lexer the Heading lex\n\t *\n\t * @returns {string} the Heading HTML\n\t */\n\tstatic parse(lexer) {\n\t\treturn `<h${lexer.level}>${Paragraph.parse(lexer)}</h${lexer.level}>`\n\t}\n}\n", "import { REGEX } from \"../regex/index.js\"\nimport { Lexer } from \"../lexer/index.js\"\nimport { Parser } from \"../parser/index.js\"\nimport { Newline, Heading, Quote } from \"./index.js\"\nimport { TOKENS, Utils, Indent } from \"../util/index.js\"\n\n/**\n * List Tokenizer\n */\nexport class List {\n\t#lines\n\t#cursor\n\t#indent\n\t#body = []\n\t#end\n\t#shrunkBody = []\n\t#lex\n\t#match\n\t#isEmpty\n\t#meta = {\n\t\tchecklist: false,\n\t\tordered: false,\n\t\tidentifier: null\n\t}\n\n\tstatic tokenName = TOKENS.LIST\n\n\tstatic testEmpty(text) {\n\t\treturn Utils.testRegex(text, REGEX.LIST.EMPTY)\n\t}\n\n\tstatic testItem(text) {\n\t\treturn Utils.testRegex(text, REGEX.LIST.ITEM)\n\t}\n\n\tstatic test({ line }) {\n\t\tif (List.testEmpty(line)) { return true }\n\t\treturn List.testItem(line)\n\t}\n\n\n\tstatic matchEmpty(text) {\n\t\treturn Utils.execRegex(text, REGEX.LIST.EMPTY)\n\t}\n\n\tstatic matchItem(text) {\n\t\treturn Utils.execRegex(text, REGEX.LIST.ITEM)\n\t}\n\n\tstatic match(text, isEmpty = false) {\n\t\tif (isEmpty) {\n\t\t\treturn List.matchEmpty(text)\n\t\t}\n\t\treturn List.matchItem(text)\n\t}\n\n\tconstructor(lines, cursor, indent) {\n\t\tthis.#lines = lines\n\t\tthis.#cursor = cursor\n\t\tthis.#indent = indent\n\t\tthis.#isEmpty = List.testEmpty(lines[cursor])\n\t\tthis.#processMeta()\n\n\t}\n\n\t/**\n\t * Finds the end of the list item\n\t * Updates the cursor value\n\t */\n\t#findEnd() {\n\t\tif (this.#isEmpty) {\n\t\t\tthis.#end = this.#cursor + 1\n\t\t\treturn\n\t\t}\n\n\t\tlet cursor = this.#cursor\n\t\tlet nextLine, nextLineIndent, nextNextLine\n\t\tlet breakMatch = false\n\n\n\t\tdo {\n\t\t\tnextLine = this.#lines[++cursor]\n\n\t\t\tnextLineIndent = Indent.get(nextLine)\n\t\t\t// check for two or more consecutive new lines\n\t\t\t// if we find that, then we know we are at the end of the list item\n\t\t\tnextNextLine = this.#lines[cursor + 1]\n\t\t\tif (\n\t\t\t\tNewline.test({ line: nextLine })\n\t\t\t) {\n\t\t\t\tif (\n\t\t\t\t\tnextNextLine &&\n\t\t\t\t\tNewline.test({ line: nextNextLine })\n\t\t\t\t) {\n\t\t\t\t\tbreakMatch = true\n\t\t\t\t} else if (\n\t\t\t\t\tIndent.get(nextNextLine) <= this.#indent\n\t\t\t\t) {\n\t\t\t\t\tbreakMatch = true\n\t\t\t\t}\n\t\t\t}\n\t\t} while (\n\t\t\tnextLine !== undefined &&\n\t\t\t!breakMatch &&\n\t\t\t!(\n\t\t\t\t(\n\t\t\t\t\tList.test({ line: nextLine }) ||\n\t\t\t\t\tHeading.test({ line: nextLine, nextLine: nextNextLine }) ||\n\t\t\t\t\tQuote.test({ line: nextLine })\n\t\t\t\t) &&\n\t\t\t\tnextLineIndent <= this.#indent\n\t\t\t)\n\t\t)\n\t\tthis.#end = cursor\n\t}\n\n\t/**\n\t * Processes the list item meta\n\t *\n\t * The following meta are calculated:\n\t * 1. ordered: boolean - if the list item is ordered\n\t * 2. identifier: string - the identifier for the list item\n\t * 3. check: boolean - if the list item is a checklist item\n\t */\n\t#processMeta() {\n\t\tthis.#match = List.match(this.#lines[this.#cursor], this.#isEmpty).groups\n\n\t\tthis.#meta.checklist = this.#match.check !== undefined\n\n\t\tthis.#meta.ordered = !!this.#match.count\n\n\t\tif (this.#match.mark) this.#meta.identifier = this.#match.mark\n\t}\n\n\t/**\n\t * Sets the raw body of the list item\n\t */\n\t#setBody() {\n\t\tthis.#body = this.#lines.slice(this.#cursor, this.#end)\n\t}\n\n\t/**\n\t * Shrinks raw body for the list item\n\t */\n\t#shrinkBody() {\n\t\tfor (let index = 0; index < this.#body.length; index++) {\n\t\t\tconst line = this.#body[index]\n\t\t\tif (index === 0) {\n\t\t\t\tif (this.#isEmpty) {\n\t\t\t\t\tthis.#shrunkBody.push(\"\")\n\t\t\t\t} else {\n\t\t\t\t\tthis.#shrunkBody.push(this.#match.value)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tthis.#shrunkBody.push(line)\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Tokenizes the provided lines for the List Item token\n\t *\n\t * @returns {{cursor: number,  meta: {ordered: boolean, identifier: null, checklist: boolean}, lexer: {count: null, checked: (boolean|null), raw: string, tokens: *, type: string}}}\n\t */\n\ttokenize() {\n\t\tthis.#findEnd()\n\n\t\tthis.#setBody()\n\n\t\tthis.#shrinkBody()\n\n\t\tthis.#lex = new Lexer(this.#shrunkBody, { from: TOKENS.LIST_ITEM })\n\n\t\treturn {\n\t\t\tcursor: this.#end - 1,\n\t\t\tmeta: this.#meta,\n\t\t\tlexer: {\n\t\t\t\ttype: TOKENS.LIST_ITEM,\n\t\t\t\ttokens: this.#lex.run(),\n\t\t\t\tcount: this.#match.count || null,\n\t\t\t\tchecked: (this.#meta.checklist) ? this.#match.check === \"x\" : null,\n\t\t\t\traw: this.#body.join(\"\\n\")\n\t\t\t}\n\t\t}\n\t}\n\n\t/**\n\t * Runs HTML parsing for the List token\n\t *\n\t * @param {Object} lexer - the List lexer\n\t *\n\t * @returns {string} - the List HTML\n\t */\n\tstatic parse(lexer) {\n\t\tconst listTag = (lexer.meta.ordered) ? \"ol\" : \"ul\"\n\t\tlet listBodyHtml = []\n\t\tlexer.items.forEach(listItem => {\n\t\t\tlet listItemHtml = \"<li>%s</li>\"\n\t\t\tconst lParser = new Parser(listItem.tokens, { from: TOKENS.LIST })\n\t\t\tif (lexer.meta.checklist) {\n\t\t\t\tconst isChecked = (listItem.checked) ? \" checked\" : \"\"\n\t\t\t\tlistItemHtml = listItemHtml. replace(\n\t\t\t\t\t\"%s\",\n\t\t\t\t\t\"<input type='checkbox'\" +\n\t\t\t\t\t\tisChecked +\n\t\t\t\t\t\t\">\" +\n\t\t\t\t\t\tlParser.run()\n\t\t\t\t)\n\t\t\t} else {\n\t\t\t\tlistItemHtml = listItemHtml.replace(\n\t\t\t\t\t\"%s\",\n\t\t\t\t\tnew Parser(listItem.tokens, { from: TOKENS.LIST }).run()\n\t\t\t\t)\n\t\t\t}\n\t\t\tlistBodyHtml.push(listItemHtml)\n\t\t})\n\t\treturn `<${listTag}>${listBodyHtml.join(\"\")}</${listTag}>`\n\t}\n\n\t/**\n\t * Runs check if the last and current lexer is of same list type\n\t *\n\t * Things under check are:\n\t * 1. type of the lexers\n\t * 2. indentation\n\t * 3. is of type checklist\n\t * 4. ordered or unordered\n\t * 5. identifier of the list item\n\t *\n\t * @param {Object} baseLexer\n\t * @param {Object} lexerToCompare\n\t * @param {number} indent\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic compareIfTwoListLexerAreOfSameType(baseLexer, lexerToCompare, indent) {\n\t\treturn (\n\t\t\tbaseLexer &&\n\t\t\tbaseLexer.type === TOKENS.LIST &&\n\t\t\tbaseLexer.indent === indent &&\n\t\t\tbaseLexer.meta.checklist === lexerToCompare.meta.checklist &&\n\t\t\tbaseLexer.meta.ordered === lexerToCompare.meta.ordered &&\n\t\t\tbaseLexer.meta.identifier === lexerToCompare.meta.identifier\n\t\t)\n\t}\n}\n", "import { REGEX } from \"../regex/index.js\"\nimport { Utils, TOKENS } from \"../util/index.js\"\n\n/**\n * HTML code\n */\nexport class HTML {\n\t#linkRefs\n\t#lines\n\t#cursor\n\t#indent\n\t#lex\n\n\tstatic tokenName = TOKENS.HTML\n\n\tconstructor(lines, cursor, indent, linkRefs) {\n\t\tthis.#lines = lines\n\t\tthis.#cursor = cursor\n\t\tthis.#indent = indent\n\t\tthis.#linkRefs = linkRefs\n\t\tthis.#lex = []\n\t}\n\n\t/**\n\t * @param {string} text\n\t *\n\t * @returns {boolean}\n\t */\n\tstatic test(text) {\n\t\treturn Utils.testRegex(text, REGEX.PARAGRAPH.HTML)\n\t}\n\n\tstatic testBlock({ lines, cursor }) {\n\t\tconst lineToParse = lines[cursor]\n\t\treturn Utils.testRegex(lineToParse, REGEX.HTML)\n\t}\n\n\ttokenize() {\n\t\tconst regexMatch = Utils.execRegex(this.#lines[this.#cursor], REGEX.HTML)\n\t\tthis.#lex = {\n\t\t\ttype: TOKENS.HTML,\n\t\t\tindent: this.#indent,\n\t\t\t...regexMatch.groups,\n\t\t\traw: this.#lines[this.#cursor]\n\t\t}\n\t\treturn { lexer: this.#lex, cursor: this.#cursor }\n\t}\n\n\t/**\n\t * returns HTML\n\t *\n\t * @returns {string}\n\t */\n\tstatic parse(lexer) {\n\t\t// if (lexer.tag.toLowerCase() === \"a\") {\n\t\t// \treturn `<p>${lexer.raw}</p>`\n\t\t// }\n\t\treturn lexer.raw\n\t}\n}\n", "import { REGEX } from \"../regex/index.js\"\nimport { TOKENS, Utils, Esc } from \"../util/index.js\"\n\n\n\nexport class Paragraph {\n\tstatic tokenName = TOKENS.PARAGRAPH\n\n\t/**\n\t * Returns a fence object\n\t *\n\t * @param {Boolean} fence - true if fence, false otherwise\n\t * @param {String} ident - identifier, defaults to \"\"\n\t * @param {Number} start - start index, defaults to -1\n\t * @param {Number} end - end index, defaults to -1\n\t *\n\t * @returns {{ident: string, start: number, end: number, fence: boolean}}\n\t */\n\tstatic fenceObj(fence = false, ident = \"\", start = -1, end = -1) {\n\t\treturn {\n\t\t\tfence, ident, start, end\n\t\t}\n\t}\n\n\t/**\n\t * Determines if the identifier can have a complete fence\n\t *\n\t * Checks:\n\t * 1. If start is greater than the length of the string\n\t * 2. If string after start contains the identifier character\n\t *\n\t * @param str\n\t * @param start\n\t * @param identifierChar\n\t * @returns {boolean}\n\t */\n\tstatic #fenceSanity(str, start, identifierChar) {\n\t\t// if start is greater than the length of the line, immediately return false\n\t\tif (start > str.length) return false\n\n\t\t// if no identifier beside the start, immediately return false\n\t\tconst afterIdentifier = str.substring(start)\n\t\treturn afterIdentifier.includes(identifierChar)\n\t}\n\n\t/**\n\t * Determines if the provided string is fenced from the cursor position\n\t *\n\t * @param {String} lineToParse - line to parse\n\t * @param {Number} cursor - starting position\n\t * @param {String} identifier - fence identifier\n\t * @param {Boolean} onlyExact - only exact match\n\t * @param {Boolean} evenFence - even fence\n\t *\n\t * @returns {{start: Number, ident: string, end: Number, fence: boolean}}\n\t */\n\tstatic #isFenced(lineToParse, cursor, identifier, onlyExact=false, evenFence = false) {\n\t\t// start from cursor + length of identifier\n\t\tconst start = cursor + identifier.length\n\n\t\tconst sanity = Paragraph.#fenceSanity(lineToParse, start, identifier[0])\n\t\tif (!sanity) return Paragraph.fenceObj()\n\n\t\tconst afterStartStr = lineToParse.slice(start)\n\n\t\tif ((evenFence && identifier.length % 2 === 0)||!evenFence) {\n\t\t\t// if exact identifier behind then do not go for further checks\n\t\t\tconst exactEnd = Utils.isExactMatch(afterStartStr, identifier)\n\n\t\t\tif (exactEnd !== -1) {\n\t\t\t\treturn this.fenceObj(true, identifier, start, start + exactEnd)\n\t\t\t}\n\t\t}\n\n\t\tif (!onlyExact) {\n\t\t\tfor (let i=start; i >= cursor; i--) {\n\n\n\t\t\t\tconst tempIdentifier = lineToParse.substring(cursor, i)\n\n\t\t\t\tif (evenFence) {\n\t\t\t\t\tif (tempIdentifier.length % 2 !== 0) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tconst end = Utils.isLooseMatch(afterStartStr, tempIdentifier)\n\n\t\t\t\tif (end !== -1) {\n\t\t\t\t\treturn Paragraph.fenceObj(true, tempIdentifier, start, start + end)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\treturn Paragraph.fenceObj()\n\t}\n\n\n\t/**\n\t * Link: title, href, tooltip\n\t *\n\t * If match not found then falsy value is returned\n\t * Otherwise, groups and end are returned\n\t *\n\t * @param {String} lineToParse\n\t * @param {Number} cursor\n\t * @returns {{found: boolean, groups: null, end: number}|{found: boolean, groups: {[p: string]: string}, end: *}}\n\t */\n\tstatic #findLink(lineToParse, cursor) {\n\t\tconst check = lineToParse.substring(cursor)\n\t\tif (Utils.testRegex(check, REGEX.PARAGRAPH.LINK)) {\n\t\t\tconst match = Utils.execRegex(check, REGEX.PARAGRAPH.LINK)\n\t\t\treturn {\n\t\t\t\tfound: true,\n\t\t\t\tgroups: match.groups,\n\t\t\t\tend: cursor + match[0].length - 1\n\t\t\t}\n\t\t} return { found: false, groups: null, end: -1 }\n\t}\n\n\tstatic #findHtml(lineToParse, cursor) {\n\t\tconst check = lineToParse.substring(cursor)\n\t\tif (Utils.testRegex(check, REGEX.PARAGRAPH.HTML)) {\n\t\t\tconst match = Utils.execRegex(check, REGEX.PARAGRAPH.HTML)\n\t\t\treturn {\n\t\t\t\tfound: true,\n\t\t\t\tgroups: match.groups,\n\t\t\t\tend: cursor + match[0].length - 1\n\t\t\t}\n\t\t} return { found: false, groups: null, end: -1 }\n\t}\n\n\t/**\n\t * Finds link reference in the provided line\n\t *\n\t * If match not found then falsy value is returned\n\t * Otherwise, groups, withText (bool) and end are returned\n\t *\n\t * @param {String} lineToParse\n\t * @param {Number} cursor\n\t * @returns {{found: boolean, groups: null, end: number}|{found: boolean, groups: {[p: string]: string}, end: number, withText: boolean}}\n\t */\n\tstatic #findLinkRef(lineToParse, cursor) {\n\t\tconst check = lineToParse.substring(cursor)\n\t\tlet withText = false\n\t\tlet match\n\n\t\tif (Utils.testRegex(check, REGEX.PARAGRAPH.REF_LINK)) {\n\t\t\t// check if link ref with text\n\t\t\tif (Utils.testRegex(check, REGEX.LINK_REF.WITH_TEXT)) {\n\t\t\t\twithText = true\n\t\t\t\tmatch = Utils.execRegex(check, REGEX.LINK_REF.WITH_TEXT)\n\t\t\t} else {\n\t\t\t\tmatch = Utils.execRegex(check, REGEX.LINK_REF.WITHOUT_TEXT)\n\t\t\t}\n\n\t\t\treturn {\n\t\t\t\tfound: true,\n\t\t\t\twithText,\n\t\t\t\tgroups: match.groups,\n\t\t\t\tend: cursor + match[0].length - 1\n\t\t\t}\n\t\t} return { found: false, groups: null, end: -1 }\n\t}\n\n\n\t/**\n\t * Finds image in the provided line\n\t *\n\t * If match not found then falsy value is returned\n\t * Otherwise, groups and end are returned\n\t *\n\t * @param {String} lineToParse\n\t * @param {Number} cursor\n\t *\n\t * @returns {{found: boolean, groups: {[p: string]: string}, end: number}|{found: boolean, groups: null, end: number}}\n\t */\n\tstatic #findImage(lineToParse, cursor) {\n\t\tconst check = lineToParse.substring(cursor)\n\t\tif (Utils.testRegex(check, REGEX.PARAGRAPH.IMAGE)) {\n\t\t\tconst match = Utils.execRegex(check, REGEX.PARAGRAPH.IMAGE)\n\t\t\treturn {\n\t\t\t\tfound: true,\n\t\t\t\tgroups: match.groups,\n\t\t\t\tend: cursor + match[0].length - 1\n\t\t\t}\n\t\t} return { found: false, groups: null, end: -1 }\n\t}\n\n\t/**\n\t * Tokenize emphasis using the identifiers\n\t *\n\t * 1. Bold: **|__ fence (even)\n\t * 2. Italics: *|_ fence (odd)\n\t * 3. Code: ` fence (exact)\n\t * 4. Underline: ++ fence (even)\n\t * 5. Strike: -- fence (even)\n\t * 6. Links: [text](url \"title\")\n\t * \t\t\t\t\t\"title\" is optional\n\t * 7. Image: ![text](url \"title\" 50 50)\n   * \t\t\t\t\t\"title\" 50 50 are optional\n\t *\n\t *\n\t * @param {String} lineToParse\n\t * @param {Array} linkRefs\n\t *\n\t * @returns {*[]}\n\t */\n\tstatic #findEmphasis(lineToParse, linkRefs) {\n\t\tlet identifier\n\t\tconst tokens = []\n\n\t\tfunction runCheckForTextBeforeStart(start, cursor, ident) {\n\t\t\tconst lastToken = tokens[tokens.length - 1]\n\t\t\tif (start > cursor + ident.length) {\n\t\t\t\tconst text = lineToParse.substring(cursor, start - ident.length)\n\t\t\t\tif (lastToken && lastToken.type === TOKENS.TEXT) {\n\t\t\t\t\tlastToken.raw += text\n\t\t\t\t\tlastToken.value += text\n\t\t\t\t} else {\n\t\t\t\t\ttokens.push({\n\t\t\t\t\t\ttype: TOKENS.TEXT,\n\t\t\t\t\t\traw: text,\n\t\t\t\t\t\tvalue: text\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tfor (let cursor=0; cursor<lineToParse.length; cursor++) {\n\t\t\tconst currChar = lineToParse[cursor]\n\t\t\tconst prevChar = lineToParse[cursor-1] || null\n\t\t\tconst nextChar = lineToParse[cursor+1] || null\n\t\t\tconst lastToken = tokens[tokens.length - 1]\n\n\t\t\tlet escape = false\n\n\t\t\tif (prevChar && prevChar === \"\\\\\") escape = true\n\n\t\t\tif (!escape && (currChar === \"*\" || currChar === \"_\")) {\n\t\t\t\tidentifier = Utils.findConsecutive(lineToParse, cursor, currChar)\n\n\t\t\t\tconst { fence, ident, start, end } = Paragraph.#isFenced(lineToParse, cursor, identifier)\n\n\t\t\t\tif (fence) {\n\t\t\t\t\t// grab the text before the fence\n\t\t\t\t\trunCheckForTextBeforeStart(start, cursor, ident)\n\n\t\t\t\t\tconst v = lineToParse.slice(start, end)\n\t\t\t\t\ttokens.push({\n\t\t\t\t\t\ttype: (ident.length % 2 === 0)\n\t\t\t\t\t\t\t? TOKENS.BOLD\n\t\t\t\t\t\t\t: TOKENS.ITALIC,\n\t\t\t\t\t\traw: `${ident}${v}${ident}`,\n\t\t\t\t\t\ttokens: Paragraph.#findEmphasis(v, linkRefs)\n\t\t\t\t\t})\n\t\t\t\t\tcursor = end + ident.length - 1\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (!escape && currChar === \"`\") {\n\t\t\t\tidentifier = Utils.findConsecutive(lineToParse, cursor, \"`\")\n\n\t\t\t\tconst { fence, ident, start, end } = Paragraph.#isFenced(lineToParse, cursor, identifier, true)\n\n\t\t\t\tif (fence) {\n\t\t\t\t\tconst value = lineToParse.slice(start, end)\n\t\t\t\t\tif (value.length > 0) {\n\t\t\t\t\t\ttokens.push({\n\t\t\t\t\t\t\ttype: TOKENS.CODE,\n\t\t\t\t\t\t\traw: `${ident}${value}${ident}`,\n\t\t\t\t\t\t\t// TIP: no need to waste time escaping it again\n\t\t\t\t\t\t\t// because, the code token value is already escaped here\n\t\t\t\t\t\t\tvalue: value.trim()\n\t\t\t\t\t\t})\n\t\t\t\t\t\tcursor = end + ident.length - 1\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (!escape && [\"~\", \"+\"].includes(currChar)) {\n\t\t\t\t// underline and strike\n\t\t\t\tif (nextChar && nextChar === currChar) {\n\t\t\t\t\tidentifier = Utils.findConsecutive(lineToParse, cursor, currChar)\n\n\t\t\t\t\tconst { fence, ident, start, end } = Paragraph.#isFenced(lineToParse, cursor, identifier, false, true)\n\n\t\t\t\t\tif (fence) {\n\t\t\t\t\t\trunCheckForTextBeforeStart(start, cursor, ident)\n\n\t\t\t\t\t\tconst v = lineToParse.slice(start, end)\n\t\t\t\t\t\ttokens.push({\n\t\t\t\t\t\t\ttype: (currChar === \"+\") ? TOKENS.UNDERLINE: TOKENS.STRIKE_THROUGH,\n\t\t\t\t\t\t\traw: `${ident}${v}${ident}`,\n\t\t\t\t\t\t\ttokens: Paragraph.#findEmphasis(v, linkRefs)\n\t\t\t\t\t\t})\n\t\t\t\t\t\tcursor = end + ident.length - 1\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (!escape && currChar === \"[\") {\n\t\t\t\t// link\n\t\t\t\tconst linkMatch = Paragraph.#findLink(lineToParse, cursor)\n\n\t\t\t\tif (linkMatch.found) {\n\t\t\t\t\ttokens.push({\n\t\t\t\t\t\ttype: TOKENS.LINK,\n\t\t\t\t\t\traw: lineToParse.slice(cursor, linkMatch.end + 1),\n\t\t\t\t\t\ttokens: {\n\t\t\t\t\t\t\ttitle: {\n\t\t\t\t\t\t\t\traw: linkMatch.groups.text,\n\t\t\t\t\t\t\t\ttokens: Paragraph.#findEmphasis(linkMatch.groups.text, linkRefs)\n\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\thref: linkMatch.groups.href,\n\t\t\t\t\t\t\ttooltip: linkMatch.groups.title\n\t\t\t\t\t\t}\n\t\t\t\t\t})\n\t\t\t\t\tcursor = linkMatch.end\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\t// link reference\n\t\t\t\tif (linkRefs.length > 0) {\n\t\t\t\t\tconst linkRefMatch = Paragraph.#findLinkRef(lineToParse, cursor)\n\t\t\t\t\tif (linkRefMatch.found) {\n\n\t\t\t\t\t\t// if the found reference is in the list of references, add it to the tokens\n\t\t\t\t\t\tconst ref = linkRefs.find(r => r.text === linkRefMatch.groups.ref)\n\n\t\t\t\t\t\tif (ref) {\n\t\t\t\t\t\t\tconst rawTitle = (linkRefMatch.withText) ? linkRefMatch.groups.text : ref.text\n\n\t\t\t\t\t\t\ttokens.push({\n\t\t\t\t\t\t\t\ttype: TOKENS.LINK,\n\t\t\t\t\t\t\t\traw: lineToParse.slice(cursor, linkRefMatch.end + 1),\n\t\t\t\t\t\t\t\ttokens: {\n\t\t\t\t\t\t\t\t\ttitle: {\n\t\t\t\t\t\t\t\t\t\traw: rawTitle,\n\t\t\t\t\t\t\t\t\t\ttokens: Paragraph.#findEmphasis(rawTitle, linkRefs)\n\t\t\t\t\t\t\t\t\t},\n\t\t\t\t\t\t\t\t\thref: ref.href,\n\t\t\t\t\t\t\t\t\ttooltip: ref.title\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\tcursor = linkRefMatch.end\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\telse if (!escape && currChar === \"!\") {\n\t\t\t\t// image parsing\n\t\t\t\tconst imageMatch = Paragraph.#findImage(lineToParse, cursor)\n\t\t\t\tif (imageMatch.found) {\n\t\t\t\t\ttokens.push({\n\t\t\t\t\t\ttype: TOKENS.IMAGE,\n\t\t\t\t\t\traw: lineToParse.slice(cursor, imageMatch.end + 1),\n\t\t\t\t\t\ttokens: imageMatch.groups\n\t\t\t\t\t})\n\t\t\t\t\tcursor = imageMatch.end\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\t// TODO: image reference\n\t\t\t}\n\t\t\telse if (!escape && currChar === \"<\") {\n\t\t\t\tconst htmlMatch = Paragraph.#findHtml(lineToParse, cursor)\n\t\t\t\tif (htmlMatch.found) {\n\t\t\t\t\ttokens.push({\n\t\t\t\t\t\ttype: TOKENS.HTML,\n\t\t\t\t\t\traw: lineToParse.slice(cursor, htmlMatch.end + 1),\n\t\t\t\t\t\ttokens: {\n\t\t\t\t\t\t\ttag: htmlMatch.groups?.tag || htmlMatch.groups?.endTag,\n\t\t\t\t\t\t\tattributes: htmlMatch.groups.attrs?.trim(),\n\t\t\t\t\t\t\tisEndTag: !! htmlMatch.groups?.endTag\n\t\t\t\t\t\t}\n\t\t\t\t\t})\n\t\t\t\t\tcursor = htmlMatch.end\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// otherwise a normal text\n\t\t\tif (lastToken && lastToken.type === TOKENS.TEXT) {\n\t\t\t\tlastToken.raw += currChar\n\t\t\t\tlastToken.value += currChar\n\t\t\t} else {\n\t\t\t\t// a normal text\n\t\t\t\ttokens.push({\n\t\t\t\t\ttype: TOKENS.TEXT,\n\t\t\t\t\traw: currChar,\n\t\t\t\t\tvalue: currChar\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t\treturn tokens\n\t}\n\n\t/**\n\t * Paragraph Tokenization\n\t * Tokenizes a line of text into emphasis tokens\n\t *\n\t * @param {String} lineToParse\n\t * @param {Array} linkRefs\n\t *\n\t * @returns {*[]}\n\t */\n\tstatic tokenize(lineToParse, linkRefs) {\n\t\treturn Paragraph.#findEmphasis(lineToParse, linkRefs)\n\t}\n\n\tstatic parse(lexer) {\n\t\tlet parsed = \"\"\n\t\tlexer.tokens.forEach(token => {\n\t\t\tif (token.type === TOKENS.BOLD) {\n\t\t\t\tparsed += `<strong>${Paragraph.parse(token)}</strong>`\n\t\t\t} else if (token.type === TOKENS.ITALIC) {\n\t\t\t\tparsed += `<em>${Paragraph.parse(token)}</em>`\n\t\t\t} else if (token.type === TOKENS.CODE) {\n\t\t\t\ttoken.value = Esc.unEscape(token.value)\n\t\t\t\tparsed += `<code>${Esc.everything(token.value)}</code>`\n\t\t\t}else if (token.type === TOKENS.STRIKE_THROUGH) {\n\t\t\t\tparsed += `<s>${Paragraph.parse(token)}</s>`\n\t\t\t} else if (token.type === TOKENS.LINK) {\n\t\t\t\tconst linkTokens = token.tokens\n\t\t\t\tlet linkTag = `<a href=\"${linkTokens.href}\"` +\n\t\t\t\t\t\t(linkTokens.tooltip ? ` title=\"${linkTokens.tooltip}\"` : \"\") +\n\t\t\t\t\t\t\">\" +\n\t\t\t\t\t\tParagraph.parse(linkTokens.title) +\n\t\t\t\t\t\t\"</a>\"\n\n\t\t\t\tparsed += linkTag\n\t\t\t} else if (token.type === TOKENS.UNDERLINE) {\n\t\t\t\tparsed += `<u>${Paragraph.parse(token)}</u>`\n\t\t\t} else if (token.type === TOKENS.IMAGE) {\n\t\t\t\tconst imgTokens = token.tokens\n\t\t\t\tlet imgTag = `<img src=\"${imgTokens.href}\"` +\n\t\t\t\t\t\t(imgTokens.alt !== undefined ? ` alt=\"${imgTokens.alt}\"` : \"\") +\n\t\t\t\t\t\t(imgTokens.title !== undefined ? ` title=\"${imgTokens.title}\"` : \"\") +\n\t\t\t\t\t\t(imgTokens.width !== undefined ? ` width=\"${imgTokens.width}\"` : \"\") +\n\t\t\t\t\t\t(imgTokens.height !== undefined ? ` height=\"${imgTokens.height}\"` : \"\") +\n\t\t\t\t\t\t\">\"\n\t\t\t\tparsed += imgTag\n\t\t\t} else if (token.type === TOKENS.HTML) {\n\t\t\t\tparsed += token.raw\n\t\t\t} else {\n\t\t\t\tconst escaped = Esc.nonTags(token.value)\n\t\t\t\tconst unescaped = Esc.unEscape(escaped)\n\t\t\t\tparsed += unescaped\n\t\t\t}\n\t\t})\n\t\treturn parsed\n\t}\n}\n", "import { TOKENS, Utils } from \"../util/index.js\"\nimport { REGEX } from \"../regex/index.js\"\n\n\nexport class FrontMatter {\n\t#lines\n\t#endLine\n\t#body\n\t#value = {}\n\n\tstatic tokenName = TOKENS.FRONT_MATTER\n\n\tconstructor(lines) {\n\t\tthis.#lines = lines\n\t\tthis.findEnd()\n\t}\n\n\tstatic test(lines) {\n\t\tif (Utils.testRegex(lines[0], REGEX.FRONT_MATTER.BOUNDARY)) {\n\t\t\tfor (let i = 1; i < lines.length; i++) {\n\t\t\t\tconst line = lines[i]\n\t\t\t\tif (Utils.testRegex(line, REGEX.FRONT_MATTER.BOUNDARY)) {\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t\tif (!Utils.testRegex(line, REGEX.FRONT_MATTER.ENTRY)) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn false\n\t}\n\n\tfindEnd() {\n\t\tfor (let i = 1; i < this.#lines.length; i++) {\n\t\t\tif (Utils.testRegex(this.#lines[i], REGEX.FRONT_MATTER.BOUNDARY)) {\n\t\t\t\tthis.#endLine = i + 1\n\t\t\t}\n\t\t}\n\t\tthis.#body = this.#lines.slice(1, this.#endLine - 1)\n\t}\n\n\tremoveFrontMatterFromGivenLines() {\n\t\treturn this.#lines.slice(this.#endLine + 1)\n\t}\n\n\tgetValue() {\n\t\tfor (let i = 0; i < this.#body.length; i++) {\n\t\t\tconst line = this.#body[i]\n\t\t\tif (Utils.testRegex(line, REGEX.FRONT_MATTER.ENTRY)) {\n\t\t\t\tconst match = Utils.execRegex(line, REGEX.FRONT_MATTER.ENTRY)\n\t\t\t\tif (match) {\n\t\t\t\t\tlet keyValue = match.groups.value\n\t\t\t\t\tif ([\"true\", \"false\"].includes(keyValue.toLowerCase())) {\n\t\t\t\t\t\tkeyValue = keyValue.toLowerCase() === \"true\"\n\t\t\t\t\t} else if (REGEX.NUMBER.test(keyValue)) {\n\t\t\t\t\t\tkeyValue = parseInt(keyValue)\n\t\t\t\t\t} else if (REGEX.NUMBER_WITH_DECIMAL.test(keyValue)) {\n\t\t\t\t\t\tkeyValue = parseFloat(keyValue)\n\t\t\t\t\t} else if (REGEX.BIG_BRACKETED.test(keyValue) || REGEX.CURLY_BRACKETED.test(keyValue)) {\n\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\tkeyValue = JSON.parse(keyValue)\n\t\t\t\t\t\t} catch (e) {\n\t\t\t\t\t\t\t// do nothing\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tthis.#value[match.groups.key] = keyValue\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn this.#value\n\t}\n}\n", "import { TOKENS } from \"../util/index.js\"\n\n\nexport class Newline {\n\tstatic tokenName = TOKENS.NEW_LINE\n\n\tstatic test({ line }) {\n\t\tif (typeof line !== \"string\") return false\n\t\treturn [\"\", \"\\n\"].includes(line.trim())\n\t}\n\n\t/**\n\t * returns HTML for a newline\n\t *\n\t * @returns {string}\n\t */\n\tstatic parse() {\n\t\treturn \"<br>\"\n\t}\n}\n", "import { Table } from \"./table.js\"\nimport { Image } from \"./image.js\"\nimport { Comment } from \"./comment.js\"\nimport { HrLine } from \"./hrLine.js\"\nimport { CodeBlock } from \"./codeblock.js\"\nimport { Quote } from \"./quote.js\"\nimport { Heading } from \"./heading.js\"\nimport { List } from \"./list.js\"\nimport { HTML } from \"./html.js\"\nimport { Paragraph } from \"./paragraph.js\"\nimport { FrontMatter } from \"./frontMatter.js\"\nimport { Newline } from \"./newline.js\"\n\n\nconst Parsers = {\n\tTable, Image, Comment, HrLine, CodeBlock, Quote, Heading, List, HTML, Paragraph\n}\n\nconst Tokenizers = {\n\tTable, Image, Comment, HrLine, CodeBlock, Quote, Heading, List, HTML, Newline\n}\n\nexport {\n\tParsers, Tokenizers,\n\tTable, Image, Comment, HrLine, CodeBlock, Quote, Heading, List, HTML, Paragraph, FrontMatter, Newline\n}\n", "import { REGEX } from \"../regex/index.js\"\nimport {\n\tNewline, Heading, FrontMatter, List, HTML,\n\tHrLine, Paragraph, Comment, Quote, Image, Table, CodeBlock\n} from \"../tokenizer/index.js\"\nimport { Indent, Utils, TOKENS } from \"../util/index.js\"\n\n\nexport class Lexer {\n\t#cursor\n\t#lines\n\t#lexerData\n\t#currLine\n\t#nextLine\n\t#currLineIndent\n\t#currLineRawIndent\n\t#lastLexerItem\n\t#lexerLengthBefore\n\t#fromToken\n\t#linkRefs = []\n\t#frontMatter\n\t#config\n\n\tconstructor(lines, { from = null, config= {} } = {}) {\n\t\tthis.#lines = lines\n\t\tthis.#lexerData = []\n\t\tthis.#fromToken = from\n\t\tthis.#cursor = 0\n\t\tthis.#config = config\n\t}\n\n\t#runCurrLineLexer() {\n\t\tconst context = {\n\t\t\tline: this.#currLine,\n\t\t\tnextLine: this.#nextLine,\n\t\t\tlines: this.#lines,\n\t\t\tcursor: this.#cursor,\n\t\t\tindent: this.#currLineIndent,\n\t\t\tlastLexer: this.#lastLexerItem,\n\t\t\tfromToken: this.#fromToken\n\t\t}\n\n\t\tif (Newline.test(context)) return this.#runNewLineLexer()\n\n\t\tif (Heading.test(context)) return this.#runHeadingLexer()\n\n\t\tif (HrLine.test(context)) return this.#runHrLineLexer()\n\n\t\tif (Comment.test(context)) return this.#runCommentLexer()\n\n\t\tif (Image.test(context)) return this.#runImageLexer()\n\n\t\tif (Quote.test(context)) return this.#runQuoteLexer()\n\n\t\tif (List.test(context)) return this.#runListLexer()\n\n\t\tif (Table.test(context)) return this.#runTableLexer()\n\n\t\tif (HTML.testBlock(context)) return this.#runHTMLLexer()\n\n\t\tif (CodeBlock.test(context)) return this.#runCodeBlockLexer()\n\n\t\t// otherwise, it is a paragraph\n\t\treturn this.#runParagraphLexer()\n\t}\n\n\t#runNewLineLexer() {\n\t\t// cannot be added at the top of the content\n\t\tif (this.#lexerLengthBefore === 0) return true\n\t\t// if there are multiple new lines in a row,\n\t\t// only single new line is added to the lexerContent\n\t\tif (this.#lastLexerItem.type !== TOKENS.NEW_LINE) {\n\t\t\tthis.#lexerData.push({\n\t\t\t\ttype: TOKENS.NEW_LINE\n\t\t\t})\n\t\t}\n\t}\n\n\t#runHrLineLexer() {\n\t\t// if (this.#lastLexerItem && this.#lastLexerItem.type === TOKENS.HR_LINE) return true\n\t\tthis.#lexerData.push({\n\t\t\ttype: TOKENS.HR_LINE\n\t\t})\n\t}\n\n\t#runCodeBlockLexer() {\n\t\tconst cbTokenizer = new CodeBlock(\n\t\t\tthis.#lines,\n\t\t\tthis.#cursor,\n\t\t\tthis.#currLineIndent,\n\t\t\tthis.#currLineRawIndent\n\t\t)\n\n\t\tconst cbTokens = cbTokenizer.tokenize()\n\n\t\tthis.#lexerData.push(cbTokens.lexer)\n\n\t\t// skip the lines that were parsed\n\t\tthis.#cursor = cbTokens.cursor\n\t}\n\n\t#runTableLexer() {\n\t\tconst tableTokenizer = new Table(\n\t\t\tthis.#lines,\n\t\t\tthis.#cursor,\n\t\t\tthis.#currLineIndent,\n\t\t\tthis.#linkRefs\n\t\t)\n\t\tconst tableTokens = tableTokenizer.tokenize()\n\n\t\tthis.#lexerData.push(tableTokens.lexer)\n\n\t\tthis.#cursor = tableTokens.cursor\n\t}\n\n\t#runHTMLLexer() {\n\t\tconst htmlTokenizer = new HTML(\n\t\t\tthis.#lines,\n\t\t\tthis.#cursor,\n\t\t\tthis.#currLineIndent,\n\t\t\tthis.#linkRefs\n\t\t)\n\t\tconst htmlTokens = htmlTokenizer.tokenize()\n\n\t\tthis.#lexerData.push(htmlTokens.lexer)\n\n\t\tthis.#cursor = htmlTokens.cursor\n\t}\n\n\t#runListLexer() {\n\t\tconst list = new List(\n\t\t\tthis.#lines,\n\t\t\tthis.#cursor,\n\t\t\tthis.#currLineIndent,\n\t\t\tthis.#fromToken\n\t\t)\n\t\tconst listTokens = list.tokenize()\n\n\n\t\tthis.#cursor = listTokens.cursor\n\n\t\t// case 1: if the last lexer is a list with same context,\n\t\t// then merge the list items into the last lexer items\n\t\tif (\n\t\t\tList.compareIfTwoListLexerAreOfSameType(this.#lastLexerItem, listTokens, this.#currLineIndent)\n\t\t) {\n\t\t\tthis.#lastLexerItem.items.push(listTokens.lexer)\n\t\t\tthis.#lastLexerItem.raw += `\\n${listTokens.lexer.raw}`\n\t\t\treturn\n\t\t}\n\n\t\t// case 2: if the last lexer is a newline and the lexer before that is a list with same context,\n\t\t// then merge the list items into the last lexer items\n\t\tconst lastLastLexerItem = this.#lexerData[this.#lexerData.length - 2] || false\n\n\t\tif (\n\t\t\tthis.#lastLexerItem &&\n\t\t\tthis.#lastLexerItem.type === TOKENS.NEW_LINE &&\n\t\t\tList.compareIfTwoListLexerAreOfSameType(lastLastLexerItem, listTokens, this.#currLineIndent)\n\t\t) {\n\t\t\t// remove last newline from the lexer content\n\t\t\tthis.#lexerData.pop()\n\t\t\t// add the list to the last lexer item\n\t\t\tconst lastLexerItem = this.#lexerData.at(-1)\n\t\t\t// lastLexerItem.items.push(newline)\n\t\t\tlastLexerItem.items.push(listTokens.lexer)\n\t\t\tlastLexerItem.raw += `\\n${listTokens.lexer.raw}`\n\t\t\treturn\n\t\t}\n\n\t\tthis.#lexerData.push({\n\t\t\ttype: TOKENS.LIST,\n\t\t\tindent: this.#currLineIndent,\n\t\t\tmeta: listTokens.meta,\n\t\t\titems: [listTokens.lexer],\n\t\t\traw: listTokens.lexer.raw\n\t\t})\n\t}\n\n\t#runQuoteLexer() {\n\t\tconst quoteTokenizer = new Quote(this.#lines, this.#cursor)\n\t\tconst quoteTokens = quoteTokenizer.tokenize()\n\t\tthis.#cursor = quoteTokens.cursor\n\n\t\tthis.#lexerData.push({\n\t\t\tindent: this.#currLineIndent,\n\t\t\t...quoteTokens.lexer\n\t\t})\n\t}\n\n\t#runHeadingLexer() {\n\t\tconst hTokenizer = new Heading(this.#currLine, this.#nextLine)\n\t\tconst hTokens = hTokenizer.tokenize()\n\n\t\tif (hTokens.setext) {\n\t\t\tthis.#cursor++\n\t\t}\n\n\t\tthis.#lexerData.push({\n\t\t\ttype: TOKENS.HEADING,\n\t\t\tindent: this.#currLineIndent,\n\t\t\t...hTokens,\n\t\t\ttokens: Paragraph.tokenize(hTokens.value, this.#linkRefs)\n\t\t})\n\t}\n\n\t#runCommentLexer() {\n\t\tthis.#lexerData.push({\n\t\t\ttype: TOKENS.COMMENT,\n\t\t\tindent: this.#currLineIndent,\n\t\t\t...Comment.tokenize(this.#currLine),\n\t\t\traw: this.#currLine\n\t\t})\n\t}\n\n\t#runImageLexer() {\n\t\tthis.#lexerData.push({\n\t\t\ttype: TOKENS.IMAGE,\n\t\t\tindent: this.#currLineIndent,\n\t\t\t...Image.tokenize(this.#currLine),\n\t\t\traw: this.#currLine\n\t\t})\n\t}\n\n\t#runParagraphLexer() {\n\t\tif (\n\t\t\tthis.#lastLexerItem &&\n\t\t\tthis.#lastLexerItem.type === TOKENS.PARAGRAPH &&\n\t\t\tthis.#currLineIndent >= this.#lastLexerItem.indent\n\t\t) {\n\t\t\t// if the last line has 2 or more spaces at the end,\n\t\t\t// then a line break is added to the last line\n\t\t\t// otherwise, the line is added to the last line\n\t\t\tif (this.#lastLexerItem.raw.endsWith(\"  \")) {\n\t\t\t\tthis.#lastLexerItem.value = this.#lastLexerItem.value.trimEnd() + \"<br>\"\n\t\t\t}\n\t\t\tthis.#lastLexerItem.raw += `\\n${this.#currLine}`\n\t\t\tthis.#lastLexerItem.value += ` ${this.#currLine}`\n\t\t\tthis.#lastLexerItem.tokens = Paragraph.tokenize(this.#lastLexerItem.value, this.#linkRefs)\n\t\t} else {\n\t\t\tthis.#lexerData.push({\n\t\t\t\ttype: TOKENS.PARAGRAPH,\n\t\t\t\tindent: this.#currLineIndent,\n\t\t\t\ttokens: Paragraph.tokenize(this.#currLine, this.#linkRefs),\n\t\t\t\traw: this.#currLine,\n\t\t\t\tvalue: this.#currLine\n\t\t\t})\n\t\t}\n\t}\n\n\t#checkForLinkRefs() {\n\t\tfor (this.#cursor = 0; this.#cursor < this.#lines.length; this.#cursor++) {\n\t\t\tconst line = this.#lines[this.#cursor]\n\t\t\tif (Utils.testRegex(line, REGEX.LINK_REF.DECLARATION)) {\n\t\t\t\tthis.#linkRefs.push(Utils.execRegex(line, REGEX.LINK_REF.DECLARATION).groups)\n\t\t\t\t// now remove the current line from the lines array\n\t\t\t\tthis.#lines.splice(this.#cursor, 1)\n\t\t\t\t// and decrement the cursor\n\t\t\t\tthis.#cursor--\n\t\t\t}\n\t\t}\n\t}\n\n\t#runPrep() {\n\t\tthis.#currLine = this.#lines[this.#cursor]\n\t\tthis.#nextLine = this.#lines[this.#cursor + 1]\n\t\tthis.#lexerLengthBefore = this.#lexerData.length\n\t\tthis.#lastLexerItem = this.#lexerData[this.#lexerLengthBefore - 1] || null\n\t\tthis.#currLineRawIndent = Indent.raw(this.#currLine)\n\t\tthis.#currLineIndent = Indent.calc(this.#currLineRawIndent)\n\t}\n\n\t#skipFrontMatter() {\n\t\tif (FrontMatter.test(this.#lines)) {\n\t\t\tthis.#frontMatter = new FrontMatter(this.#lines)\n\t\t\tthis.#lines = this.#frontMatter.removeFrontMatterFromGivenLines()\n\t\t\tthis.#cursor = 0\n\t\t}\n\t}\n\n\tgetFrontMatter() {\n\t\tif (FrontMatter.test(this.#lines)) {\n\t\t\tthis.#frontMatter = new FrontMatter(this.#lines)\n\t\t\treturn this.#frontMatter.getValue()\n\t\t} else {\n\t\t\treturn {}\n\t\t}\n\t}\n\n\trun() {\n\t\tthis.#skipFrontMatter()\n\t\tthis.#checkForLinkRefs()\n\n\t\tfor (this.#cursor = 0; this.#cursor < this.#lines.length; this.#cursor++) {\n\t\t\tthis.#runPrep()\n\t\t\tthis.#runCurrLineLexer()\n\t\t}\n\n\t\treturn this.#lexerData\n\t}\n}\n", "import { Lexer } from \"./lexer/index.js\"\nimport { Parser } from \"./parser/index.js\"\n\n\nexport class HtmlMark {\n\tconfig = {}\n\n\tconstructor(config = {}) {\n\t\tthis.config.indent = config.indent || 4\n\t\tthis.config.highlightFn = config.highlightFn || null\n\t\tthis.config.useLinkRefs = config.useLinkRefs || false\n\t}\n\n\ttokenize(str) {\n\t\tif (typeof str !== \"string\") throw new Error(\"Input must be a string\")\n\t\tconst lexer = new Lexer(str.split(\"\\n\"), { config: this.config })\n\t\treturn lexer.run()\n\t}\n\n\tparse(str) {\n\t\tif (typeof str !== \"string\") throw new Error(\"Input must be a string\")\n\t\tconst lex = this.tokenize(str)\n\t\tconst parser = new Parser(lex, { config: this.config })\n\t\treturn parser.run()\n\t}\n\n\tgetFrontMatter(str) {\n\t\tif (typeof str !== \"string\") throw new Error(\"Input must be a string\")\n\t\tconst lexer = new Lexer(str.split(\"\\n\"))\n\t\treturn lexer.getFrontMatter()\n\t}\n}\n"],
  "mappings": ";;;;;;;;;;AAAO,IAAM,QAAQ;EACpB,SAAS;EACT,OAAO;IACN,MAAM;IACN,OAAO;IACP,OAAO;IACP,WAAW;EACb;EACC,SAAS;EACT,OAAO;EACP,SAAS;IACR,MAAM;IACN,aAAa;IACb,aAAa;EACf;EACC,YAAY;EACZ,MAAM;IACL,UAAU;IACV,WAAW;IACX,SAAS;IACT,MAAM;IACN,OAAO;EACT;EACC,WAAW;IACV,MAAM;IACN,UAAU,WAAA,mCAAgC;IAC1C,MAAM;;IAEN,eAAe;IACf,OAAO;EACT;EACC,MAAM;EACN,UAAU;IACT,aAAa;IACb,WAAW,WAAA,sEAAgE;IAC3E,cAAc,WAAA,oCAAiC;EACjD;EACC,OAAO;IACN,KAAK,WAAA,2EAAA,IAAiE;;;;IAItE,WAAW;;;;IAIX,aAAa;;;;IAIb,YAAY;;;;IAIZ,cAAc;IACd,MAAM,WAAA,kBAAA,GAAc;EACtB;EACC,KAAK;IACJ,IAAI,WAAA,wBAAA,GAAqB;IACzB,IAAI;EACN;EACC,SAAS;EACT,cAAc;IACb,UAAU;IACV,OAAO;EACT;EACC,QAAQ;EACR,qBAAqB;EACrB,eAAe;EACf,iBAAiB;AAClB;ACnEO,IAAM,QAAN,MAAM,OAAM;;;;;;;;;EASlB,OAAO,UAAU,MAAM,OAAO;AAC7B,UAAM,YAAY;AAClB,WAAO,CAAC,CAAC,MAAM,KAAK,IAAI;EAC1B;;;;;;;;EASC,OAAO,UAAU,MAAM,OAAO;AAC7B,UAAM,YAAY;AAClB,WAAO,MAAM,KAAK,IAAI;EACxB;;;;;;;;;EAUC,OAAO,WAAW,MAAM,OAAO;AAC9B,QAAI;AACJ,UAAM,UAAU,CAAA;AAEhB,YAAQ,IAAI,MAAM,KAAK,IAAI,OAAO,MAAM;AACvC,UAAI,EAAE,UAAU,MAAM,WAAW;AAChC,cAAM;MACV;AAEG,YAAM,UAAU,OAAO,KAAK,EAAE,MAAM;AAEpC,QAAE,QAAQ,CAAC,OAAO,eAAe;AAChC,YAAI,SAAS,eAAe,GAAG;AAC9B,kBAAQ,KAAK;YACZ,MAAM,QAAQ,aAAa,CAAC;YAC5B,OAAO;UACb,CAAM;QACN;MACA,CAAI;IACJ;AACE,WAAO;EACT;;;;;;;;;EAUC,OAAO,QAAQ,OAAO,KAAK;AAC1B,UAAM,UAAU,CAAA;AAChB,UAAM,QAAQ,CAAC,MAAM,UAAU;AAC9B,UAAI,UAAU,GAAG;AAChB,gBAAQ,KAAK,IAAI;MACrB,OAAU;AACN,cAAM,OAAO,QAAQ,QAAQ,SAAS,CAAC;AACvC,YAAI,KAAK,GAAG,MAAM,KAAK,GAAG,GAAG;AAC5B,eAAK,SAAS,KAAK;QACxB,OAAW;AACN,kBAAQ,KAAK,IAAI;QACtB;MACA;IACA,CAAG;AACD,WAAO;EACT;;;;;;;EAQC,OAAO,QAAQ,MAAM,OAAO;AAC3B,UAAM,UAAU,OAAM,WAAW,MAAM,KAAK;AAE5C,WAAO,OAAM,QAAQ,SAAS,MAAM;EACtC;;;;;;;;;;;EAYC,OAAO,YAAY,MAAM,UAAU,YAAY,KAAK;AACnD,QAAI,QAAQ;AACZ,aAAS,IAAI,GAAG,IAAI,KAAK,QAAQ,KAAK;AACrC,UAAI,KAAK,CAAC,MAAM,WAAW;AAC1B;AACA,YAAI,UAAU,UAAU;AACvB,iBAAO;QACZ;MACA;IACA;AACE,WAAO;EACT;;;;;;;;;;EAUC,OAAO,gBAAgB,KAAK,QAAQ,MAAM;AACzC,QAAI,cAAc;AAClB,aAAS,IAAE,QAAQ,IAAE,IAAI,QAAQ,KAAK;AACrC,UAAI,IAAI,CAAC,MAAM,MAAM;AACpB;MACJ,OAAU;AACN;MACJ;IACA;AACE,WAAO,KAAK,OAAO,WAAW;EAChC;;;;;;;;;;;;;EAaC,OAAO,aAAa,KAAK,YAAY;AACpC,UAAM,QAAQ,WAAW;AACzB,UAAM,QAAQ,WAAW,CAAC;AAE1B,UAAM,aAAa,IAAI,OAAO,YAC1B,KAAK,OAEL,KAAK,IACJ,KAAK,SAEN,KAAK,GACL;AAEJ,WAAO,IAAI,OAAO,UAAU;EAC9B;;;;;;;;;;;;;EAcC,OAAO,aAAa,KAAK,YAAY;AACpC,UAAM,QAAQ,WAAW,CAAC;AAC1B,UAAM,QAAQ,WAAW;AAEzB,UAAM,QAAQ,IAAI;MACjB,YAAY,KAAK,OACZ,KAAK,IACN,KAAK;IACZ;AACE,WAAO,IAAI,OAAO,KAAK;EACzB;AACA;AC1LO,IAAM,MAAN,MAAU;EAChB,OAAO,QAAQ,KAAK;AACnB,QAAI,CAAC,IAAK,QAAO;AACjB,WAAO,IACL,WAAW,KAAK,OAAO,EACvB,WAAW,MAAM,IAAI,IAAI,MAAM,EAC/B,WAAW,MAAM,IAAI,IAAI,MAAM,EAC/B,WAAW,KAAM,QAAQ,EACzB,WAAW,KAAK,OAAO;EAC3B;EAEC,OAAO,WAAW,KAAK;AACtB,QAAI,CAAC,IAAK,QAAO;AACjB,WAAO,IACL,WAAW,KAAK,OAAO,EACvB,WAAW,KAAK,MAAM,EACtB,WAAW,KAAK,MAAM,EACtB,WAAW,KAAM,QAAQ,EACzB,WAAW,KAAK,OAAO;EAC3B;EAEC,OAAO,OAAO,KAAK;AAClB,QAAI,CAAC,IAAK,QAAO;AACjB,WAAO,IACL,WAAW,SAAS,GAAG,EACvB,WAAW,QAAQ,GAAG,EACtB,WAAW,QAAQ,GAAG,EACtB,WAAW,UAAU,GAAI,EACzB,WAAW,SAAS,GAAG;EAC3B;EAEC,OAAO,SAAS,KAAK;AACpB,QAAI,CAAC,IAAK,QAAO;AACjB,QAAI,MAAM,UAAU,KAAK,MAAM,OAAO,GAAG;AACxC,YAAM,IAAI,WAAW,MAAM,SAAS,IAAI;IAC3C;AACE,WAAO;EACT;AACA;AC1CO,IAAM,SAAS;EACrB,UAAU;EACV,WAAW;EACX,YAAY;EACZ,SAAS;EACT,OAAO;EACP,OAAO;EACP,MAAM;EACN,QAAQ;EACR,WAAW;EACX,gBAAgB;EAChB,MAAM;EACN,MAAM;EACN,MAAM;EACN,WAAW;EACX,YAAY;EACZ,YAAY;EACZ,SAAS;EACT,MAAM;EACN,SAAS;EACT,OAAO;EAAS,gBAAgB;EAChC,cAAc;EACd,iBAAiB;EACjB,OAAO;EACP,MAAM;EACN,cAAc;AACf;ACpBA,OAAO,UAAU,UAAU,SAAU,GAAG,GAAG;AAC1C,SAAO,QAAQ,KAAK,QAAQ;AAC7B;AAEA,IAAM,cAAc;AAMb,IAAM,SAAN,MAAa;;;;;;;;EAQnB,OAAO,IAAI,MAAM;AAChB,QAAI,CAAC,IAAI,MAAM,MAAS,EAAE,SAAS,IAAI,EAAG,QAAO;AACjD,QAAI,QAAQ;AACZ,WAAO,KAAK,KAAK,MAAM,OAAO,KAAK,KAAK,MAAM,KAAM;AACnD;IACH;AACE,WAAO;EACT;;;;;;;;EASC,OAAO,KAAK,WAAW;AACtB,WAAO,KAAK,MAAM,YAAY,WAAW,IAAI;EAC/C;;;;;;;;EASC,OAAO,IAAI,MAAM;AAChB,WAAO,KAAK,KAAK,KAAK,IAAI,IAAI,CAAC;EACjC;;;;;;;;;EAUC,OAAO,QAAQ,MAAM,QAAQ;AAC5B,WAAO,KAAK;MACV,SAAO,cAAc,IAAK,IAAI,SAAO;MACtC,SAAO;IACV;EACA;AACA;;AC9DO,IAAM,SAAN,MAAM,OAAM;;;;;;;;;;;EAwKlB,YAAY,OAAO,QAAQ,QAAQ,UAAU;AAxKvC;AACN;AACA;AACA;AACA;AACA;AACA,8BAAQ,CAAA;AACR;AACA;AACA;;AAgKC,uBAAK,QAAS;AACd,uBAAK,SAAU;AACf,uBAAK,QAAS;AACd,uBAAK,SAAU;AACf,uBAAK,WAAY;AACjB,uBAAK,YAAa,6BAAM,gCAAN,SAAoB,mBAAK,QAAO,mBAAK,QAAO;AAC9D,uBAAK,MAAO,EAAE,MAAM,OAAO,OAAO,QAAQ,mBAAK,UAAS,MAAM,CAAA,EAAE;AAChE,uBAAK,cAAe;EACtB;;;;;;EAtEC,OAAO,KAAK,EAAE,OAAO,QAAQ,OAAM,GAAI;;AACtC,UAAM,cAAc,MAAM,MAAM;AAEhC,QAAI,CAAC,6BAAM,2BAAN,SAAe,aAAc,QAAO;AAEzC,UAAM,YAAY,sBAAK,gCAAL,WAAmB;AACrC,QAAI,WAAW,MAAM,SAAS,CAAC;AAC/B,QAAI,eAAe,MAAM,SAAS,CAAC;AAEnC,QAAI,aAAa,QAAW;AAC3B,iBAAW,SAAS,QAAO;AAC3B,qBAAe,6CAAc;AAE7B,UAEE,gBACG,6BAAM,2BAAN,SAAe,UAAU,WAAW,WACpC,6BAAM,yBAAN,SAAa,cAAc,WAAW,WAEvC,6BAAM,yBAAN,SAAa,UAAU,WAAW,SACpC;AACD,eAAO;MACX;IACA;AACE,WAAO;EACT;;;;;;EA4EC,WAAW;AACV,0BAAK,8BAAL;AAEA,0BAAK,8BAAL;AAEA,0BAAK,qCAAL;AAEA,WAAO,EAAE,OAAO,mBAAK,OAAM,QAAQ,mBAAK,WAAU,EAAC;EACrD;;;;;;;;EASC,OAAO,MAAM,OAAO;AACnB,QAAI,cAAc;AAClB,QAAI,MAAM,aAAa;AACtB,YAAM,WAAW,MAAM,KAAK,CAAC;AAC7B,qBAAe,OAAO,SAAS,IAAI,OAAK,UAAU,MAAM,CAAC,CAAC,EAAE,KAAK,WAAW,CAAC;AAC7E,cAAQ,MAAM,KAAK,MAAM,CAAC;IAC7B,OAAS;AACN,cAAQ,MAAM;IACjB;AACE,UAAM,YAAY,MAAM,IAAI,SAAO,WAAW,IAAI,IAAI,UAAQ,UAAU,MAAM,IAAI,CAAC,EAAE,KAAK,WAAW,CAAC,YAAY,EAAE,KAAK,EAAE;AAC3H,WAAO,UAAU,eAAe;MAC5B,YAAY;mBACC,EAAE;;MAEf,SAAS;;;EAGf;AACA;AAlPC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AATM;AAoBC,aAAQ,SAAC,MAAM;AACrB,SAAO,MAAM,UAAU,MAAM,MAAM,MAAM,GAAG,KACxC,EACF,MAAM,UAAU,MAAM,MAAM,MAAM,SAAS,KAC3C,MAAM,UAAU,MAAM,MAAM,MAAM,UAAU,KAC5C,MAAM,UAAU,MAAM,MAAM,MAAM,WAAW,KAC7C,MAAM,UAAU,MAAM,MAAM,MAAM,YAAY;AAElD;AASQ,kBAAa,SAAC,MAAM;AAC1B,UAAQ,KAAK,MAAM,MAAM,MAAM,IAAI,KAAK,CAAA,GAAI;AAC9C;AAWQ,aAAQ,SAAC,MAAM,OAAO,QAAQ;;AACpC,SAAO,OAAO,IAAI,IAAI,MAAM,WAE1B,MAAM,UAAU,MAAM,MAAM,MAAM,SAAS,KAC3C,MAAM,UAAU,MAAM,MAAM,MAAM,UAAU,KAC5C,MAAM,UAAU,MAAM,MAAM,MAAM,WAAW,KAC7C,MAAM,UAAU,MAAM,MAAM,MAAM,YAAY,MAE/C,6BAAM,gCAAN,SAAoB,UAAU;AACjC;AAWQ,WAAM,SAAC,MAAM,OAAO,QAAQ;;AAClC,SAAO,OAAO,IAAI,IAAI,MAAM,UAC3B,6BAAM,2BAAN,SAAe,SACf,6BAAM,gCAAN,SAAoB,UAAU,SAC9B,CAAC,6BAAM,2BAAN,SAAe,MAAM,OAAO;AAChC;AAUQ,kBAAa,SAAC,KAAK,UAAU;AACnC,QAAM,cAAc,IAAI,KAAI,EAAG,MAAM,GAAG,EAAE;AAC1C,QAAM,WAAW,YAAY,MAAM,MAAM,MAAM,IAAI;AAEnD,QAAM,QAAQ,CAAA;AAEd,WAAS,QAAQ,UAAQ;AACxB,QAAI,SAAS,IAAK;AAClB,UAAM,KAAK;MACV,KAAK;MACL,QAAQ,UAAU,SAAS,KAAK,KAAI,GAAI,QAAQ;IACpD,CAAI;EACJ,CAAG;AAED,SAAO;AACT;AApGO;;;;AAyIN,aAAQ,WAAG;;AAMV,qBAAK,SAAL,mBAAK,WAAW;AAChB,MAAI,6BAAM,2BAAN,SAAe,mBAAK,QAAO,mBAAK,QAAO,GAAG,mBAAK,aAAY,mBAAK,WAAU;AAC7E,uBAAK,SAAL,mBAAK,WAAW;AAChB,uBAAK,cAAe;EACvB;AAEE,SACC,mBAAK,QAAO,mBAAK,QAAO,MAAM,UAC9B,6BAAM,yBAAN,SAAa,mBAAK,QAAO,mBAAK,QAAO,GAAG,mBAAK,aAAY,mBAAK,WAC7D;AACD,2BAAK,SAAL;EACH;AACE,qBAAK,MAAK,aAAa,IAAI,mBAAK;AAClC;;;;AA0BC,aAAQ,WAAG;AACV,QAAM,cAAc,mBAAK,QAAO,mBAAK,OAAM;AAE3C,MAAI,mBAAK,eAAc;AACtB,uBAAK,OAAS,mBAAK,aAAY,mBAAK,UAAS,IAC1C,CAAC,aAAa,mBAAK,QAAO,mBAAK,UAAS,CAAC,CAAC,IAC1C,CAAC,GAAG,CAAC,WAAW,GAAG,GAAG,mBAAK,QAAO,MAAM,mBAAK,UAAS,GAAG,mBAAK,QAAO,CAAC;EAC5E,OAAS;AACN,uBAAK,OAAQ,mBAAK,QAAO,MAAM,mBAAK,SAAQ,mBAAK,QAAO;EAC3D;AACA;;;;AAKC,oBAAe,WAAG;AACjB,qBAAK,OAAM,QAAQ,SAAO;;AACzB,uBAAK,MAAK,KAAK,KAAK,6BAAM,gCAAN,SAAoB,KAAK,mBAAK,WAAU;EAC/D,CAAG;AACH;AAzMO,aAAM,QAAN;AAWN,cAXY,QAWL,aAAY,OAAO;AAXpB,IAAM,QAAN;ACHA,IAAM,SAAN,MAAM,OAAM;;;;EAMlB,OAAO,KAAK,EAAE,KAAI,GAAI;AACrB,WAAO,MAAM,UAAU,MAAM,MAAM,KAAK;EAC1C;;;;;;EAOC,OAAO,MAAM,MAAM;AAClB,WAAO,MAAM,UAAU,KAAK,KAAI,GAAI,MAAM,KAAK;EACjD;;;;;;EAOC,OAAO,SAAS,MAAM;AACrB,WAAO,OAAM,MAAM,IAAI,EAAE;EAC3B;;;;;;EAOC,OAAO,MAAM,OAAO;AACnB,WAAO,aAAa,MAAM,GAAG,UAAU,IAAI,QAAQ,MAAM,GAAG,CAAC;EAC/D;AACA;AAnCC,cADY,QACL,aAAY,OAAO;AADpB,IAAM,QAAN;ACAA,IAAM,WAAN,MAAM,SAAQ;;;;EAMpB,OAAO,KAAK,EAAE,KAAI,GAAI;AACrB,WAAO,MAAM,UAAU,MAAM,MAAM,OAAO;EAC5C;;;;;;EAMC,OAAO,MAAM,MAAM;AAClB,WAAO,MAAM,UAAU,KAAK,KAAI,GAAI,MAAM,OAAO;EACnD;;;;;;EAOC,OAAO,SAAS,MAAM;AACrB,WAAO,SAAQ,MAAM,IAAI,EAAE;EAC7B;;;;;;;;EASC,OAAO,MAAM,OAAO;AACnB,WAAO,QAAQ,MAAM,KAAK;EAC5B;AACA;AApCC,cADY,UACL,aAAY,OAAO;AADpB,IAAM,UAAN;ACEA,IAAM,SAAN,MAAa;;;;EAMnB,OAAO,KAAK,EAAE,KAAI,GAAI;AACrB,WAAO,MAAM,UAAU,MAAM,MAAM,OAAO;EAC5C;;;;;;EAOC,OAAO,QAAQ;AACd,WAAO;EACT;AACA;AAjBC,cADY,QACL,aAAY,OAAO;;ACHpB,IAAM,aAAN,MAAM,WAAU;;;;;;;;;;;EAmFtB,YAAY,OAAO,QAAQ,QAAQ,WAAW;AAnFxC;AACN,uBAAAA;AACA,uBAAAC;AACA,uBAAAC;AACA,uBAAAC;AACA;AACA;AACA;AACA;AACA;AACA,kCAAY;;AA0EX,uBAAKH,SAAS;AACd,uBAAKE,UAAU;AACf,uBAAKD,SAAS;AACd,uBAAKE,UAAU;AACf,uBAAK,YAAa;AAClB,uBAAK,aAAc,WAAU,UAAU,MAAM,MAAM,CAAC;AACpD,uBAAK,SAAQ,sBAAU,WAAW,MAAM,MAAM,CAAC,MAAlC,mBAAqC,WAArC,mBAA6C,SAAQ;EACpE;;;;;;EAxEC,OAAO,KAAK,EAAE,MAAM,QAAQ,WAAW,UAAS,GAAI;AACnD,QACC,CAAC,aACD,UAAU,MACT,CAAC,aAAa,UAAU,SAAS,OAAO,WACxC;AACD,aAAO;IACV;AAIE,QACC,cAAc,OAAO,aAAa,UAAU,MAC3C,CAAC,cAAa,uCAAW,UAAS,OAAO,WACzC;AACD,aAAO;IACV;AAME,QACC,cAAc,OAAO,SAAS,UAAU,MACvC,CAAC,cAAa,uCAAW,UAAS,OAAO,WACzC;AACD,aAAO;IACV;AAEE,WAAO,WAAU,UAAU,IAAI;EACjC;;;;;;;;EASC,OAAO,UAAU,MAAM;AACtB,WAAO,MAAM,UAAU,KAAK,QAAO,GAAI,MAAM,UAAU;EACzD;;;;;;;;EASC,OAAO,WAAW,MAAM;AACvB,WAAO,MAAM,UAAU,KAAK,QAAO,GAAI,MAAM,UAAU;EACzD;;;;;;;;;;;;;;EAmGC,WAAW;AACV,0BAAK,sBAAAC,aAAL;AAEA,0BAAK,kCAAL;AAEA,0BAAK,iCAAL;AAEA,WAAO;MACN,QAAQ,mBAAKF,YAAU;MACvB,OAAO;QACN,MAAM,OAAO;QACb,QAAQ,mBAAKC;QACb,UAAU,mBAAK,UAAS;QACxB,OAAO,mBAAK;QACZ,KAAK,mBAAK;MACd;IACA;EACA;;;;;;;;;;;EAYC,OAAO,MAAM,OAAO,cAAc,MAAM;AACvC,QAAI,WAAW;AACf,QAAI,MAAM,UAAU;AACnB,iBAAW,SAAS,QAAQ,UAAU,oBAAoB,MAAM,QAAQ,GAAG;IAC9E,OAAS;AACN,iBAAW,SAAS,QAAQ,UAAU,EAAE;IAC3C;AACE,QAAI,aAAa;AAChB,YAAM,kBAAkB,YAAY,MAAM,OAAO,MAAM,QAAQ;AAC/D,UAAI,OAAO,oBAAoB,UAAU;AACxC,cAAM,QAAQ;MAClB,OAAU;AACN,gBAAQ,MAAM,kCAAkC;AAChD,gBAAQ,KAAK,0BAA0B;MAC3C;AACG,iBAAW,SAAS,QAAQ,MAAM,MAAM,KAAK;IAChD,OAAS;AACN,iBAAW,SAAS,QAAQ,MAAM,IAAI,WAAW,MAAM,KAAK,CAAC;IAChE;AACE,WAAO;EACT;AACA;AA3NCH,UAAA;AACAC,UAAA;AACAC,WAAA;AACAC,WAAA;AACA;AACA;AACA;AACA;AACA;AACA;AAVM;;;;;;AAkGNC,cAAQ,WAAG;AACV,MAAI,UAAU,gBAAgB,eAAe;AAE7C,KAAG;AACF,eAAW,mBAAKJ,SAAc,EAAL,uBAAKE,UAAL,CAAY;AACrC,QAAI,aAAa,IAAI;AACpB;IACJ;AACG,qBAAkB,WAAY,OAAO,IAAI,QAAQ,IAAI;AAErD,QAAI,aAAa,QAAW;AAC3B,UAAI,mBAAK,cAAa;AACrB,wBAAgB,SAAS,KAAI,MAAO;AACpC,YACC,iBACA,mBAAmB,mBAAKC,WACvB;AACD,iCAAuB;QAC7B;MACA;IACA;AAEG,QAAI,CAAC,sBAAsB;AAC1B,UAAI,iBAAiB,mBAAKA,WAAS;AAClC,+BAAuB;AACvB,YAAI,mBAAK,aAAa,oBAAK,WAAY;MAC5C;IACA;EAEA,SACG,aAAa,UACb,CAAC;AAEJ;;;;AAKC,aAAQ,WAAG;AACV,QAAM,QAAS,mBAAK,eAAe,mBAAKF,WAAS,IAAI,mBAAKA;AAE1D,qBAAK,OAAQ,mBAAKD,SAAO,MAAM,OAAO,mBAAKE,SAAO,EAChD,IAAI,UAAQ,KAAK,MAAM,KAAK,IAAI,mBAAK,aAAY,OAAO,IAAI,IAAI,CAAC,CAAC,CAAC,EACnE,KAAK,IAAI;AACb;;;;AAKC,YAAO,WAAG;AACT,MAAI;AACJ,MAAI,mBAAK,cAAa;AACrB,aAAS,mBAAKA,YAAU;AACxB,QAAI,mBAAK,WAAW,UAAS,mBAAKA;EACrC,MAAS,UAAS,mBAAKA;AACrB,qBAAK,MAAO,mBAAKF,SAAO,MAAM,mBAAKC,UAAQ,MAAM,EAAE,KAAK,IAAI;AAC5D,qBAAKC,UAAU;AACjB;AA/IC,cAZY,YAYL,aAAY,OAAO;AAZpB,IAAM,YAAN;;ACAA,IAAM,SAAN,MAAa;EASnB,YAAY,QAAQ,EAAE,OAAO,MAAM,SAAS,CAAA,EAAE,IAAK,CAAA,GAAI;AATjD;AACN;AACA,uBAAAA;AACA;AACA;AACA;AACA;AACA,yCAAmB,CAAA;AAGlB,uBAAK,SAAU;AACf,uBAAK,gBAAiB,CAAA;AACtB,uBAAK,YAAa;AAClB,uBAAK,SAAU;AACf,uBAAK,kBAAmB,CAAA;AAExB,uBAAK,kBAAiB,OAAO,SAAS,IAAI,sBAAK,sCAAgB,KAAK,IAAI;EAC1E;EAiCC,MAAM;AACL,SAAK,mBAAKA,UAAQ,IAAG,mBAAKA,YAAQ,mBAAK,SAAQ,QAAQ,uBAAKA,UAAL,KAAgB;AACtE,yBAAK,eAAgB,mBAAK,SAAQ,mBAAKA,SAAO;AAC9C,4BAAK,yCAAL;IACH;AAGE,WAAO,mBAAK,gBACV,IAAI,UAAQ,KAAK,WAAW,MAAM,EAAE,CAAC,EACrC,KAAK,EAAE;EACX;AACA;AA5DC;AACAA,WAAA;AACA;AACA;AACA;AACA;AACA;AAPM;AAmBN,oBAAe,WAAG;AACjB,MAAI,SAAS,QAAQ,UAAU,MAAM,mBAAK,cAAa;AACvD,MAAI,mBAAK,gBAAe,OAAO,MAAM;AACpC,uBAAK,gBAAe,KAAK,GAAG,MAAM,EAAE;EACvC,MAAS,oBAAK,gBAAe,KAAK,MAAM,MAAM,MAAM;AACpD;AAGC,uBAAkB,WAAG;AACpB,aAAW,UAAU,SAAS;AAC7B,QAAI,QAAQ,MAAM,EAAE,cAAc,mBAAK,eAAc,MAAM;AAC1D,UAAI,mBAAK,kBAAiB,mBAAK,eAAc,IAAI,GAAG;AACnD,2BAAK,kBAAiB,mBAAK,eAAc,IAAI,EAAC;AAC9C;MACL;AAEI,UACC,mBAAK,eAAc,SAAS,OAAO,cACnC,mBAAK,SAAQ,eACb,OAAO,mBAAK,SAAQ,gBAAgB,YACnC;AACD,2BAAK,gBAAe,KAAK,QAAQ,MAAM,EAAE,MAAM,mBAAK,gBAAe,mBAAK,SAAQ,WAAW,CAAC;AAC5F;MACL;AAEI,yBAAK,gBAAe,KAAK,QAAQ,MAAM,EAAE,MAAM,mBAAK,cAAa,CAAC;AAClE;IACJ;EACA;AACA;;AC7CO,IAAM,SAAN,MAAM,OAAM;EAuElB,YAAY,OAAO,QAAQ;AAvErB;AACN,uBAAAF;AACA,uBAAAC;AACA,uBAAAC;AACA,uBAAAG,QAAQ,CAAA;AACR,+BAAS,CAAA;AACT;AAEA;qCAAe;;;MAGd,MAAM,QAAQ;MACd,MAAM,KAAK;MACX,MAAM;IACR;AA0DE,uBAAKL,SAAS;AACd,uBAAKE,UAAU;AACf,uBAAKD,SAAS;EAChB;;;;;;EApDC,OAAO,KAAK,EAAE,KAAI,GAAI;AACrB,WAAO,MAAM,UAAU,MAAM,MAAM,MAAM,IAAI;EAC/C;;;;;;;;EASC,OAAO,UAAU,MAAM;AACtB,WAAO,MAAM,UAAU,MAAM,MAAM,MAAM,KAAK;EAChD;;;;;;;;;;;EAYC,OAAO,SAAS,MAAM;AACrB,WAAO,KAAK,UAAS;AACrB,QAAI,KAAK,CAAC,MAAM,IAAK,QAAO;AAC5B,QAAI,OAAM,UAAU,KAAK,KAAI,CAAE,EAAG,QAAO,KAAK,MAAM,MAAM,MAAM,KAAK,EAAE;AACvE,UAAM,YAAY,KAAK,UAAU,GAAG,KAAK,OAAO,MAAM,MAAM,SAAS,CAAC;AACtE,WAAO,UAAU,MAAM,MAAM,MAAM,KAAK,EAAE;EAC5C;;;;;;;;;EAUC,OAAO,SAAS,MAAM,OAAO;AAC5B,WAAO,KAAK,UAAS;AACrB,UAAM,SAAS,MAAM,YAAY,MAAM,KAAK;AAE5C,WAAO,KAAK,UAAU,SAAS,CAAC;EAClC;;;;;;EA2GC,WAAW;AACV,0BAAK,kBAAAG,aAAL;AAEA,0BAAK,kBAAAE,aAAL;AAEA,0BAAK,sCAAL;AAEA,0BAAK,+BAAL;AAEA,UAAM,MAAM,IAAI,MAAM,mBAAK,SAAQ,EAAE,MAAM,OAAO,MAAK,CAAE;AAEzD,WAAO;MACN,QAAQ,mBAAKJ;MACb,OAAO;QACN,MAAM,OAAO;QACb,QAAQ,IAAI,IAAG;QACf,OAAO,mBAAK;QACZ,KAAK,mBAAKG,QAAM,KAAK,IAAI;MAC7B;IACA;EACA;;;;;;;;EA0BC,OAAO,MAAM,OAAO;;AACnB,UAAM,SAAS,CAAA;AACf,UAAM,OAAO,QAAQ,aAAW;AAC/B,UAAI;AACJ,mBAAa,IAAI,OAAO,CAAC,OAAO,CAAC;AACjC,aAAO,KAAK,WAAW,IAAG,CAAE;IAC/B,CAAG;AACD,WAAO,6BAAM,8BAAN,SACN,MAAM,OACN,OAAO,KAAK,EAAE;EAEjB;AACA;AAzOCL,UAAA;AACAC,UAAA;AACAC,WAAA;AACAG,SAAA;AACA;AACA;AAEA;AARM;AA6EN,iBAAY,WAAG;AACd,yBAAKH,UAAL;AAEA,MAAI;AAEJ,MAAI,UAAU;AACd,KAAG;AACF,eAAW,mBAAKF,SAAc,EAAL,uBAAKE,UAAL,CAAY;AACrC,QAAI,aAAa,QAAW;AAC3B,UAAI,QAAQ,KAAK,EAAE,MAAM,SAAQ,CAAE,GAAG;AACrC,kBAAU;MACf;AACI,eAAS,IAAE,GAAG,IAAE,mBAAK,cAAa,QAAQ,KAAK;AAC9C,YAAI,MAAM,UAAU,UAAU,mBAAK,cAAa,CAAC,CAAC,GAAG;AACpD,oBAAU;AACV;QACN;MACA;IACA;EACA,SAAW,aAAa,UAAa,CAAC;AAGpC,yBAAKA,UAAL;AACF;;;;;;AAOCE,cAAQ,WAAG;AACV,MAAI,WAAW,mBAAKJ,SAAO,mBAAKE,SAAO;AACvC,MAAI;AAEJ,KAAG;AACF,eAAW,mBAAKF,SAAc,EAAL,uBAAKE,UAAL,CAAY;AACrC,QAAI,aAAa,QAAW;AAC3B,sBAAgB,SAAS,KAAI,EAAG,WAAW,GAAG;IAClD,MAAU,iBAAgB;EAC1B,SACG;AAQD,QAAM,kBAAkB,mBAAKF,SAAO,mBAAKE,YAAU,CAAC;AACpD,MAAI,OAAM,UAAU,eAAe,GAAG;AACrC,2BAAKA,UAAL;AACA;EACH;AAEE,wBAAK,kCAAL;AACF;;;;AAKC,qBAAgB,WAAG;AAClB,qBAAKG,QAAM,QAAQ,CAAC,SAAS;AAC5B,UAAM,YAAY,OAAM,SAAS,IAAI;AACrC,QAAI,mBAAK,aAAY,QAAW;AAC/B,yBAAK,SAAU;IACnB,WAAc,cAAc,GAAG;AAC3B,yBAAK,SAAU,KAAK,IAAI,mBAAK,UAAS,SAAS;IACnD;EACA,CAAG;AACH;;;;AAMCC,cAAQ,WAAG;AACV,qBAAKD,QAAQ,mBAAKL,SAAO,MAAM,mBAAKC,UAAQ,mBAAKC,YAAU,CAAC;AAC9D;;;;;AAMC,cAAS,WAAG;AACX,qBAAKG,QAAM,QAAQ,CAAC,SAAS;AAC5B,QAAI,OAAM,KAAK,EAAE,MAAM,KAAI,CAAE,KAAK,OAAM,UAAU,IAAI,GAAG;AACxD,yBAAK,QAAO,KAAK,OAAM,SAAS,MAAM,mBAAK,QAAO,EAAE,QAAO,CAAE;IACjE,OAAU;AAEN,yBAAK,QAAO,KAAK,KAAK,QAAO,CAAE;IACnC;EACA,CAAG;AACH;AAzKO;AA8MC,gBAAW,SAAC,OAAO,SAAS;AAClC,MAAI,QAAQ;AACZ,WAAS,IAAE,GAAG,IAAE,OAAO,KAAK;AAC3B,YAAQ,MAAM,QAAQ,MAAM;gBACf;EAChB;AACE,SAAO,MAAM,QAAQ,MAAM,GAAG,OAAO,EAAE;AACzC;AArNO,aAAM,QAAN;AAgBN,cAhBY,QAgBL,aAAY,OAAO;AAhBpB,IAAM,QAAN;;ACAA,IAAM,WAAN,MAAM,SAAQ;;;;;;;;;EAiFpB,YAAY,MAAM,UAAU;AAjFtB;AACN;AACA;AACA;AACA;AACA,gCAAU;AA6ET,uBAAK,OAAQ;AACb,uBAAK,WAAY;AACjB,0BAAK,iCAAL;EACF;;;;;;;EAtEC,OAAO,UAAU,MAAM;AACtB,WAAO,MAAM,UAAU,MAAM,MAAM,QAAQ,IAAI;EACjD;;;;;;;EAQC,OAAO,qBAAqB,MAAM;AACjC,WAAO,MAAM,UAAU,MAAM,MAAM,QAAQ,WAAW;EACxD;;;;;;;;EASC,OAAO,qBAAqB,MAAM;AACjC,WAAO,MAAM,UAAU,MAAM,MAAM,QAAQ,WAAW;EACxD;;;;;;;;;;;;;EAcC,OAAO,MAAM,MAAM;AAClB,WAAO,MAAM,UAAU,MAAM,MAAM,QAAQ,IAAI;EACjD;;;;;;EAOC,OAAO,KAAK,EAAE,MAAM,SAAQ,GAAI;AAC/B,QAAI,SAAQ,UAAU,IAAI,EAAG,QAAO;AACpC,QAAI,aAAa,UAAa,CAAC,OAAO,KAAK,EAAE,KAAI,CAAE,GAAG;AACrD,UACC,SAAQ,qBAAqB,QAAQ,KACrC,SAAQ,qBAAqB,QAAQ,GACpC;AACD,eAAO;MACX;IACA;EACA;;;;;;EAkDC,WAAW;AACV,QAAI,CAAC,mBAAK,UAAS;AAClB,aAAO;QACN,OAAO,mBAAK,QAAO,MAAM;QACzB,OAAO,mBAAK,QAAO,MAAM,QAAO;QAChC,KAAK,mBAAK;QACV,QAAQ;MACZ;IACA,OAAS;AACN,aAAO;QACN,OAAO,mBAAK;QACZ,OAAO,mBAAK,OAAM,QAAO;QACzB,KAAK,GAAG,mBAAK,MAAK;EAAK,mBAAK,UAAS;QACrC,QAAQ;MACZ;IACA;EACA;;;;;;;;EASC,OAAO,MAAM,OAAO;AACnB,WAAO,KAAK,MAAM,KAAK,IAAI,UAAU,MAAM,KAAK,CAAC,MAAM,MAAM,KAAK;EACpE;AACA;AApJC;AACA;AACA;AACA;AACA;AALM;;;;;;;;;AA+FN,cAAS,WAAG;;AACX,MAAI,mBAAK,eAAc,QAAW;AACjC,QAAI,CAAC,SAAQ,UAAU,mBAAK,MAAK,GAAG;AACnC,UAAI,SAAQ,qBAAqB,mBAAK,UAAS,GAAG;AACjD,2BAAK,SAAU;AACf,2BAAK,QAAS;MACnB,WACa,SAAQ,qBAAqB,mBAAK,UAAS,GAAG;AACtD,2BAAK,SAAU;AACf,2BAAK,QAAS;MACnB;IACA;EACA;AACE,MAAI,CAAC,mBAAK,UAAS;AAClB,uBAAK,SAAS,cAAQ,MAAM,mBAAK,MAAK,MAAxB,mBAA2B;AACzC,uBAAK,QAAO,QAAQ,mBAAK,QAAO,YAAY,mBAAK,QAAO;AACxD,WAAO,mBAAK,QAAO;AACnB,WAAO,mBAAK,QAAO;EACtB;AACA;AA3GC,cAPY,UAOL,aAAY,OAAO;AAPpB,IAAM,UAAN;;ACEA,IAAM,QAAN,MAAM,MAAK;EA+CjB,YAAY,OAAO,QAAQ,QAAQ;AA/C7B;AACN,uBAAAL;AACA,uBAAAE;AACA,uBAAAC;AACA,uBAAAE,QAAQ,CAAA;AACR;AACA,oCAAc,CAAA;AACd,uBAAAE;AACA,uBAAAC;AACA;AACA,8BAAQ;MACP,WAAW;MACX,SAAS;MACT,YAAY;IACd;AAkCE,uBAAKR,SAAS;AACd,uBAAKE,UAAU;AACf,uBAAKC,UAAU;AACf,uBAAK,UAAW,MAAK,UAAU,MAAM,MAAM,CAAC;AAC5C,0BAAK,iCAAL;EAEF;EApCC,OAAO,UAAU,MAAM;AACtB,WAAO,MAAM,UAAU,MAAM,MAAM,KAAK,KAAK;EAC/C;EAEC,OAAO,SAAS,MAAM;AACrB,WAAO,MAAM,UAAU,MAAM,MAAM,KAAK,IAAI;EAC9C;EAEC,OAAO,KAAK,EAAE,KAAI,GAAI;AACrB,QAAI,MAAK,UAAU,IAAI,GAAG;AAAE,aAAO;IAAI;AACvC,WAAO,MAAK,SAAS,IAAI;EAC3B;EAGC,OAAO,WAAW,MAAM;AACvB,WAAO,MAAM,UAAU,MAAM,MAAM,KAAK,KAAK;EAC/C;EAEC,OAAO,UAAU,MAAM;AACtB,WAAO,MAAM,UAAU,MAAM,MAAM,KAAK,IAAI;EAC9C;EAEC,OAAO,MAAM,MAAM,UAAU,OAAO;AACnC,QAAI,SAAS;AACZ,aAAO,MAAK,WAAW,IAAI;IAC9B;AACE,WAAO,MAAK,UAAU,IAAI;EAC5B;;;;;;EA8GC,WAAW;AACV,0BAAK,iBAAAC,aAAL;AAEA,0BAAK,iBAAAE,aAAL;AAEA,0BAAK,gCAAL;AAEA,uBAAKC,OAAO,IAAI,MAAM,mBAAK,cAAa,EAAE,MAAM,OAAO,UAAS,CAAE;AAElE,WAAO;MACN,QAAQ,mBAAK,QAAO;MACpB,MAAM,mBAAK;MACX,OAAO;QACN,MAAM,OAAO;QACb,QAAQ,mBAAKA,OAAK,IAAG;QACrB,OAAO,mBAAKC,SAAO,SAAS;QAC5B,SAAU,mBAAK,OAAM,YAAa,mBAAKA,SAAO,UAAU,MAAM;QAC9D,KAAK,mBAAKH,QAAM,KAAK,IAAI;MAC7B;IACA;EACA;;;;;;;;EASC,OAAO,MAAM,OAAO;AACnB,UAAM,UAAW,MAAM,KAAK,UAAW,OAAO;AAC9C,QAAI,eAAe,CAAA;AACnB,UAAM,MAAM,QAAQ,cAAY;AAC/B,UAAI,eAAe;AACnB,YAAM,UAAU,IAAI,OAAO,SAAS,QAAQ,EAAE,MAAM,OAAO,KAAI,CAAE;AACjE,UAAI,MAAM,KAAK,WAAW;AACzB,cAAM,YAAa,SAAS,UAAW,aAAa;AACpD,uBAAe,aAAc;UAC5B;UACA,2BACC,YACA,MACA,QAAQ,IAAG;QACjB;MACA,OAAU;AACN,uBAAe,aAAa;UAC3B;UACA,IAAI,OAAO,SAAS,QAAQ,EAAE,MAAM,OAAO,KAAI,CAAE,EAAE,IAAG;QAC3D;MACA;AACG,mBAAa,KAAK,YAAY;IACjC,CAAG;AACD,WAAO,IAAI,OAAO,IAAI,aAAa,KAAK,EAAE,CAAC,KAAK,OAAO;EACzD;;;;;;;;;;;;;;;;;EAkBC,OAAO,mCAAmC,WAAW,gBAAgB,QAAQ;AAC5E,WACC,aACA,UAAU,SAAS,OAAO,QAC1B,UAAU,WAAW,UACrB,UAAU,KAAK,cAAc,eAAe,KAAK,aACjD,UAAU,KAAK,YAAY,eAAe,KAAK,WAC/C,UAAU,KAAK,eAAe,eAAe,KAAK;EAErD;AACA;AA3OCL,UAAA;AACAE,WAAA;AACAC,WAAA;AACAE,SAAA;AACA;AACA;AACAE,QAAA;AACAC,UAAA;AACA;AACA;AAVM;;;;;AA4DNJ,cAAQ,WAAG;AACV,MAAI,mBAAK,WAAU;AAClB,uBAAK,MAAO,mBAAKF,YAAU;AAC3B;EACH;AAEE,MAAI,SAAS,mBAAKA;AAClB,MAAI,UAAU,gBAAgB;AAC9B,MAAI,aAAa;AAGjB,KAAG;AACF,eAAW,mBAAKF,SAAO,EAAE,MAAM;AAE/B,qBAAiB,OAAO,IAAI,QAAQ;AAGpC,mBAAe,mBAAKA,SAAO,SAAS,CAAC;AACrC,QACC,QAAQ,KAAK,EAAE,MAAM,SAAQ,CAAE,GAC9B;AACD,UACC,gBACA,QAAQ,KAAK,EAAE,MAAM,aAAY,CAAE,GAClC;AACD,qBAAa;MAClB,WACK,OAAO,IAAI,YAAY,KAAK,mBAAKG,WAChC;AACD,qBAAa;MAClB;IACA;EACA,SACG,aAAa,UACb,CAAC,cACD,GAEE,MAAK,KAAK,EAAE,MAAM,SAAQ,CAAE,KAC5B,QAAQ,KAAK,EAAE,MAAM,UAAU,UAAU,aAAY,CAAE,KACvD,MAAM,KAAK,EAAE,MAAM,SAAQ,CAAE,MAE9B,kBAAkB,mBAAKA;AAGzB,qBAAK,MAAO;AACd;;;;;;;;;AAUC,iBAAY,WAAG;AACd,qBAAKK,SAAS,MAAK,MAAM,mBAAKR,SAAO,mBAAKE,SAAO,GAAG,mBAAK,SAAQ,EAAE;AAEnE,qBAAK,OAAM,YAAY,mBAAKM,SAAO,UAAU;AAE7C,qBAAK,OAAM,UAAU,CAAC,CAAC,mBAAKA,SAAO;AAEnC,MAAI,mBAAKA,SAAO,KAAM,oBAAK,OAAM,aAAa,mBAAKA,SAAO;AAC5D;;;;AAKCF,cAAQ,WAAG;AACV,qBAAKD,QAAQ,mBAAKL,SAAO,MAAM,mBAAKE,WAAS,mBAAK,KAAI;AACxD;;;;AAKC,gBAAW,WAAG;AACb,WAAS,QAAQ,GAAG,QAAQ,mBAAKG,QAAM,QAAQ,SAAS;AACvD,UAAM,OAAO,mBAAKA,QAAM,KAAK;AAC7B,QAAI,UAAU,GAAG;AAChB,UAAI,mBAAK,WAAU;AAClB,2BAAK,aAAY,KAAK,EAAE;MAC7B,OAAW;AACN,2BAAK,aAAY,KAAK,mBAAKG,SAAO,KAAK;MAC5C;IACA,OAAU;AACN,yBAAK,aAAY,KAAK,IAAI;IAC9B;EACA;AACA;AApIC,cAhBY,OAgBL,aAAY,OAAO;AAhBpB,IAAM,OAAN;;ACHA,IAAM,OAAN,MAAW;EASjB,YAAY,OAAO,QAAQ,QAAQ,UAAU;AAR7C,uBAAAC;AACA,uBAAAT;AACA,uBAAAE;AACA,uBAAAC;AACA,uBAAAI;AAKC,uBAAKP,SAAS;AACd,uBAAKE,UAAU;AACf,uBAAKC,UAAU;AACf,uBAAKM,YAAY;AACjB,uBAAKF,OAAO,CAAA;EACd;;;;;;EAOC,OAAO,KAAK,MAAM;AACjB,WAAO,MAAM,UAAU,MAAM,MAAM,UAAU,IAAI;EACnD;EAEC,OAAO,UAAU,EAAE,OAAO,OAAM,GAAI;AACnC,UAAM,cAAc,MAAM,MAAM;AAChC,WAAO,MAAM,UAAU,aAAa,MAAM,IAAI;EAChD;EAEC,WAAW;AACV,UAAM,aAAa,MAAM,UAAU,mBAAKP,SAAO,mBAAKE,SAAO,GAAG,MAAM,IAAI;AACxE,uBAAKK,OAAO;MACX,MAAM,OAAO;MACb,QAAQ,mBAAKJ;MACb,GAAG,WAAW;MACd,KAAK,mBAAKH,SAAO,mBAAKE,SAAO;IAChC;AACE,WAAO,EAAE,OAAO,mBAAKK,QAAM,QAAQ,mBAAKL,UAAO;EACjD;;;;;;EAOC,OAAO,MAAM,OAAO;AAInB,WAAO,MAAM;EACf;AACA;AApDCO,aAAA;AACAT,UAAA;AACAE,WAAA;AACAC,WAAA;AACAI,QAAA;AAEA,cAPY,MAOL,aAAY,OAAO;;ACRpB,IAAM,aAAN,MAAM,WAAU;;;;;;;;;;;EAatB,OAAO,SAAS,QAAQ,OAAO,QAAQ,IAAI,QAAQ,IAAI,MAAM,IAAI;AAChE,WAAO;MACN;MAAO;MAAO;MAAO;IACxB;EACA;;;;;;;;;;EAiYC,OAAO,SAAS,aAAa,UAAU;;AACtC,WAAO,iCAAU,oCAAV,SAAwB,aAAa;EAC9C;EAEC,OAAO,MAAM,OAAO;AACnB,QAAI,SAAS;AACb,UAAM,OAAO,QAAQ,WAAS;AAC7B,UAAI,MAAM,SAAS,OAAO,MAAM;AAC/B,kBAAU,WAAW,WAAU,MAAM,KAAK,CAAC;MAC/C,WAAc,MAAM,SAAS,OAAO,QAAQ;AACxC,kBAAU,OAAO,WAAU,MAAM,KAAK,CAAC;MAC3C,WAAc,MAAM,SAAS,OAAO,MAAM;AACtC,cAAM,QAAQ,IAAI,SAAS,MAAM,KAAK;AACtC,kBAAU,SAAS,IAAI,WAAW,MAAM,KAAK,CAAC;MAClD,WAAa,MAAM,SAAS,OAAO,gBAAgB;AAC/C,kBAAU,MAAM,WAAU,MAAM,KAAK,CAAC;MAC1C,WAAc,MAAM,SAAS,OAAO,MAAM;AACtC,cAAM,aAAa,MAAM;AACzB,YAAI,UAAU,YAAY,WAAW,IAAI,OACtC,WAAW,UAAU,WAAW,WAAW,OAAO,MAAM,MACzD,MACA,WAAU,MAAM,WAAW,KAAK,IAChC;AAEF,kBAAU;MACd,WAAc,MAAM,SAAS,OAAO,WAAW;AAC3C,kBAAU,MAAM,WAAU,MAAM,KAAK,CAAC;MAC1C,WAAc,MAAM,SAAS,OAAO,OAAO;AACvC,cAAM,YAAY,MAAM;AACxB,YAAI,SAAS,aAAa,UAAU,IAAI,OACrC,UAAU,QAAQ,SAAY,SAAS,UAAU,GAAG,MAAM,OAC1D,UAAU,UAAU,SAAY,WAAW,UAAU,KAAK,MAAM,OAChE,UAAU,UAAU,SAAY,WAAW,UAAU,KAAK,MAAM,OAChE,UAAU,WAAW,SAAY,YAAY,UAAU,MAAM,MAAM,MACpE;AACF,kBAAU;MACd,WAAc,MAAM,SAAS,OAAO,MAAM;AACtC,kBAAU,MAAM;MACpB,OAAU;AACN,cAAM,UAAU,IAAI,QAAQ,MAAM,KAAK;AACvC,cAAM,YAAY,IAAI,SAAS,OAAO;AACtC,kBAAU;MACd;IACA,CAAG;AACD,WAAO;EACT;AACA;AAhcO;AA+BC,iBAAY,SAAC,KAAK,OAAO,gBAAgB;AAE/C,MAAI,QAAQ,IAAI,OAAQ,QAAO;AAG/B,QAAM,kBAAkB,IAAI,UAAU,KAAK;AAC3C,SAAO,gBAAgB,SAAS,cAAc;AAChD;AAaQ,cAAS,SAAC,aAAa,QAAQ,YAAY,YAAU,OAAO,YAAY,OAAO;;AAErF,QAAM,QAAQ,SAAS,WAAW;AAElC,QAAM,SAAS,iCAAU,mCAAV,SAAuB,aAAa,OAAO,WAAW,CAAC;AACtE,MAAI,CAAC,OAAQ,QAAO,WAAU,SAAQ;AAEtC,QAAM,gBAAgB,YAAY,MAAM,KAAK;AAE7C,MAAK,aAAa,WAAW,SAAS,MAAM,KAAI,CAAC,WAAW;AAE3D,UAAM,WAAW,MAAM,aAAa,eAAe,UAAU;AAE7D,QAAI,aAAa,IAAI;AACpB,aAAO,KAAK,SAAS,MAAM,YAAY,OAAO,QAAQ,QAAQ;IAClE;EACA;AAEE,MAAI,CAAC,WAAW;AACf,aAAS,IAAE,OAAO,KAAK,QAAQ,KAAK;AAGnC,YAAM,iBAAiB,YAAY,UAAU,QAAQ,CAAC;AAEtD,UAAI,WAAW;AACd,YAAI,eAAe,SAAS,MAAM,GAAG;AACpC;QACN;MACA;AAEI,YAAM,MAAM,MAAM,aAAa,eAAe,cAAc;AAE5D,UAAI,QAAQ,IAAI;AACf,eAAO,WAAU,SAAS,MAAM,gBAAgB,OAAO,QAAQ,GAAG;MACvE;IACA;EACA;AAEE,SAAO,WAAU,SAAQ;AAC3B;AAaQ,cAAS,SAAC,aAAa,QAAQ;AACrC,QAAM,QAAQ,YAAY,UAAU,MAAM;AAC1C,MAAI,MAAM,UAAU,OAAO,MAAM,UAAU,IAAI,GAAG;AACjD,UAAM,QAAQ,MAAM,UAAU,OAAO,MAAM,UAAU,IAAI;AACzD,WAAO;MACN,OAAO;MACP,QAAQ,MAAM;MACd,KAAK,SAAS,MAAM,CAAC,EAAE,SAAS;IACpC;EACA;AAAI,SAAO,EAAE,OAAO,OAAO,QAAQ,MAAM,KAAK,GAAE;AAChD;AAEQ,cAAS,SAAC,aAAa,QAAQ;AACrC,QAAM,QAAQ,YAAY,UAAU,MAAM;AAC1C,MAAI,MAAM,UAAU,OAAO,MAAM,UAAU,IAAI,GAAG;AACjD,UAAM,QAAQ,MAAM,UAAU,OAAO,MAAM,UAAU,IAAI;AACzD,WAAO;MACN,OAAO;MACP,QAAQ,MAAM;MACd,KAAK,SAAS,MAAM,CAAC,EAAE,SAAS;IACpC;EACA;AAAI,SAAO,EAAE,OAAO,OAAO,QAAQ,MAAM,KAAK,GAAE;AAChD;AAYQ,iBAAY,SAAC,aAAa,QAAQ;AACxC,QAAM,QAAQ,YAAY,UAAU,MAAM;AAC1C,MAAI,WAAW;AACf,MAAI;AAEJ,MAAI,MAAM,UAAU,OAAO,MAAM,UAAU,QAAQ,GAAG;AAErD,QAAI,MAAM,UAAU,OAAO,MAAM,SAAS,SAAS,GAAG;AACrD,iBAAW;AACX,cAAQ,MAAM,UAAU,OAAO,MAAM,SAAS,SAAS;IAC3D,OAAU;AACN,cAAQ,MAAM,UAAU,OAAO,MAAM,SAAS,YAAY;IAC9D;AAEG,WAAO;MACN,OAAO;MACP;MACA,QAAQ,MAAM;MACd,KAAK,SAAS,MAAM,CAAC,EAAE,SAAS;IACpC;EACA;AAAI,SAAO,EAAE,OAAO,OAAO,QAAQ,MAAM,KAAK,GAAE;AAChD;AAcQ,eAAU,SAAC,aAAa,QAAQ;AACtC,QAAM,QAAQ,YAAY,UAAU,MAAM;AAC1C,MAAI,MAAM,UAAU,OAAO,MAAM,UAAU,KAAK,GAAG;AAClD,UAAM,QAAQ,MAAM,UAAU,OAAO,MAAM,UAAU,KAAK;AAC1D,WAAO;MACN,OAAO;MACP,QAAQ,MAAM;MACd,KAAK,SAAS,MAAM,CAAC,EAAE,SAAS;IACpC;EACA;AAAI,SAAO,EAAE,OAAO,OAAO,QAAQ,MAAM,KAAK,GAAE;AAChD;AAqBQ,kBAAa,SAAC,aAAa,UAAU;;AAC3C,MAAI;AACJ,QAAM,SAAS,CAAA;AAEf,WAAS,2BAA2B,OAAO,QAAQ,OAAO;AACzD,UAAM,YAAY,OAAO,OAAO,SAAS,CAAC;AAC1C,QAAI,QAAQ,SAAS,MAAM,QAAQ;AAClC,YAAM,OAAO,YAAY,UAAU,QAAQ,QAAQ,MAAM,MAAM;AAC/D,UAAI,aAAa,UAAU,SAAS,OAAO,MAAM;AAChD,kBAAU,OAAO;AACjB,kBAAU,SAAS;MACxB,OAAW;AACN,eAAO,KAAK;UACX,MAAM,OAAO;UACb,KAAK;UACL,OAAO;QACb,CAAM;MACN;IACA;EACA;AAEE,WAAS,SAAO,GAAG,SAAO,YAAY,QAAQ,UAAU;AACvD,UAAM,WAAW,YAAY,MAAM;AACnC,UAAM,WAAW,YAAY,SAAO,CAAC,KAAK;AAC1C,UAAM,WAAW,YAAY,SAAO,CAAC,KAAK;AAC1C,UAAM,YAAY,OAAO,OAAO,SAAS,CAAC;AAE1C,QAAI,SAAS;AAEb,QAAI,YAAY,aAAa,KAAM,UAAS;AAE5C,QAAI,CAAC,WAAW,aAAa,OAAO,aAAa,MAAM;AACtD,mBAAa,MAAM,gBAAgB,aAAa,QAAQ,QAAQ;AAEhE,YAAM,EAAE,OAAO,OAAO,OAAO,IAAG,IAAK,iCAAU,gCAAV,SAAoB,aAAa,QAAQ;AAE9E,UAAI,OAAO;AAEV,mCAA2B,OAAO,QAAQ,KAAK;AAE/C,cAAM,IAAI,YAAY,MAAM,OAAO,GAAG;AACtC,eAAO,KAAK;UACX,MAAO,MAAM,SAAS,MAAM,IACzB,OAAO,OACP,OAAO;UACV,KAAK,GAAG,KAAK,GAAG,CAAC,GAAG,KAAK;UACzB,QAAQ,iCAAU,oCAAV,SAAwB,GAAG;QACzC,CAAM;AACD,iBAAS,MAAM,MAAM,SAAS;AAC9B;MACL;IACA,WACY,CAAC,UAAU,aAAa,KAAK;AACrC,mBAAa,MAAM,gBAAgB,aAAa,QAAQ,GAAG;AAE3D,YAAM,EAAE,OAAO,OAAO,OAAO,IAAG,IAAK,iCAAU,gCAAV,SAAoB,aAAa,QAAQ,YAAY;AAE1F,UAAI,OAAO;AACV,cAAM,QAAQ,YAAY,MAAM,OAAO,GAAG;AAC1C,YAAI,MAAM,SAAS,GAAG;AACrB,iBAAO,KAAK;YACX,MAAM,OAAO;YACb,KAAK,GAAG,KAAK,GAAG,KAAK,GAAG,KAAK;;;YAG7B,OAAO,MAAM,KAAI;UACxB,CAAO;AACD,mBAAS,MAAM,MAAM,SAAS;AAC9B;QACN;MACA;IACA,WACY,CAAC,UAAU,CAAC,KAAK,GAAG,EAAE,SAAS,QAAQ,GAAG;AAElD,UAAI,YAAY,aAAa,UAAU;AACtC,qBAAa,MAAM,gBAAgB,aAAa,QAAQ,QAAQ;AAEhE,cAAM,EAAE,OAAO,OAAO,OAAO,IAAG,IAAK,iCAAU,gCAAV,SAAoB,aAAa,QAAQ,YAAY,OAAO;AAEjG,YAAI,OAAO;AACV,qCAA2B,OAAO,QAAQ,KAAK;AAE/C,gBAAM,IAAI,YAAY,MAAM,OAAO,GAAG;AACtC,iBAAO,KAAK;YACX,MAAO,aAAa,MAAO,OAAO,YAAW,OAAO;YACpD,KAAK,GAAG,KAAK,GAAG,CAAC,GAAG,KAAK;YACzB,QAAQ,iCAAU,oCAAV,SAAwB,GAAG;UAC1C,CAAO;AACD,mBAAS,MAAM,MAAM,SAAS;AAC9B;QACN;MACA;IACA,WACY,CAAC,UAAU,aAAa,KAAK;AAErC,YAAM,YAAY,iCAAU,gCAAV,SAAoB,aAAa;AAEnD,UAAI,UAAU,OAAO;AACpB,eAAO,KAAK;UACX,MAAM,OAAO;UACb,KAAK,YAAY,MAAM,QAAQ,UAAU,MAAM,CAAC;UAChD,QAAQ;YACP,OAAO;cACN,KAAK,UAAU,OAAO;cACtB,QAAQ,iCAAU,oCAAV,SAAwB,UAAU,OAAO,MAAM;YAC/D;YACO,MAAM,UAAU,OAAO;YACvB,SAAS,UAAU,OAAO;UACjC;QACA,CAAM;AACD,iBAAS,UAAU;AACnB;MACL;AAGI,UAAI,SAAS,SAAS,GAAG;AACxB,cAAM,eAAe,iCAAU,mCAAV,SAAuB,aAAa;AACzD,YAAI,aAAa,OAAO;AAGvB,gBAAM,MAAM,SAAS,KAAK,OAAK,EAAE,SAAS,aAAa,OAAO,GAAG;AAEjE,cAAI,KAAK;AACR,kBAAM,WAAY,aAAa,WAAY,aAAa,OAAO,OAAO,IAAI;AAE1E,mBAAO,KAAK;cACX,MAAM,OAAO;cACb,KAAK,YAAY,MAAM,QAAQ,aAAa,MAAM,CAAC;cACnD,QAAQ;gBACP,OAAO;kBACN,KAAK;kBACL,QAAQ,iCAAU,oCAAV,SAAwB,UAAU;gBACpD;gBACS,MAAM,IAAI;gBACV,SAAS,IAAI;cACtB;YACA,CAAQ;AACD,qBAAS,aAAa;AACtB;UACP;QACA;MACA;IACA,WACY,CAAC,UAAU,aAAa,KAAK;AAErC,YAAM,aAAa,iCAAU,iCAAV,SAAqB,aAAa;AACrD,UAAI,WAAW,OAAO;AACrB,eAAO,KAAK;UACX,MAAM,OAAO;UACb,KAAK,YAAY,MAAM,QAAQ,WAAW,MAAM,CAAC;UACjD,QAAQ,WAAW;QACzB,CAAM;AACD,iBAAS,WAAW;AACpB;MACL;IAEA,WACY,CAAC,UAAU,aAAa,KAAK;AACrC,YAAM,YAAY,iCAAU,gCAAV,SAAoB,aAAa;AACnD,UAAI,UAAU,OAAO;AACpB,eAAO,KAAK;UACX,MAAM,OAAO;UACb,KAAK,YAAY,MAAM,QAAQ,UAAU,MAAM,CAAC;UAChD,QAAQ;YACP,OAAK,eAAU,WAAV,mBAAkB,UAAO,eAAU,WAAV,mBAAkB;YAChD,aAAY,eAAU,OAAO,UAAjB,mBAAwB;YACpC,UAAU,CAAC,GAAE,eAAU,WAAV,mBAAkB;UACtC;QACA,CAAM;AACD,iBAAS,UAAU;AACnB;MACL;IACA;AAGG,QAAI,aAAa,UAAU,SAAS,OAAO,MAAM;AAChD,gBAAU,OAAO;AACjB,gBAAU,SAAS;IACvB,OAAU;AAEN,aAAO,KAAK;QACX,MAAM,OAAO;QACb,KAAK;QACL,OAAO;MACZ,CAAK;IACL;EACA;AACE,SAAO;AACT;AAvYO,aAAM,YAAN;AACN,cADY,YACL,aAAY,OAAO;AADpB,IAAM,YAAN;;ACDA,IAAM,cAAN,MAAkB;EAQxB,YAAY,OAAO;AAPnB,uBAAAP;AACA;AACA,uBAAAK;AACA,+BAAS,CAAA;AAKR,uBAAKL,SAAS;AACd,SAAK,QAAO;EACd;EAEC,OAAO,KAAK,OAAO;AAClB,QAAI,MAAM,UAAU,MAAM,CAAC,GAAG,MAAM,aAAa,QAAQ,GAAG;AAC3D,eAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACtC,cAAM,OAAO,MAAM,CAAC;AACpB,YAAI,MAAM,UAAU,MAAM,MAAM,aAAa,QAAQ,GAAG;AACvD,iBAAO;QACZ;AACI,YAAI,CAAC,MAAM,UAAU,MAAM,MAAM,aAAa,KAAK,GAAG;AACrD,iBAAO;QACZ;MACA;IACA;AACE,WAAO;EACT;EAEC,UAAU;AACT,aAAS,IAAI,GAAG,IAAI,mBAAKA,SAAO,QAAQ,KAAK;AAC5C,UAAI,MAAM,UAAU,mBAAKA,SAAO,CAAC,GAAG,MAAM,aAAa,QAAQ,GAAG;AACjE,2BAAK,UAAW,IAAI;MACxB;IACA;AACE,uBAAKK,QAAQ,mBAAKL,SAAO,MAAM,GAAG,mBAAK,YAAW,CAAC;EACrD;EAEC,kCAAkC;AACjC,WAAO,mBAAKA,SAAO,MAAM,mBAAK,YAAW,CAAC;EAC5C;EAEC,WAAW;AACV,aAAS,IAAI,GAAG,IAAI,mBAAKK,QAAM,QAAQ,KAAK;AAC3C,YAAM,OAAO,mBAAKA,QAAM,CAAC;AACzB,UAAI,MAAM,UAAU,MAAM,MAAM,aAAa,KAAK,GAAG;AACpD,cAAM,QAAQ,MAAM,UAAU,MAAM,MAAM,aAAa,KAAK;AAC5D,YAAI,OAAO;AACV,cAAI,WAAW,MAAM,OAAO;AAC5B,cAAI,CAAC,QAAQ,OAAO,EAAE,SAAS,SAAS,YAAW,CAAE,GAAG;AACvD,uBAAW,SAAS,YAAW,MAAO;UAC5C,WAAgB,MAAM,OAAO,KAAK,QAAQ,GAAG;AACvC,uBAAW,SAAS,QAAQ;UAClC,WAAgB,MAAM,oBAAoB,KAAK,QAAQ,GAAG;AACpD,uBAAW,WAAW,QAAQ;UACpC,WAAgB,MAAM,cAAc,KAAK,QAAQ,KAAK,MAAM,gBAAgB,KAAK,QAAQ,GAAG;AACtF,gBAAI;AACH,yBAAW,KAAK,MAAM,QAAQ;YACrC,SAAe,GAAG;YAElB;UACA;AACK,6BAAK,QAAO,MAAM,OAAO,GAAG,IAAI;QACrC;MACA;IACA;AACE,WAAO,mBAAK;EACd;AACA;AAlECL,UAAA;AACA;AACAK,SAAA;AACA;AAEA,cANY,aAML,aAAY,OAAO;ACPpB,IAAM,UAAN,MAAc;EAGpB,OAAO,KAAK,EAAE,KAAI,GAAI;AACrB,QAAI,OAAO,SAAS,SAAU,QAAO;AACrC,WAAO,CAAC,IAAI,IAAI,EAAE,SAAS,KAAK,KAAI,CAAE;EACxC;;;;;;EAOC,OAAO,QAAQ;AACd,WAAO;EACT;AACA;AAfC,cADY,SACL,aAAY,OAAO;ACU3B,IAAM,UAAU;EACf;EAAO;EAAO;EAAS;EAAQ;EAAW;EAAO;EAAS;EAAM;EAAM;AACvE;;ACRO,IAAM,QAAN,MAAY;EAelB,YAAY,OAAO,EAAE,OAAO,MAAM,SAAQ,CAAA,EAAE,IAAK,CAAA,GAAI;AAf/C;AACN,uBAAAH;AACA,uBAAAF;AACA;AACA;AACA,uBAAAU;AACA;AACA;AACA;AACA;AACA,uBAAAC;AACA,uBAAAF,YAAY,CAAA;AACZ;AACA,uBAAAG;AAGC,uBAAKZ,SAAS;AACd,uBAAK,YAAa,CAAA;AAClB,uBAAKW,aAAa;AAClB,uBAAKT,UAAU;AACf,uBAAKU,UAAU;EACjB;EA2PC,iBAAiB;AAChB,QAAI,YAAY,KAAK,mBAAKZ,QAAM,GAAG;AAClC,yBAAK,cAAe,IAAI,YAAY,mBAAKA,QAAM;AAC/C,aAAO,mBAAK,cAAa,SAAQ;IACpC,OAAS;AACN,aAAO,CAAA;IACV;EACA;EAEC,MAAM;AACL,0BAAK,sCAAL;AACA,0BAAK,uCAAL;AAEA,SAAK,mBAAKE,UAAU,IAAG,mBAAKA,YAAU,mBAAKF,SAAO,QAAQ,uBAAKE,UAAL,KAAgB;AACzE,4BAAK,8BAAL;AACA,4BAAK,uCAAL;IACH;AAEE,WAAO,mBAAK;EACd;AACA;AAnSCA,WAAA;AACAF,UAAA;AACA;AACA;AACAU,aAAA;AACA;AACA;AACA;AACA;AACAC,cAAA;AACAF,aAAA;AACA;AACAG,WAAA;AAbM;AAuBN,sBAAiB,WAAG;AACnB,QAAM,UAAU;IACf,MAAM,mBAAK;IACX,UAAU,mBAAKF;IACf,OAAO,mBAAKV;IACZ,QAAQ,mBAAKE;IACb,QAAQ,mBAAK;IACb,WAAW,mBAAK;IAChB,WAAW,mBAAKS;EACnB;AAEE,MAAI,QAAQ,KAAK,OAAO,EAAG,QAAO,sBAAK,sCAAL;AAElC,MAAI,QAAQ,KAAK,OAAO,EAAG,QAAO,sBAAK,sCAAL;AAElC,MAAI,OAAO,KAAK,OAAO,EAAG,QAAO,sBAAK,qCAAL;AAEjC,MAAI,QAAQ,KAAK,OAAO,EAAG,QAAO,sBAAK,sCAAL;AAElC,MAAI,MAAM,KAAK,OAAO,EAAG,QAAO,sBAAK,oCAAL;AAEhC,MAAI,MAAM,KAAK,OAAO,EAAG,QAAO,sBAAK,oCAAL;AAEhC,MAAI,KAAK,KAAK,OAAO,EAAG,QAAO,sBAAK,mCAAL;AAE/B,MAAI,MAAM,KAAK,OAAO,EAAG,QAAO,sBAAK,oCAAL;AAEhC,MAAI,KAAK,UAAU,OAAO,EAAG,QAAO,sBAAK,mCAAL;AAEpC,MAAI,UAAU,KAAK,OAAO,EAAG,QAAO,sBAAK,wCAAL;AAGpC,SAAO,sBAAK,wCAAL;AACT;AAEC,qBAAgB,WAAG;AAElB,MAAI,mBAAK,wBAAuB,EAAG,QAAO;AAG1C,MAAI,mBAAK,gBAAe,SAAS,OAAO,UAAU;AACjD,uBAAK,YAAW,KAAK;MACpB,MAAM,OAAO;IACjB,CAAI;EACJ;AACA;AAEC,oBAAe,WAAG;AAEjB,qBAAK,YAAW,KAAK;IACpB,MAAM,OAAO;EAChB,CAAG;AACH;AAEC,uBAAkB,WAAG;AACpB,QAAM,cAAc,IAAI;IACvB,mBAAKX;IACL,mBAAKE;IACL,mBAAK;IACL,mBAAK;EACR;AAEE,QAAM,WAAW,YAAY,SAAQ;AAErC,qBAAK,YAAW,KAAK,SAAS,KAAK;AAGnC,qBAAKA,UAAU,SAAS;AAC1B;AAEC,mBAAc,WAAG;AAChB,QAAM,iBAAiB,IAAI;IAC1B,mBAAKF;IACL,mBAAKE;IACL,mBAAK;IACL,mBAAKO;EACR;AACE,QAAM,cAAc,eAAe,SAAQ;AAE3C,qBAAK,YAAW,KAAK,YAAY,KAAK;AAEtC,qBAAKP,UAAU,YAAY;AAC7B;AAEC,kBAAa,WAAG;AACf,QAAM,gBAAgB,IAAI;IACzB,mBAAKF;IACL,mBAAKE;IACL,mBAAK;IACL,mBAAKO;EACR;AACE,QAAM,aAAa,cAAc,SAAQ;AAEzC,qBAAK,YAAW,KAAK,WAAW,KAAK;AAErC,qBAAKP,UAAU,WAAW;AAC5B;AAEC,kBAAa,WAAG;AACf,QAAM,OAAO,IAAI;IAChB,mBAAKF;IACL,mBAAKE;IACL,mBAAK;IACL,mBAAKS;EACR;AACE,QAAM,aAAa,KAAK,SAAQ;AAGhC,qBAAKT,UAAU,WAAW;AAI1B,MACC,KAAK,mCAAmC,mBAAK,iBAAgB,YAAY,mBAAK,gBAAe,GAC5F;AACD,uBAAK,gBAAe,MAAM,KAAK,WAAW,KAAK;AAC/C,uBAAK,gBAAe,OAAO;EAAK,WAAW,MAAM,GAAG;AACpD;EACH;AAIE,QAAM,oBAAoB,mBAAK,YAAW,mBAAK,YAAW,SAAS,CAAC,KAAK;AAEzE,MACC,mBAAK,mBACL,mBAAK,gBAAe,SAAS,OAAO,YACpC,KAAK,mCAAmC,mBAAmB,YAAY,mBAAK,gBAAe,GAC1F;AAED,uBAAK,YAAW,IAAG;AAEnB,UAAM,gBAAgB,mBAAK,YAAW,GAAG,EAAE;AAE3C,kBAAc,MAAM,KAAK,WAAW,KAAK;AACzC,kBAAc,OAAO;EAAK,WAAW,MAAM,GAAG;AAC9C;EACH;AAEE,qBAAK,YAAW,KAAK;IACpB,MAAM,OAAO;IACb,QAAQ,mBAAK;IACb,MAAM,WAAW;IACjB,OAAO,CAAC,WAAW,KAAK;IACxB,KAAK,WAAW,MAAM;EACzB,CAAG;AACH;AAEC,mBAAc,WAAG;AAChB,QAAM,iBAAiB,IAAI,MAAM,mBAAKF,UAAQ,mBAAKE,SAAO;AAC1D,QAAM,cAAc,eAAe,SAAQ;AAC3C,qBAAKA,UAAU,YAAY;AAE3B,qBAAK,YAAW,KAAK;IACpB,QAAQ,mBAAK;IACb,GAAG,YAAY;EAClB,CAAG;AACH;AAEC,qBAAgB,WAAG;AAClB,QAAM,aAAa,IAAI,QAAQ,mBAAK,YAAW,mBAAKQ,WAAS;AAC7D,QAAM,UAAU,WAAW,SAAQ;AAEnC,MAAI,QAAQ,QAAQ;AACnB,2BAAKR,UAAL;EACH;AAEE,qBAAK,YAAW,KAAK;IACpB,MAAM,OAAO;IACb,QAAQ,mBAAK;IACb,GAAG;IACH,QAAQ,UAAU,SAAS,QAAQ,OAAO,mBAAKO,WAAS;EAC3D,CAAG;AACH;AAEC,qBAAgB,WAAG;AAClB,qBAAK,YAAW,KAAK;IACpB,MAAM,OAAO;IACb,QAAQ,mBAAK;IACb,GAAG,QAAQ,SAAS,mBAAK,UAAS;IAClC,KAAK,mBAAK;EACb,CAAG;AACH;AAEC,mBAAc,WAAG;AAChB,qBAAK,YAAW,KAAK;IACpB,MAAM,OAAO;IACb,QAAQ,mBAAK;IACb,GAAG,MAAM,SAAS,mBAAK,UAAS;IAChC,KAAK,mBAAK;EACb,CAAG;AACH;AAEC,uBAAkB,WAAG;AACpB,MACC,mBAAK,mBACL,mBAAK,gBAAe,SAAS,OAAO,aACpC,mBAAK,oBAAmB,mBAAK,gBAAe,QAC3C;AAID,QAAI,mBAAK,gBAAe,IAAI,SAAS,IAAI,GAAG;AAC3C,yBAAK,gBAAe,QAAQ,mBAAK,gBAAe,MAAM,QAAO,IAAK;IACtE;AACG,uBAAK,gBAAe,OAAO;EAAK,mBAAK,UAAS;AAC9C,uBAAK,gBAAe,SAAS,IAAI,mBAAK,UAAS;AAC/C,uBAAK,gBAAe,SAAS,UAAU,SAAS,mBAAK,gBAAe,OAAO,mBAAKA,WAAS;EAC5F,OAAS;AACN,uBAAK,YAAW,KAAK;MACpB,MAAM,OAAO;MACb,QAAQ,mBAAK;MACb,QAAQ,UAAU,SAAS,mBAAK,YAAW,mBAAKA,WAAS;MACzD,KAAK,mBAAK;MACV,OAAO,mBAAK;IAChB,CAAI;EACJ;AACA;AAEC,sBAAiB,WAAG;AACnB,OAAK,mBAAKP,UAAU,IAAG,mBAAKA,YAAU,mBAAKF,SAAO,QAAQ,uBAAKE,UAAL,KAAgB;AACzE,UAAM,OAAO,mBAAKF,SAAO,mBAAKE,SAAO;AACrC,QAAI,MAAM,UAAU,MAAM,MAAM,SAAS,WAAW,GAAG;AACtD,yBAAKO,YAAU,KAAK,MAAM,UAAU,MAAM,MAAM,SAAS,WAAW,EAAE,MAAM;AAE5E,yBAAKT,SAAO,OAAO,mBAAKE,WAAS,CAAC;AAElC,6BAAKA,UAAL;IACJ;EACA;AACA;AAEC,aAAQ,WAAG;AACV,qBAAK,WAAY,mBAAKF,SAAO,mBAAKE,SAAO;AACzC,qBAAKQ,YAAY,mBAAKV,SAAO,mBAAKE,YAAU,CAAC;AAC7C,qBAAK,oBAAqB,mBAAK,YAAW;AAC1C,qBAAK,gBAAiB,mBAAK,YAAW,mBAAK,sBAAqB,CAAC,KAAK;AACtE,qBAAK,oBAAqB,OAAO,IAAI,mBAAK,UAAS;AACnD,qBAAK,iBAAkB,OAAO,KAAK,mBAAK,mBAAkB;AAC5D;AAEC,qBAAgB,WAAG;AAClB,MAAI,YAAY,KAAK,mBAAKF,QAAM,GAAG;AAClC,uBAAK,cAAe,IAAI,YAAY,mBAAKA,QAAM;AAC/C,uBAAKA,SAAS,mBAAK,cAAa,gCAA+B;AAC/D,uBAAKE,UAAU;EAClB;AACA;AClRO,IAAM,WAAN,MAAe;EAGrB,YAAY,SAAS,CAAA,GAAI;AAFzB,kCAAS,CAAA;AAGR,SAAK,OAAO,SAAS,OAAO,UAAU;AACtC,SAAK,OAAO,cAAc,OAAO,eAAe;AAChD,SAAK,OAAO,cAAc,OAAO,eAAe;EAClD;EAEC,SAAS,KAAK;AACb,QAAI,OAAO,QAAQ,SAAU,OAAM,IAAI,MAAM,wBAAwB;AACrE,UAAM,QAAQ,IAAI,MAAM,IAAI,MAAM,IAAI,GAAG,EAAE,QAAQ,KAAK,OAAM,CAAE;AAChE,WAAO,MAAM,IAAG;EAClB;EAEC,MAAM,KAAK;AACV,QAAI,OAAO,QAAQ,SAAU,OAAM,IAAI,MAAM,wBAAwB;AACrE,UAAM,MAAM,KAAK,SAAS,GAAG;AAC7B,UAAM,SAAS,IAAI,OAAO,KAAK,EAAE,QAAQ,KAAK,OAAM,CAAE;AACtD,WAAO,OAAO,IAAG;EACnB;EAEC,eAAe,KAAK;AACnB,QAAI,OAAO,QAAQ,SAAU,OAAM,IAAI,MAAM,wBAAwB;AACrE,UAAM,QAAQ,IAAI,MAAM,IAAI,MAAM,IAAI,CAAC;AACvC,WAAO,MAAM,eAAc;EAC7B;AACA;",
  "names": ["_lines", "_start", "_cursor", "_indent", "findEnd_fn", "_body", "setBody_fn", "_lex", "_match", "_linkRefs", "_nextLine", "_fromToken", "_config"]
}
